{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tqdm import tqdm\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from nltk.tokenize import RegexpTokenizer\n",
    "from nltk.stem import WordNetLemmatizer\n",
    "import glob\n",
    "import nltk\n",
    "import matplotlib.pyplot as plt\n",
    "from tqdm import tqdm_notebook\n",
    "from nltk.sentiment.vader import SentimentIntensityAnalyzer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "from keras.models import Sequential\n",
    "from keras.preprocessing.sequence import pad_sequences"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "word_space_df = pd.read_csv('words_space.tsv', sep='\\t', header=None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "      <th>9</th>\n",
       "      <th>...</th>\n",
       "      <th>41</th>\n",
       "      <th>42</th>\n",
       "      <th>43</th>\n",
       "      <th>44</th>\n",
       "      <th>45</th>\n",
       "      <th>46</th>\n",
       "      <th>47</th>\n",
       "      <th>48</th>\n",
       "      <th>49</th>\n",
       "      <th>50</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>NaN</td>\n",
       "      <td>0.000891</td>\n",
       "      <td>2.306850e-04</td>\n",
       "      <td>-0.002487</td>\n",
       "      <td>0.000365</td>\n",
       "      <td>8.903410e-04</td>\n",
       "      <td>-0.000867</td>\n",
       "      <td>0.000126</td>\n",
       "      <td>-8.548350e-04</td>\n",
       "      <td>0.001290</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.000868</td>\n",
       "      <td>0.001118</td>\n",
       "      <td>-0.002038</td>\n",
       "      <td>-0.001416</td>\n",
       "      <td>-0.001188</td>\n",
       "      <td>0.000272</td>\n",
       "      <td>-1.039700e-03</td>\n",
       "      <td>1.249780e-03</td>\n",
       "      <td>-0.000796</td>\n",
       "      <td>-8.301510e-05</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>__word__price</td>\n",
       "      <td>0.000006</td>\n",
       "      <td>2.973840e-06</td>\n",
       "      <td>0.000004</td>\n",
       "      <td>-0.000031</td>\n",
       "      <td>2.896700e-05</td>\n",
       "      <td>-0.000038</td>\n",
       "      <td>0.000014</td>\n",
       "      <td>4.506230e-07</td>\n",
       "      <td>-0.000032</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.000008</td>\n",
       "      <td>-0.000016</td>\n",
       "      <td>-0.000029</td>\n",
       "      <td>0.000015</td>\n",
       "      <td>-0.000010</td>\n",
       "      <td>-0.000019</td>\n",
       "      <td>-4.357470e-05</td>\n",
       "      <td>2.011180e-05</td>\n",
       "      <td>0.000009</td>\n",
       "      <td>-7.639540e-06</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>__word__go</td>\n",
       "      <td>0.000026</td>\n",
       "      <td>-4.015650e-06</td>\n",
       "      <td>0.000006</td>\n",
       "      <td>-0.000084</td>\n",
       "      <td>-6.160200e-06</td>\n",
       "      <td>0.000005</td>\n",
       "      <td>0.000058</td>\n",
       "      <td>-4.459280e-05</td>\n",
       "      <td>0.000004</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000023</td>\n",
       "      <td>0.000007</td>\n",
       "      <td>-0.000041</td>\n",
       "      <td>-0.000026</td>\n",
       "      <td>0.000058</td>\n",
       "      <td>-0.000013</td>\n",
       "      <td>-1.563940e-05</td>\n",
       "      <td>1.153700e-05</td>\n",
       "      <td>-0.000031</td>\n",
       "      <td>-2.430360e-06</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>__word__people</td>\n",
       "      <td>-0.000029</td>\n",
       "      <td>1.171530e-05</td>\n",
       "      <td>-0.000140</td>\n",
       "      <td>-0.000021</td>\n",
       "      <td>-1.690560e-05</td>\n",
       "      <td>-0.000029</td>\n",
       "      <td>-0.000035</td>\n",
       "      <td>-1.161040e-04</td>\n",
       "      <td>-0.000003</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000027</td>\n",
       "      <td>-0.000037</td>\n",
       "      <td>0.000019</td>\n",
       "      <td>-0.000025</td>\n",
       "      <td>0.000066</td>\n",
       "      <td>0.000021</td>\n",
       "      <td>1.222220e-05</td>\n",
       "      <td>-5.887540e-05</td>\n",
       "      <td>0.000007</td>\n",
       "      <td>3.758550e-05</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>__word__time</td>\n",
       "      <td>0.000044</td>\n",
       "      <td>-4.201780e-05</td>\n",
       "      <td>0.000069</td>\n",
       "      <td>-0.000026</td>\n",
       "      <td>-3.616490e-05</td>\n",
       "      <td>0.000025</td>\n",
       "      <td>-0.000018</td>\n",
       "      <td>-2.569730e-05</td>\n",
       "      <td>-0.000017</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.000020</td>\n",
       "      <td>-0.000019</td>\n",
       "      <td>0.000005</td>\n",
       "      <td>0.000014</td>\n",
       "      <td>0.000015</td>\n",
       "      <td>-0.000032</td>\n",
       "      <td>-3.797110e-05</td>\n",
       "      <td>-1.402450e-05</td>\n",
       "      <td>0.000012</td>\n",
       "      <td>-6.772960e-06</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>__word__rise</td>\n",
       "      <td>-0.000032</td>\n",
       "      <td>-1.503780e-05</td>\n",
       "      <td>-0.000033</td>\n",
       "      <td>-0.000011</td>\n",
       "      <td>7.164010e-05</td>\n",
       "      <td>-0.000066</td>\n",
       "      <td>0.000035</td>\n",
       "      <td>1.904780e-07</td>\n",
       "      <td>-0.000034</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000007</td>\n",
       "      <td>-0.000003</td>\n",
       "      <td>-0.000060</td>\n",
       "      <td>0.000041</td>\n",
       "      <td>0.000021</td>\n",
       "      <td>-0.000062</td>\n",
       "      <td>-8.350000e-05</td>\n",
       "      <td>6.057710e-05</td>\n",
       "      <td>0.000056</td>\n",
       "      <td>-4.780960e-05</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>__word__buy</td>\n",
       "      <td>0.000104</td>\n",
       "      <td>-6.503720e-05</td>\n",
       "      <td>0.000020</td>\n",
       "      <td>-0.000063</td>\n",
       "      <td>-3.680070e-05</td>\n",
       "      <td>-0.000003</td>\n",
       "      <td>0.000063</td>\n",
       "      <td>-9.256760e-05</td>\n",
       "      <td>-0.000058</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.000046</td>\n",
       "      <td>-0.000039</td>\n",
       "      <td>0.000052</td>\n",
       "      <td>-0.000032</td>\n",
       "      <td>-0.000095</td>\n",
       "      <td>-0.000008</td>\n",
       "      <td>-6.154720e-06</td>\n",
       "      <td>-5.206500e-06</td>\n",
       "      <td>0.000013</td>\n",
       "      <td>-1.546800e-05</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>__word__good</td>\n",
       "      <td>-0.000022</td>\n",
       "      <td>-1.697910e-05</td>\n",
       "      <td>0.000031</td>\n",
       "      <td>-0.000017</td>\n",
       "      <td>-5.420950e-06</td>\n",
       "      <td>-0.000010</td>\n",
       "      <td>-0.000028</td>\n",
       "      <td>-6.218520e-05</td>\n",
       "      <td>-0.000002</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000003</td>\n",
       "      <td>0.000041</td>\n",
       "      <td>-0.000017</td>\n",
       "      <td>-0.000033</td>\n",
       "      <td>0.000029</td>\n",
       "      <td>-0.000018</td>\n",
       "      <td>-3.421030e-05</td>\n",
       "      <td>4.295350e-05</td>\n",
       "      <td>-0.000036</td>\n",
       "      <td>1.250570e-07</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>__word__year</td>\n",
       "      <td>0.000040</td>\n",
       "      <td>-4.497130e-05</td>\n",
       "      <td>0.000001</td>\n",
       "      <td>0.000034</td>\n",
       "      <td>9.840050e-05</td>\n",
       "      <td>0.000023</td>\n",
       "      <td>-0.000077</td>\n",
       "      <td>2.076430e-05</td>\n",
       "      <td>-0.000013</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.000104</td>\n",
       "      <td>0.000027</td>\n",
       "      <td>-0.000029</td>\n",
       "      <td>0.000065</td>\n",
       "      <td>0.000015</td>\n",
       "      <td>-0.000033</td>\n",
       "      <td>2.274020e-05</td>\n",
       "      <td>8.231730e-05</td>\n",
       "      <td>0.000019</td>\n",
       "      <td>-1.743520e-06</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>__word__see</td>\n",
       "      <td>-0.000040</td>\n",
       "      <td>3.179700e-07</td>\n",
       "      <td>0.000015</td>\n",
       "      <td>-0.000011</td>\n",
       "      <td>2.281250e-05</td>\n",
       "      <td>-0.000005</td>\n",
       "      <td>-0.000014</td>\n",
       "      <td>-5.124530e-05</td>\n",
       "      <td>0.000012</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000015</td>\n",
       "      <td>0.000055</td>\n",
       "      <td>-0.000024</td>\n",
       "      <td>0.000062</td>\n",
       "      <td>0.000034</td>\n",
       "      <td>-0.000017</td>\n",
       "      <td>4.706920e-06</td>\n",
       "      <td>-5.948090e-05</td>\n",
       "      <td>-0.000021</td>\n",
       "      <td>-5.747050e-05</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>__word__market</td>\n",
       "      <td>-0.000082</td>\n",
       "      <td>-8.552860e-05</td>\n",
       "      <td>-0.000013</td>\n",
       "      <td>-0.000074</td>\n",
       "      <td>-1.088330e-04</td>\n",
       "      <td>0.000011</td>\n",
       "      <td>0.000052</td>\n",
       "      <td>-1.135720e-05</td>\n",
       "      <td>0.000054</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.000022</td>\n",
       "      <td>-0.000116</td>\n",
       "      <td>-0.000045</td>\n",
       "      <td>0.000032</td>\n",
       "      <td>-0.000027</td>\n",
       "      <td>-0.000004</td>\n",
       "      <td>-9.676540e-05</td>\n",
       "      <td>8.301950e-06</td>\n",
       "      <td>0.000038</td>\n",
       "      <td>1.810370e-05</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>__word__make</td>\n",
       "      <td>0.000003</td>\n",
       "      <td>-8.568250e-06</td>\n",
       "      <td>-0.000011</td>\n",
       "      <td>-0.000008</td>\n",
       "      <td>-5.899240e-05</td>\n",
       "      <td>-0.000035</td>\n",
       "      <td>-0.000081</td>\n",
       "      <td>-5.015670e-05</td>\n",
       "      <td>0.000019</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.000017</td>\n",
       "      <td>-0.000022</td>\n",
       "      <td>-0.000016</td>\n",
       "      <td>0.000015</td>\n",
       "      <td>0.000015</td>\n",
       "      <td>0.000035</td>\n",
       "      <td>4.682290e-05</td>\n",
       "      <td>5.608910e-05</td>\n",
       "      <td>-0.000106</td>\n",
       "      <td>8.471740e-05</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>__word__happen</td>\n",
       "      <td>-0.000008</td>\n",
       "      <td>4.278960e-05</td>\n",
       "      <td>-0.000029</td>\n",
       "      <td>0.000001</td>\n",
       "      <td>1.716380e-05</td>\n",
       "      <td>0.000020</td>\n",
       "      <td>-0.000018</td>\n",
       "      <td>-7.456680e-05</td>\n",
       "      <td>-0.000039</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000013</td>\n",
       "      <td>0.000090</td>\n",
       "      <td>-0.000055</td>\n",
       "      <td>0.000036</td>\n",
       "      <td>0.000025</td>\n",
       "      <td>-0.000009</td>\n",
       "      <td>1.202550e-05</td>\n",
       "      <td>1.455940e-05</td>\n",
       "      <td>-0.000014</td>\n",
       "      <td>-8.176780e-05</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>__word__like</td>\n",
       "      <td>0.000020</td>\n",
       "      <td>-7.956410e-06</td>\n",
       "      <td>-0.000041</td>\n",
       "      <td>0.000038</td>\n",
       "      <td>2.103190e-05</td>\n",
       "      <td>-0.000008</td>\n",
       "      <td>-0.000026</td>\n",
       "      <td>-1.196680e-04</td>\n",
       "      <td>0.000025</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000058</td>\n",
       "      <td>0.000046</td>\n",
       "      <td>-0.000017</td>\n",
       "      <td>-0.000021</td>\n",
       "      <td>0.000014</td>\n",
       "      <td>-0.000033</td>\n",
       "      <td>5.423480e-05</td>\n",
       "      <td>-3.767350e-05</td>\n",
       "      <td>-0.000082</td>\n",
       "      <td>2.584870e-05</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>__word__money</td>\n",
       "      <td>0.000025</td>\n",
       "      <td>-5.086750e-05</td>\n",
       "      <td>-0.000171</td>\n",
       "      <td>0.000090</td>\n",
       "      <td>-1.015540e-04</td>\n",
       "      <td>0.000067</td>\n",
       "      <td>-0.000043</td>\n",
       "      <td>-1.142120e-04</td>\n",
       "      <td>0.000167</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.000056</td>\n",
       "      <td>-0.000143</td>\n",
       "      <td>-0.000014</td>\n",
       "      <td>-0.000023</td>\n",
       "      <td>0.000016</td>\n",
       "      <td>0.000142</td>\n",
       "      <td>1.277130e-04</td>\n",
       "      <td>6.132710e-05</td>\n",
       "      <td>0.000027</td>\n",
       "      <td>1.761470e-04</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>__word__know</td>\n",
       "      <td>-0.000027</td>\n",
       "      <td>-6.000350e-06</td>\n",
       "      <td>-0.000048</td>\n",
       "      <td>-0.000117</td>\n",
       "      <td>-4.460470e-05</td>\n",
       "      <td>0.000102</td>\n",
       "      <td>0.000013</td>\n",
       "      <td>-2.935990e-05</td>\n",
       "      <td>-0.000004</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000030</td>\n",
       "      <td>0.000024</td>\n",
       "      <td>-0.000043</td>\n",
       "      <td>-0.000072</td>\n",
       "      <td>0.000014</td>\n",
       "      <td>0.000031</td>\n",
       "      <td>-1.164980e-07</td>\n",
       "      <td>-6.795670e-05</td>\n",
       "      <td>-0.000039</td>\n",
       "      <td>-5.392040e-05</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>__word__one</td>\n",
       "      <td>-0.000005</td>\n",
       "      <td>-7.904870e-05</td>\n",
       "      <td>-0.000005</td>\n",
       "      <td>-0.000025</td>\n",
       "      <td>2.324080e-05</td>\n",
       "      <td>0.000023</td>\n",
       "      <td>-0.000013</td>\n",
       "      <td>-6.081730e-05</td>\n",
       "      <td>-0.000033</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000007</td>\n",
       "      <td>-0.000018</td>\n",
       "      <td>0.000006</td>\n",
       "      <td>-0.000023</td>\n",
       "      <td>-0.000019</td>\n",
       "      <td>0.000150</td>\n",
       "      <td>4.326830e-05</td>\n",
       "      <td>4.024570e-05</td>\n",
       "      <td>-0.000028</td>\n",
       "      <td>-2.255610e-05</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>__word__sell</td>\n",
       "      <td>0.000104</td>\n",
       "      <td>-1.669280e-05</td>\n",
       "      <td>-0.000024</td>\n",
       "      <td>-0.000040</td>\n",
       "      <td>-4.551940e-05</td>\n",
       "      <td>0.000040</td>\n",
       "      <td>0.000044</td>\n",
       "      <td>-3.047290e-05</td>\n",
       "      <td>-0.000168</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000009</td>\n",
       "      <td>-0.000079</td>\n",
       "      <td>0.000041</td>\n",
       "      <td>0.000018</td>\n",
       "      <td>-0.000085</td>\n",
       "      <td>-0.000072</td>\n",
       "      <td>-2.725490e-05</td>\n",
       "      <td>6.437440e-05</td>\n",
       "      <td>-0.000059</td>\n",
       "      <td>5.761320e-05</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>__word__high</td>\n",
       "      <td>0.000035</td>\n",
       "      <td>-2.978150e-05</td>\n",
       "      <td>0.000031</td>\n",
       "      <td>-0.000062</td>\n",
       "      <td>-9.969450e-07</td>\n",
       "      <td>0.000013</td>\n",
       "      <td>-0.000023</td>\n",
       "      <td>-1.119710e-05</td>\n",
       "      <td>-0.000054</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.000042</td>\n",
       "      <td>-0.000091</td>\n",
       "      <td>-0.000074</td>\n",
       "      <td>-0.000040</td>\n",
       "      <td>0.000048</td>\n",
       "      <td>0.000016</td>\n",
       "      <td>-6.702450e-05</td>\n",
       "      <td>3.389700e-05</td>\n",
       "      <td>0.000006</td>\n",
       "      <td>6.228510e-05</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>__word__bitcoin</td>\n",
       "      <td>0.000340</td>\n",
       "      <td>1.934590e-04</td>\n",
       "      <td>0.000168</td>\n",
       "      <td>-0.000110</td>\n",
       "      <td>4.661170e-05</td>\n",
       "      <td>0.000021</td>\n",
       "      <td>0.000046</td>\n",
       "      <td>-2.217640e-04</td>\n",
       "      <td>0.000019</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000127</td>\n",
       "      <td>0.000204</td>\n",
       "      <td>0.000014</td>\n",
       "      <td>0.000213</td>\n",
       "      <td>-0.000087</td>\n",
       "      <td>-0.000031</td>\n",
       "      <td>1.007680e-04</td>\n",
       "      <td>4.726460e-05</td>\n",
       "      <td>0.000349</td>\n",
       "      <td>-1.575370e-04</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>__word__even</td>\n",
       "      <td>0.000052</td>\n",
       "      <td>2.802450e-05</td>\n",
       "      <td>-0.000031</td>\n",
       "      <td>-0.000049</td>\n",
       "      <td>2.240520e-05</td>\n",
       "      <td>0.000052</td>\n",
       "      <td>-0.000032</td>\n",
       "      <td>2.252010e-05</td>\n",
       "      <td>0.000014</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.000043</td>\n",
       "      <td>0.000038</td>\n",
       "      <td>-0.000024</td>\n",
       "      <td>0.000019</td>\n",
       "      <td>0.000015</td>\n",
       "      <td>0.000035</td>\n",
       "      <td>-3.407370e-05</td>\n",
       "      <td>1.734660e-06</td>\n",
       "      <td>-0.000014</td>\n",
       "      <td>-8.174900e-06</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>__word__still</td>\n",
       "      <td>-0.000009</td>\n",
       "      <td>-3.306890e-05</td>\n",
       "      <td>-0.000045</td>\n",
       "      <td>-0.000173</td>\n",
       "      <td>4.552790e-05</td>\n",
       "      <td>-0.000005</td>\n",
       "      <td>-0.000037</td>\n",
       "      <td>5.556940e-05</td>\n",
       "      <td>0.000022</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.000132</td>\n",
       "      <td>0.000042</td>\n",
       "      <td>0.000033</td>\n",
       "      <td>0.000040</td>\n",
       "      <td>-0.000026</td>\n",
       "      <td>0.000033</td>\n",
       "      <td>-4.815830e-05</td>\n",
       "      <td>4.127900e-06</td>\n",
       "      <td>0.000054</td>\n",
       "      <td>-9.324580e-05</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>__word__also</td>\n",
       "      <td>-0.000039</td>\n",
       "      <td>3.451810e-05</td>\n",
       "      <td>-0.000088</td>\n",
       "      <td>0.000075</td>\n",
       "      <td>-2.887120e-05</td>\n",
       "      <td>-0.000037</td>\n",
       "      <td>-0.000063</td>\n",
       "      <td>-6.824580e-05</td>\n",
       "      <td>-0.000010</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000054</td>\n",
       "      <td>0.000029</td>\n",
       "      <td>-0.000027</td>\n",
       "      <td>-0.000030</td>\n",
       "      <td>0.000046</td>\n",
       "      <td>-0.000024</td>\n",
       "      <td>-2.972300e-06</td>\n",
       "      <td>4.834600e-05</td>\n",
       "      <td>0.000028</td>\n",
       "      <td>5.954240e-05</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>__word__don</td>\n",
       "      <td>-0.000072</td>\n",
       "      <td>8.575820e-05</td>\n",
       "      <td>-0.000050</td>\n",
       "      <td>-0.000084</td>\n",
       "      <td>-1.258500e-05</td>\n",
       "      <td>0.000225</td>\n",
       "      <td>0.000084</td>\n",
       "      <td>-7.119820e-05</td>\n",
       "      <td>-0.000055</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.000035</td>\n",
       "      <td>0.000058</td>\n",
       "      <td>0.000005</td>\n",
       "      <td>0.000043</td>\n",
       "      <td>0.000010</td>\n",
       "      <td>-0.000001</td>\n",
       "      <td>5.082580e-06</td>\n",
       "      <td>-1.365750e-04</td>\n",
       "      <td>-0.000039</td>\n",
       "      <td>-4.572480e-06</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>__word__coin</td>\n",
       "      <td>-0.000116</td>\n",
       "      <td>-3.001440e-04</td>\n",
       "      <td>0.000009</td>\n",
       "      <td>0.000093</td>\n",
       "      <td>-7.908060e-05</td>\n",
       "      <td>-0.000014</td>\n",
       "      <td>-0.000017</td>\n",
       "      <td>-1.419140e-04</td>\n",
       "      <td>-0.000213</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000097</td>\n",
       "      <td>-0.000078</td>\n",
       "      <td>0.000076</td>\n",
       "      <td>-0.000015</td>\n",
       "      <td>-0.000086</td>\n",
       "      <td>0.000115</td>\n",
       "      <td>-1.975670e-04</td>\n",
       "      <td>5.710110e-05</td>\n",
       "      <td>-0.000120</td>\n",
       "      <td>5.518170e-05</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>__word__value</td>\n",
       "      <td>-0.000078</td>\n",
       "      <td>7.626980e-05</td>\n",
       "      <td>0.000021</td>\n",
       "      <td>0.000135</td>\n",
       "      <td>-1.754790e-05</td>\n",
       "      <td>0.000067</td>\n",
       "      <td>-0.000001</td>\n",
       "      <td>-2.681780e-05</td>\n",
       "      <td>-0.000103</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000006</td>\n",
       "      <td>0.000008</td>\n",
       "      <td>-0.000229</td>\n",
       "      <td>-0.000058</td>\n",
       "      <td>0.000141</td>\n",
       "      <td>-0.000018</td>\n",
       "      <td>3.797800e-05</td>\n",
       "      <td>9.211330e-08</td>\n",
       "      <td>0.000021</td>\n",
       "      <td>-2.054590e-05</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>__word__currency</td>\n",
       "      <td>0.000039</td>\n",
       "      <td>-5.104700e-05</td>\n",
       "      <td>0.000061</td>\n",
       "      <td>0.000103</td>\n",
       "      <td>-1.194060e-04</td>\n",
       "      <td>-0.000181</td>\n",
       "      <td>-0.000058</td>\n",
       "      <td>-1.096660e-04</td>\n",
       "      <td>0.000050</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.000219</td>\n",
       "      <td>-0.000111</td>\n",
       "      <td>-0.000203</td>\n",
       "      <td>-0.000264</td>\n",
       "      <td>0.000147</td>\n",
       "      <td>0.000103</td>\n",
       "      <td>2.212090e-06</td>\n",
       "      <td>2.685890e-05</td>\n",
       "      <td>0.000101</td>\n",
       "      <td>-6.131520e-05</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>__word__many</td>\n",
       "      <td>-0.000031</td>\n",
       "      <td>-3.920700e-05</td>\n",
       "      <td>-0.000122</td>\n",
       "      <td>-0.000002</td>\n",
       "      <td>2.812940e-05</td>\n",
       "      <td>-0.000071</td>\n",
       "      <td>-0.000094</td>\n",
       "      <td>-1.046650e-04</td>\n",
       "      <td>0.000013</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000029</td>\n",
       "      <td>-0.000038</td>\n",
       "      <td>-0.000017</td>\n",
       "      <td>0.000002</td>\n",
       "      <td>0.000008</td>\n",
       "      <td>0.000070</td>\n",
       "      <td>-3.293670e-05</td>\n",
       "      <td>-3.160790e-05</td>\n",
       "      <td>0.000035</td>\n",
       "      <td>5.073330e-05</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>__word__long</td>\n",
       "      <td>0.000058</td>\n",
       "      <td>2.467870e-05</td>\n",
       "      <td>0.000169</td>\n",
       "      <td>-0.000088</td>\n",
       "      <td>4.845060e-05</td>\n",
       "      <td>0.000093</td>\n",
       "      <td>-0.000030</td>\n",
       "      <td>-3.372640e-05</td>\n",
       "      <td>0.000073</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.000041</td>\n",
       "      <td>-0.000030</td>\n",
       "      <td>0.000039</td>\n",
       "      <td>0.000075</td>\n",
       "      <td>0.000043</td>\n",
       "      <td>-0.000081</td>\n",
       "      <td>-1.465590e-04</td>\n",
       "      <td>-6.357790e-05</td>\n",
       "      <td>-0.000071</td>\n",
       "      <td>-1.378800e-05</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>__word__really</td>\n",
       "      <td>-0.000065</td>\n",
       "      <td>3.799370e-07</td>\n",
       "      <td>0.000027</td>\n",
       "      <td>-0.000165</td>\n",
       "      <td>2.802190e-05</td>\n",
       "      <td>0.000030</td>\n",
       "      <td>-0.000108</td>\n",
       "      <td>-7.411120e-06</td>\n",
       "      <td>-0.000041</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000047</td>\n",
       "      <td>0.000076</td>\n",
       "      <td>-0.000141</td>\n",
       "      <td>-0.000018</td>\n",
       "      <td>0.000027</td>\n",
       "      <td>-0.000045</td>\n",
       "      <td>1.114940e-04</td>\n",
       "      <td>-5.830420e-05</td>\n",
       "      <td>-0.000160</td>\n",
       "      <td>-4.967930e-05</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>78961</th>\n",
       "      <td>__word__fuckaling</td>\n",
       "      <td>0.000907</td>\n",
       "      <td>-2.620640e-03</td>\n",
       "      <td>0.000498</td>\n",
       "      <td>-0.001182</td>\n",
       "      <td>-2.168760e-03</td>\n",
       "      <td>-0.000510</td>\n",
       "      <td>-0.002193</td>\n",
       "      <td>1.836560e-03</td>\n",
       "      <td>0.002248</td>\n",
       "      <td>...</td>\n",
       "      <td>0.001063</td>\n",
       "      <td>0.001047</td>\n",
       "      <td>-0.002676</td>\n",
       "      <td>0.002291</td>\n",
       "      <td>-0.001325</td>\n",
       "      <td>0.000567</td>\n",
       "      <td>-7.991940e-05</td>\n",
       "      <td>6.953040e-04</td>\n",
       "      <td>0.000690</td>\n",
       "      <td>1.005080e-04</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>78962</th>\n",
       "      <td>__word__eople</td>\n",
       "      <td>-0.001287</td>\n",
       "      <td>1.048680e-03</td>\n",
       "      <td>-0.001665</td>\n",
       "      <td>-0.001390</td>\n",
       "      <td>-2.108740e-04</td>\n",
       "      <td>-0.001398</td>\n",
       "      <td>0.001089</td>\n",
       "      <td>1.231100e-03</td>\n",
       "      <td>-0.000035</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.000432</td>\n",
       "      <td>0.001909</td>\n",
       "      <td>-0.001453</td>\n",
       "      <td>-0.002717</td>\n",
       "      <td>-0.003381</td>\n",
       "      <td>-0.001546</td>\n",
       "      <td>2.753840e-04</td>\n",
       "      <td>-1.608610e-04</td>\n",
       "      <td>0.001295</td>\n",
       "      <td>-1.380220e-03</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>78963</th>\n",
       "      <td>__word__aoon</td>\n",
       "      <td>0.000510</td>\n",
       "      <td>4.815000e-04</td>\n",
       "      <td>0.000113</td>\n",
       "      <td>-0.000837</td>\n",
       "      <td>-1.127690e-03</td>\n",
       "      <td>0.002258</td>\n",
       "      <td>0.000324</td>\n",
       "      <td>-9.777360e-04</td>\n",
       "      <td>0.001104</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000950</td>\n",
       "      <td>-0.001155</td>\n",
       "      <td>-0.000083</td>\n",
       "      <td>-0.000600</td>\n",
       "      <td>-0.000359</td>\n",
       "      <td>0.000705</td>\n",
       "      <td>1.474880e-03</td>\n",
       "      <td>1.524700e-03</td>\n",
       "      <td>-0.000450</td>\n",
       "      <td>-1.085590e-03</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>78964</th>\n",
       "      <td>__word__stardate</td>\n",
       "      <td>-0.000558</td>\n",
       "      <td>-2.062710e-03</td>\n",
       "      <td>-0.001540</td>\n",
       "      <td>-0.001117</td>\n",
       "      <td>9.955040e-04</td>\n",
       "      <td>0.001450</td>\n",
       "      <td>-0.001055</td>\n",
       "      <td>1.824730e-03</td>\n",
       "      <td>0.002824</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.001912</td>\n",
       "      <td>-0.000733</td>\n",
       "      <td>-0.000808</td>\n",
       "      <td>0.002837</td>\n",
       "      <td>0.002194</td>\n",
       "      <td>0.003074</td>\n",
       "      <td>3.532140e-05</td>\n",
       "      <td>-1.245350e-03</td>\n",
       "      <td>-0.000844</td>\n",
       "      <td>-1.443350e-03</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>78965</th>\n",
       "      <td>__word__fatboy</td>\n",
       "      <td>-0.001363</td>\n",
       "      <td>-9.426400e-04</td>\n",
       "      <td>-0.000525</td>\n",
       "      <td>0.001969</td>\n",
       "      <td>-1.551090e-04</td>\n",
       "      <td>0.001986</td>\n",
       "      <td>-0.001082</td>\n",
       "      <td>5.994700e-04</td>\n",
       "      <td>-0.001049</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000813</td>\n",
       "      <td>0.000703</td>\n",
       "      <td>0.001040</td>\n",
       "      <td>0.000856</td>\n",
       "      <td>0.002484</td>\n",
       "      <td>0.004016</td>\n",
       "      <td>-3.046230e-05</td>\n",
       "      <td>-2.057460e-03</td>\n",
       "      <td>-0.000630</td>\n",
       "      <td>-2.503440e-03</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>78966</th>\n",
       "      <td>__word__nabob</td>\n",
       "      <td>-0.002292</td>\n",
       "      <td>-7.951020e-04</td>\n",
       "      <td>-0.001822</td>\n",
       "      <td>0.000040</td>\n",
       "      <td>1.390690e-03</td>\n",
       "      <td>0.000987</td>\n",
       "      <td>-0.003352</td>\n",
       "      <td>-9.738830e-05</td>\n",
       "      <td>0.000800</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000625</td>\n",
       "      <td>-0.001012</td>\n",
       "      <td>0.001441</td>\n",
       "      <td>0.000958</td>\n",
       "      <td>0.000333</td>\n",
       "      <td>0.002915</td>\n",
       "      <td>6.809090e-04</td>\n",
       "      <td>-2.607660e-03</td>\n",
       "      <td>0.000948</td>\n",
       "      <td>-5.024280e-03</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>78967</th>\n",
       "      <td>__word__bjp</td>\n",
       "      <td>-0.000667</td>\n",
       "      <td>-1.633440e-03</td>\n",
       "      <td>-0.002409</td>\n",
       "      <td>0.000931</td>\n",
       "      <td>5.747870e-04</td>\n",
       "      <td>0.000407</td>\n",
       "      <td>-0.000794</td>\n",
       "      <td>-1.224550e-03</td>\n",
       "      <td>0.001605</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000386</td>\n",
       "      <td>-0.000648</td>\n",
       "      <td>0.001867</td>\n",
       "      <td>0.003074</td>\n",
       "      <td>0.002686</td>\n",
       "      <td>0.002670</td>\n",
       "      <td>6.179370e-04</td>\n",
       "      <td>-2.472540e-03</td>\n",
       "      <td>0.002468</td>\n",
       "      <td>-3.443540e-03</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>78968</th>\n",
       "      <td>__word__eedddbabeeefadfddbcccbe</td>\n",
       "      <td>-0.000426</td>\n",
       "      <td>1.016100e-04</td>\n",
       "      <td>0.001010</td>\n",
       "      <td>-0.001327</td>\n",
       "      <td>-1.590300e-04</td>\n",
       "      <td>-0.001064</td>\n",
       "      <td>-0.000947</td>\n",
       "      <td>-4.533870e-04</td>\n",
       "      <td>-0.000355</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.001863</td>\n",
       "      <td>0.000017</td>\n",
       "      <td>-0.001914</td>\n",
       "      <td>0.002784</td>\n",
       "      <td>-0.002119</td>\n",
       "      <td>0.000304</td>\n",
       "      <td>1.732900e-03</td>\n",
       "      <td>-2.225020e-03</td>\n",
       "      <td>-0.000647</td>\n",
       "      <td>-1.470310e-03</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>78969</th>\n",
       "      <td>__word__cqkby</td>\n",
       "      <td>0.000231</td>\n",
       "      <td>4.224240e-05</td>\n",
       "      <td>0.000275</td>\n",
       "      <td>-0.001691</td>\n",
       "      <td>1.667710e-03</td>\n",
       "      <td>-0.003467</td>\n",
       "      <td>0.001803</td>\n",
       "      <td>-1.431730e-03</td>\n",
       "      <td>-0.000203</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000938</td>\n",
       "      <td>-0.003094</td>\n",
       "      <td>-0.002979</td>\n",
       "      <td>0.000290</td>\n",
       "      <td>-0.000513</td>\n",
       "      <td>0.000729</td>\n",
       "      <td>-4.302520e-04</td>\n",
       "      <td>-1.313020e-04</td>\n",
       "      <td>0.000474</td>\n",
       "      <td>7.231630e-04</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>78970</th>\n",
       "      <td>__word__huhh</td>\n",
       "      <td>0.000083</td>\n",
       "      <td>-3.858930e-04</td>\n",
       "      <td>-0.001691</td>\n",
       "      <td>-0.000520</td>\n",
       "      <td>-6.876020e-04</td>\n",
       "      <td>-0.002378</td>\n",
       "      <td>-0.000701</td>\n",
       "      <td>-2.563880e-03</td>\n",
       "      <td>-0.002059</td>\n",
       "      <td>...</td>\n",
       "      <td>0.001561</td>\n",
       "      <td>0.000033</td>\n",
       "      <td>0.000586</td>\n",
       "      <td>-0.000801</td>\n",
       "      <td>0.001175</td>\n",
       "      <td>-0.001148</td>\n",
       "      <td>-1.221400e-03</td>\n",
       "      <td>-2.093840e-04</td>\n",
       "      <td>-0.004070</td>\n",
       "      <td>-1.077560e-03</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>78971</th>\n",
       "      <td>__word__significantl</td>\n",
       "      <td>0.002670</td>\n",
       "      <td>-1.905960e-03</td>\n",
       "      <td>0.000973</td>\n",
       "      <td>0.000531</td>\n",
       "      <td>9.084450e-04</td>\n",
       "      <td>0.001215</td>\n",
       "      <td>-0.001860</td>\n",
       "      <td>1.333330e-03</td>\n",
       "      <td>0.000463</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000028</td>\n",
       "      <td>0.000361</td>\n",
       "      <td>-0.000452</td>\n",
       "      <td>0.001392</td>\n",
       "      <td>0.000973</td>\n",
       "      <td>-0.000217</td>\n",
       "      <td>9.564120e-04</td>\n",
       "      <td>1.875080e-03</td>\n",
       "      <td>-0.001768</td>\n",
       "      <td>-2.778280e-03</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>78972</th>\n",
       "      <td>__word__viant</td>\n",
       "      <td>-0.001340</td>\n",
       "      <td>-3.159160e-03</td>\n",
       "      <td>0.002478</td>\n",
       "      <td>-0.000299</td>\n",
       "      <td>1.237350e-03</td>\n",
       "      <td>0.000834</td>\n",
       "      <td>0.000047</td>\n",
       "      <td>-1.586510e-03</td>\n",
       "      <td>0.001988</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.001355</td>\n",
       "      <td>0.001303</td>\n",
       "      <td>-0.004386</td>\n",
       "      <td>-0.000741</td>\n",
       "      <td>-0.000873</td>\n",
       "      <td>-0.000412</td>\n",
       "      <td>-1.079340e-03</td>\n",
       "      <td>-1.037770e-03</td>\n",
       "      <td>-0.002255</td>\n",
       "      <td>-1.567260e-03</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>78973</th>\n",
       "      <td>__word__faull</td>\n",
       "      <td>0.000349</td>\n",
       "      <td>-1.992730e-03</td>\n",
       "      <td>0.000649</td>\n",
       "      <td>-0.001585</td>\n",
       "      <td>-1.357520e-03</td>\n",
       "      <td>-0.000219</td>\n",
       "      <td>-0.001246</td>\n",
       "      <td>-1.767200e-03</td>\n",
       "      <td>0.001626</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.001054</td>\n",
       "      <td>-0.001224</td>\n",
       "      <td>-0.002171</td>\n",
       "      <td>0.001704</td>\n",
       "      <td>-0.000417</td>\n",
       "      <td>0.002698</td>\n",
       "      <td>-9.265140e-04</td>\n",
       "      <td>-2.299090e-04</td>\n",
       "      <td>-0.001519</td>\n",
       "      <td>-7.929800e-04</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>78974</th>\n",
       "      <td>__word__strengthing</td>\n",
       "      <td>0.001906</td>\n",
       "      <td>-1.644840e-03</td>\n",
       "      <td>0.002119</td>\n",
       "      <td>-0.000566</td>\n",
       "      <td>-2.000040e-04</td>\n",
       "      <td>0.000472</td>\n",
       "      <td>0.000382</td>\n",
       "      <td>1.723080e-04</td>\n",
       "      <td>-0.002437</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.002486</td>\n",
       "      <td>-0.001053</td>\n",
       "      <td>0.001422</td>\n",
       "      <td>0.000872</td>\n",
       "      <td>0.001521</td>\n",
       "      <td>0.000900</td>\n",
       "      <td>2.477130e-03</td>\n",
       "      <td>-5.135250e-05</td>\n",
       "      <td>-0.000675</td>\n",
       "      <td>-1.663800e-03</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>78975</th>\n",
       "      <td>__word__buybitcoin</td>\n",
       "      <td>0.001752</td>\n",
       "      <td>2.305100e-03</td>\n",
       "      <td>-0.000603</td>\n",
       "      <td>-0.001633</td>\n",
       "      <td>5.395210e-04</td>\n",
       "      <td>-0.001625</td>\n",
       "      <td>-0.001842</td>\n",
       "      <td>1.156650e-03</td>\n",
       "      <td>0.000322</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000562</td>\n",
       "      <td>-0.000322</td>\n",
       "      <td>-0.003280</td>\n",
       "      <td>0.002624</td>\n",
       "      <td>0.000044</td>\n",
       "      <td>0.000934</td>\n",
       "      <td>-2.825110e-04</td>\n",
       "      <td>1.912130e-04</td>\n",
       "      <td>-0.001442</td>\n",
       "      <td>1.166860e-03</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>78976</th>\n",
       "      <td>__word__netqk</td>\n",
       "      <td>0.000013</td>\n",
       "      <td>1.526940e-03</td>\n",
       "      <td>-0.000789</td>\n",
       "      <td>-0.000559</td>\n",
       "      <td>6.881080e-04</td>\n",
       "      <td>-0.000556</td>\n",
       "      <td>-0.000924</td>\n",
       "      <td>6.732900e-04</td>\n",
       "      <td>-0.001681</td>\n",
       "      <td>...</td>\n",
       "      <td>0.001229</td>\n",
       "      <td>-0.000499</td>\n",
       "      <td>-0.000255</td>\n",
       "      <td>-0.000138</td>\n",
       "      <td>0.001192</td>\n",
       "      <td>0.000239</td>\n",
       "      <td>-1.363180e-03</td>\n",
       "      <td>-1.091070e-03</td>\n",
       "      <td>0.001180</td>\n",
       "      <td>2.802170e-05</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>78977</th>\n",
       "      <td>__word__jammalan</td>\n",
       "      <td>-0.002422</td>\n",
       "      <td>1.973180e-03</td>\n",
       "      <td>-0.000510</td>\n",
       "      <td>-0.000935</td>\n",
       "      <td>1.145050e-03</td>\n",
       "      <td>-0.001999</td>\n",
       "      <td>0.001057</td>\n",
       "      <td>-7.002450e-04</td>\n",
       "      <td>0.002785</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000937</td>\n",
       "      <td>-0.001023</td>\n",
       "      <td>-0.002352</td>\n",
       "      <td>-0.000746</td>\n",
       "      <td>-0.000004</td>\n",
       "      <td>-0.002133</td>\n",
       "      <td>-1.206440e-03</td>\n",
       "      <td>-2.821130e-04</td>\n",
       "      <td>-0.001127</td>\n",
       "      <td>-1.360350e-04</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>78978</th>\n",
       "      <td>__word__touristing</td>\n",
       "      <td>-0.001092</td>\n",
       "      <td>2.200600e-03</td>\n",
       "      <td>-0.000692</td>\n",
       "      <td>-0.001479</td>\n",
       "      <td>9.945140e-04</td>\n",
       "      <td>0.000429</td>\n",
       "      <td>-0.003104</td>\n",
       "      <td>-1.664580e-03</td>\n",
       "      <td>-0.001810</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000604</td>\n",
       "      <td>-0.000505</td>\n",
       "      <td>-0.001069</td>\n",
       "      <td>-0.000977</td>\n",
       "      <td>0.000939</td>\n",
       "      <td>0.000814</td>\n",
       "      <td>-2.789180e-03</td>\n",
       "      <td>-1.972160e-03</td>\n",
       "      <td>-0.001505</td>\n",
       "      <td>-5.836550e-04</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>78979</th>\n",
       "      <td>__word__wxngrrjhelu</td>\n",
       "      <td>-0.000054</td>\n",
       "      <td>1.573170e-03</td>\n",
       "      <td>-0.000255</td>\n",
       "      <td>0.000714</td>\n",
       "      <td>-2.026220e-03</td>\n",
       "      <td>-0.000138</td>\n",
       "      <td>-0.001334</td>\n",
       "      <td>-2.687830e-05</td>\n",
       "      <td>0.000177</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.000774</td>\n",
       "      <td>0.000895</td>\n",
       "      <td>0.000424</td>\n",
       "      <td>-0.001245</td>\n",
       "      <td>-0.001289</td>\n",
       "      <td>-0.000539</td>\n",
       "      <td>-1.497370e-03</td>\n",
       "      <td>-1.036310e-03</td>\n",
       "      <td>-0.001056</td>\n",
       "      <td>-9.411020e-04</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>78980</th>\n",
       "      <td>__word__woooaaa</td>\n",
       "      <td>0.001943</td>\n",
       "      <td>-6.098240e-04</td>\n",
       "      <td>0.001454</td>\n",
       "      <td>-0.000369</td>\n",
       "      <td>2.648760e-03</td>\n",
       "      <td>-0.000970</td>\n",
       "      <td>0.001354</td>\n",
       "      <td>-5.739110e-04</td>\n",
       "      <td>-0.000659</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.002499</td>\n",
       "      <td>-0.001729</td>\n",
       "      <td>0.001013</td>\n",
       "      <td>-0.002637</td>\n",
       "      <td>0.000772</td>\n",
       "      <td>-0.001054</td>\n",
       "      <td>9.044390e-04</td>\n",
       "      <td>-2.354210e-04</td>\n",
       "      <td>-0.001018</td>\n",
       "      <td>-3.219100e-04</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>78981</th>\n",
       "      <td>__word__bles</td>\n",
       "      <td>0.000144</td>\n",
       "      <td>1.040230e-03</td>\n",
       "      <td>-0.001060</td>\n",
       "      <td>-0.002453</td>\n",
       "      <td>-8.893930e-04</td>\n",
       "      <td>-0.001766</td>\n",
       "      <td>0.002186</td>\n",
       "      <td>5.628800e-05</td>\n",
       "      <td>-0.001417</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000260</td>\n",
       "      <td>-0.000540</td>\n",
       "      <td>0.000656</td>\n",
       "      <td>-0.001577</td>\n",
       "      <td>-0.003603</td>\n",
       "      <td>0.000579</td>\n",
       "      <td>-1.140140e-03</td>\n",
       "      <td>1.910580e-03</td>\n",
       "      <td>0.000487</td>\n",
       "      <td>5.976540e-04</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>78982</th>\n",
       "      <td>__word__dickeater</td>\n",
       "      <td>-0.001418</td>\n",
       "      <td>1.613910e-03</td>\n",
       "      <td>0.001252</td>\n",
       "      <td>0.000707</td>\n",
       "      <td>-1.188980e-03</td>\n",
       "      <td>-0.001594</td>\n",
       "      <td>-0.001036</td>\n",
       "      <td>-4.906060e-05</td>\n",
       "      <td>-0.002260</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.001401</td>\n",
       "      <td>-0.001132</td>\n",
       "      <td>-0.002322</td>\n",
       "      <td>0.002753</td>\n",
       "      <td>0.002409</td>\n",
       "      <td>-0.001146</td>\n",
       "      <td>-3.656990e-04</td>\n",
       "      <td>-4.297690e-04</td>\n",
       "      <td>-0.001808</td>\n",
       "      <td>4.614080e-04</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>78983</th>\n",
       "      <td>__word__mvpmbq</td>\n",
       "      <td>-0.000185</td>\n",
       "      <td>3.572710e-04</td>\n",
       "      <td>-0.000071</td>\n",
       "      <td>-0.000033</td>\n",
       "      <td>-1.749650e-03</td>\n",
       "      <td>0.000436</td>\n",
       "      <td>-0.000169</td>\n",
       "      <td>2.765820e-04</td>\n",
       "      <td>0.002027</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.000351</td>\n",
       "      <td>-0.001194</td>\n",
       "      <td>-0.002549</td>\n",
       "      <td>0.000951</td>\n",
       "      <td>-0.004459</td>\n",
       "      <td>-0.002380</td>\n",
       "      <td>2.801240e-03</td>\n",
       "      <td>2.349990e-05</td>\n",
       "      <td>0.000378</td>\n",
       "      <td>-2.223390e-03</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>78984</th>\n",
       "      <td>__word__segwitshit</td>\n",
       "      <td>0.000544</td>\n",
       "      <td>-1.371230e-03</td>\n",
       "      <td>0.001933</td>\n",
       "      <td>0.002346</td>\n",
       "      <td>-1.738810e-03</td>\n",
       "      <td>-0.002046</td>\n",
       "      <td>0.002466</td>\n",
       "      <td>-1.147520e-03</td>\n",
       "      <td>-0.002247</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.000538</td>\n",
       "      <td>-0.002259</td>\n",
       "      <td>0.000246</td>\n",
       "      <td>0.001422</td>\n",
       "      <td>-0.002065</td>\n",
       "      <td>0.002164</td>\n",
       "      <td>-1.401510e-04</td>\n",
       "      <td>2.481260e-03</td>\n",
       "      <td>-0.000318</td>\n",
       "      <td>-1.579690e-03</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>78985</th>\n",
       "      <td>__word__pseudosolution</td>\n",
       "      <td>0.002385</td>\n",
       "      <td>-1.901810e-04</td>\n",
       "      <td>0.001685</td>\n",
       "      <td>0.002422</td>\n",
       "      <td>-3.860420e-04</td>\n",
       "      <td>-0.001809</td>\n",
       "      <td>0.001462</td>\n",
       "      <td>-3.688650e-03</td>\n",
       "      <td>-0.002483</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.000816</td>\n",
       "      <td>-0.002545</td>\n",
       "      <td>0.000971</td>\n",
       "      <td>0.003027</td>\n",
       "      <td>-0.001891</td>\n",
       "      <td>0.002263</td>\n",
       "      <td>-2.271970e-03</td>\n",
       "      <td>1.656410e-03</td>\n",
       "      <td>-0.001163</td>\n",
       "      <td>-2.956470e-03</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>78986</th>\n",
       "      <td>__word__gmn</td>\n",
       "      <td>-0.001890</td>\n",
       "      <td>5.482230e-04</td>\n",
       "      <td>0.001661</td>\n",
       "      <td>-0.000097</td>\n",
       "      <td>-1.437860e-03</td>\n",
       "      <td>-0.000999</td>\n",
       "      <td>-0.000371</td>\n",
       "      <td>4.123920e-04</td>\n",
       "      <td>-0.001373</td>\n",
       "      <td>...</td>\n",
       "      <td>0.004555</td>\n",
       "      <td>0.000049</td>\n",
       "      <td>0.000006</td>\n",
       "      <td>0.002189</td>\n",
       "      <td>-0.002355</td>\n",
       "      <td>-0.000678</td>\n",
       "      <td>2.456270e-03</td>\n",
       "      <td>-1.055290e-03</td>\n",
       "      <td>-0.000333</td>\n",
       "      <td>4.490640e-04</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>78987</th>\n",
       "      <td>__word__bqrxqq</td>\n",
       "      <td>-0.002729</td>\n",
       "      <td>1.984420e-04</td>\n",
       "      <td>-0.000281</td>\n",
       "      <td>0.001552</td>\n",
       "      <td>-9.748660e-04</td>\n",
       "      <td>0.000185</td>\n",
       "      <td>-0.001724</td>\n",
       "      <td>-2.079110e-03</td>\n",
       "      <td>-0.001042</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000048</td>\n",
       "      <td>-0.002144</td>\n",
       "      <td>0.000450</td>\n",
       "      <td>-0.001110</td>\n",
       "      <td>-0.002782</td>\n",
       "      <td>0.000808</td>\n",
       "      <td>-1.376350e-03</td>\n",
       "      <td>5.834340e-04</td>\n",
       "      <td>0.000033</td>\n",
       "      <td>2.126130e-03</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>78988</th>\n",
       "      <td>__word__nocoinersbtfoo</td>\n",
       "      <td>-0.002117</td>\n",
       "      <td>-4.120080e-03</td>\n",
       "      <td>-0.000378</td>\n",
       "      <td>0.001199</td>\n",
       "      <td>-1.104440e-05</td>\n",
       "      <td>-0.001101</td>\n",
       "      <td>0.000285</td>\n",
       "      <td>-6.928000e-04</td>\n",
       "      <td>-0.000447</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.000816</td>\n",
       "      <td>-0.000147</td>\n",
       "      <td>0.000659</td>\n",
       "      <td>0.001360</td>\n",
       "      <td>0.000485</td>\n",
       "      <td>-0.001595</td>\n",
       "      <td>-6.368150e-04</td>\n",
       "      <td>-3.036520e-04</td>\n",
       "      <td>0.000391</td>\n",
       "      <td>4.633280e-03</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>78989</th>\n",
       "      <td>__word__wcasy</td>\n",
       "      <td>-0.000874</td>\n",
       "      <td>-5.617070e-04</td>\n",
       "      <td>0.002005</td>\n",
       "      <td>0.001123</td>\n",
       "      <td>-1.120120e-04</td>\n",
       "      <td>-0.001738</td>\n",
       "      <td>-0.000820</td>\n",
       "      <td>1.784230e-03</td>\n",
       "      <td>-0.003275</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.000115</td>\n",
       "      <td>-0.001132</td>\n",
       "      <td>-0.002303</td>\n",
       "      <td>-0.000020</td>\n",
       "      <td>-0.001237</td>\n",
       "      <td>-0.000496</td>\n",
       "      <td>8.010320e-04</td>\n",
       "      <td>-1.125800e-03</td>\n",
       "      <td>0.000569</td>\n",
       "      <td>-2.823520e-03</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>78990</th>\n",
       "      <td>__word__dippening</td>\n",
       "      <td>-0.000080</td>\n",
       "      <td>-2.211080e-03</td>\n",
       "      <td>-0.000238</td>\n",
       "      <td>-0.001184</td>\n",
       "      <td>-8.126880e-04</td>\n",
       "      <td>0.000314</td>\n",
       "      <td>-0.004313</td>\n",
       "      <td>6.895810e-04</td>\n",
       "      <td>0.000910</td>\n",
       "      <td>...</td>\n",
       "      <td>0.001923</td>\n",
       "      <td>0.001714</td>\n",
       "      <td>-0.000897</td>\n",
       "      <td>0.001333</td>\n",
       "      <td>-0.001341</td>\n",
       "      <td>0.001248</td>\n",
       "      <td>-2.494900e-04</td>\n",
       "      <td>1.547960e-03</td>\n",
       "      <td>0.001972</td>\n",
       "      <td>7.585590e-05</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>78991 rows  51 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                    0         1             2         3   \\\n",
       "0                                  NaN  0.000891  2.306850e-04 -0.002487   \n",
       "1                        __word__price  0.000006  2.973840e-06  0.000004   \n",
       "2                           __word__go  0.000026 -4.015650e-06  0.000006   \n",
       "3                       __word__people -0.000029  1.171530e-05 -0.000140   \n",
       "4                         __word__time  0.000044 -4.201780e-05  0.000069   \n",
       "5                         __word__rise -0.000032 -1.503780e-05 -0.000033   \n",
       "6                          __word__buy  0.000104 -6.503720e-05  0.000020   \n",
       "7                         __word__good -0.000022 -1.697910e-05  0.000031   \n",
       "8                         __word__year  0.000040 -4.497130e-05  0.000001   \n",
       "9                          __word__see -0.000040  3.179700e-07  0.000015   \n",
       "10                      __word__market -0.000082 -8.552860e-05 -0.000013   \n",
       "11                        __word__make  0.000003 -8.568250e-06 -0.000011   \n",
       "12                      __word__happen -0.000008  4.278960e-05 -0.000029   \n",
       "13                        __word__like  0.000020 -7.956410e-06 -0.000041   \n",
       "14                       __word__money  0.000025 -5.086750e-05 -0.000171   \n",
       "15                        __word__know -0.000027 -6.000350e-06 -0.000048   \n",
       "16                         __word__one -0.000005 -7.904870e-05 -0.000005   \n",
       "17                        __word__sell  0.000104 -1.669280e-05 -0.000024   \n",
       "18                        __word__high  0.000035 -2.978150e-05  0.000031   \n",
       "19                     __word__bitcoin  0.000340  1.934590e-04  0.000168   \n",
       "20                        __word__even  0.000052  2.802450e-05 -0.000031   \n",
       "21                       __word__still -0.000009 -3.306890e-05 -0.000045   \n",
       "22                        __word__also -0.000039  3.451810e-05 -0.000088   \n",
       "23                         __word__don -0.000072  8.575820e-05 -0.000050   \n",
       "24                        __word__coin -0.000116 -3.001440e-04  0.000009   \n",
       "25                       __word__value -0.000078  7.626980e-05  0.000021   \n",
       "26                    __word__currency  0.000039 -5.104700e-05  0.000061   \n",
       "27                        __word__many -0.000031 -3.920700e-05 -0.000122   \n",
       "28                        __word__long  0.000058  2.467870e-05  0.000169   \n",
       "29                      __word__really -0.000065  3.799370e-07  0.000027   \n",
       "...                                ...       ...           ...       ...   \n",
       "78961                __word__fuckaling  0.000907 -2.620640e-03  0.000498   \n",
       "78962                    __word__eople -0.001287  1.048680e-03 -0.001665   \n",
       "78963                     __word__aoon  0.000510  4.815000e-04  0.000113   \n",
       "78964                 __word__stardate -0.000558 -2.062710e-03 -0.001540   \n",
       "78965                   __word__fatboy -0.001363 -9.426400e-04 -0.000525   \n",
       "78966                    __word__nabob -0.002292 -7.951020e-04 -0.001822   \n",
       "78967                      __word__bjp -0.000667 -1.633440e-03 -0.002409   \n",
       "78968  __word__eedddbabeeefadfddbcccbe -0.000426  1.016100e-04  0.001010   \n",
       "78969                    __word__cqkby  0.000231  4.224240e-05  0.000275   \n",
       "78970                     __word__huhh  0.000083 -3.858930e-04 -0.001691   \n",
       "78971             __word__significantl  0.002670 -1.905960e-03  0.000973   \n",
       "78972                    __word__viant -0.001340 -3.159160e-03  0.002478   \n",
       "78973                    __word__faull  0.000349 -1.992730e-03  0.000649   \n",
       "78974              __word__strengthing  0.001906 -1.644840e-03  0.002119   \n",
       "78975               __word__buybitcoin  0.001752  2.305100e-03 -0.000603   \n",
       "78976                    __word__netqk  0.000013  1.526940e-03 -0.000789   \n",
       "78977                 __word__jammalan -0.002422  1.973180e-03 -0.000510   \n",
       "78978               __word__touristing -0.001092  2.200600e-03 -0.000692   \n",
       "78979              __word__wxngrrjhelu -0.000054  1.573170e-03 -0.000255   \n",
       "78980                  __word__woooaaa  0.001943 -6.098240e-04  0.001454   \n",
       "78981                     __word__bles  0.000144  1.040230e-03 -0.001060   \n",
       "78982                __word__dickeater -0.001418  1.613910e-03  0.001252   \n",
       "78983                   __word__mvpmbq -0.000185  3.572710e-04 -0.000071   \n",
       "78984               __word__segwitshit  0.000544 -1.371230e-03  0.001933   \n",
       "78985           __word__pseudosolution  0.002385 -1.901810e-04  0.001685   \n",
       "78986                      __word__gmn -0.001890  5.482230e-04  0.001661   \n",
       "78987                   __word__bqrxqq -0.002729  1.984420e-04 -0.000281   \n",
       "78988           __word__nocoinersbtfoo -0.002117 -4.120080e-03 -0.000378   \n",
       "78989                    __word__wcasy -0.000874 -5.617070e-04  0.002005   \n",
       "78990                __word__dippening -0.000080 -2.211080e-03 -0.000238   \n",
       "\n",
       "             4             5         6         7             8         9   \\\n",
       "0      0.000365  8.903410e-04 -0.000867  0.000126 -8.548350e-04  0.001290   \n",
       "1     -0.000031  2.896700e-05 -0.000038  0.000014  4.506230e-07 -0.000032   \n",
       "2     -0.000084 -6.160200e-06  0.000005  0.000058 -4.459280e-05  0.000004   \n",
       "3     -0.000021 -1.690560e-05 -0.000029 -0.000035 -1.161040e-04 -0.000003   \n",
       "4     -0.000026 -3.616490e-05  0.000025 -0.000018 -2.569730e-05 -0.000017   \n",
       "5     -0.000011  7.164010e-05 -0.000066  0.000035  1.904780e-07 -0.000034   \n",
       "6     -0.000063 -3.680070e-05 -0.000003  0.000063 -9.256760e-05 -0.000058   \n",
       "7     -0.000017 -5.420950e-06 -0.000010 -0.000028 -6.218520e-05 -0.000002   \n",
       "8      0.000034  9.840050e-05  0.000023 -0.000077  2.076430e-05 -0.000013   \n",
       "9     -0.000011  2.281250e-05 -0.000005 -0.000014 -5.124530e-05  0.000012   \n",
       "10    -0.000074 -1.088330e-04  0.000011  0.000052 -1.135720e-05  0.000054   \n",
       "11    -0.000008 -5.899240e-05 -0.000035 -0.000081 -5.015670e-05  0.000019   \n",
       "12     0.000001  1.716380e-05  0.000020 -0.000018 -7.456680e-05 -0.000039   \n",
       "13     0.000038  2.103190e-05 -0.000008 -0.000026 -1.196680e-04  0.000025   \n",
       "14     0.000090 -1.015540e-04  0.000067 -0.000043 -1.142120e-04  0.000167   \n",
       "15    -0.000117 -4.460470e-05  0.000102  0.000013 -2.935990e-05 -0.000004   \n",
       "16    -0.000025  2.324080e-05  0.000023 -0.000013 -6.081730e-05 -0.000033   \n",
       "17    -0.000040 -4.551940e-05  0.000040  0.000044 -3.047290e-05 -0.000168   \n",
       "18    -0.000062 -9.969450e-07  0.000013 -0.000023 -1.119710e-05 -0.000054   \n",
       "19    -0.000110  4.661170e-05  0.000021  0.000046 -2.217640e-04  0.000019   \n",
       "20    -0.000049  2.240520e-05  0.000052 -0.000032  2.252010e-05  0.000014   \n",
       "21    -0.000173  4.552790e-05 -0.000005 -0.000037  5.556940e-05  0.000022   \n",
       "22     0.000075 -2.887120e-05 -0.000037 -0.000063 -6.824580e-05 -0.000010   \n",
       "23    -0.000084 -1.258500e-05  0.000225  0.000084 -7.119820e-05 -0.000055   \n",
       "24     0.000093 -7.908060e-05 -0.000014 -0.000017 -1.419140e-04 -0.000213   \n",
       "25     0.000135 -1.754790e-05  0.000067 -0.000001 -2.681780e-05 -0.000103   \n",
       "26     0.000103 -1.194060e-04 -0.000181 -0.000058 -1.096660e-04  0.000050   \n",
       "27    -0.000002  2.812940e-05 -0.000071 -0.000094 -1.046650e-04  0.000013   \n",
       "28    -0.000088  4.845060e-05  0.000093 -0.000030 -3.372640e-05  0.000073   \n",
       "29    -0.000165  2.802190e-05  0.000030 -0.000108 -7.411120e-06 -0.000041   \n",
       "...         ...           ...       ...       ...           ...       ...   \n",
       "78961 -0.001182 -2.168760e-03 -0.000510 -0.002193  1.836560e-03  0.002248   \n",
       "78962 -0.001390 -2.108740e-04 -0.001398  0.001089  1.231100e-03 -0.000035   \n",
       "78963 -0.000837 -1.127690e-03  0.002258  0.000324 -9.777360e-04  0.001104   \n",
       "78964 -0.001117  9.955040e-04  0.001450 -0.001055  1.824730e-03  0.002824   \n",
       "78965  0.001969 -1.551090e-04  0.001986 -0.001082  5.994700e-04 -0.001049   \n",
       "78966  0.000040  1.390690e-03  0.000987 -0.003352 -9.738830e-05  0.000800   \n",
       "78967  0.000931  5.747870e-04  0.000407 -0.000794 -1.224550e-03  0.001605   \n",
       "78968 -0.001327 -1.590300e-04 -0.001064 -0.000947 -4.533870e-04 -0.000355   \n",
       "78969 -0.001691  1.667710e-03 -0.003467  0.001803 -1.431730e-03 -0.000203   \n",
       "78970 -0.000520 -6.876020e-04 -0.002378 -0.000701 -2.563880e-03 -0.002059   \n",
       "78971  0.000531  9.084450e-04  0.001215 -0.001860  1.333330e-03  0.000463   \n",
       "78972 -0.000299  1.237350e-03  0.000834  0.000047 -1.586510e-03  0.001988   \n",
       "78973 -0.001585 -1.357520e-03 -0.000219 -0.001246 -1.767200e-03  0.001626   \n",
       "78974 -0.000566 -2.000040e-04  0.000472  0.000382  1.723080e-04 -0.002437   \n",
       "78975 -0.001633  5.395210e-04 -0.001625 -0.001842  1.156650e-03  0.000322   \n",
       "78976 -0.000559  6.881080e-04 -0.000556 -0.000924  6.732900e-04 -0.001681   \n",
       "78977 -0.000935  1.145050e-03 -0.001999  0.001057 -7.002450e-04  0.002785   \n",
       "78978 -0.001479  9.945140e-04  0.000429 -0.003104 -1.664580e-03 -0.001810   \n",
       "78979  0.000714 -2.026220e-03 -0.000138 -0.001334 -2.687830e-05  0.000177   \n",
       "78980 -0.000369  2.648760e-03 -0.000970  0.001354 -5.739110e-04 -0.000659   \n",
       "78981 -0.002453 -8.893930e-04 -0.001766  0.002186  5.628800e-05 -0.001417   \n",
       "78982  0.000707 -1.188980e-03 -0.001594 -0.001036 -4.906060e-05 -0.002260   \n",
       "78983 -0.000033 -1.749650e-03  0.000436 -0.000169  2.765820e-04  0.002027   \n",
       "78984  0.002346 -1.738810e-03 -0.002046  0.002466 -1.147520e-03 -0.002247   \n",
       "78985  0.002422 -3.860420e-04 -0.001809  0.001462 -3.688650e-03 -0.002483   \n",
       "78986 -0.000097 -1.437860e-03 -0.000999 -0.000371  4.123920e-04 -0.001373   \n",
       "78987  0.001552 -9.748660e-04  0.000185 -0.001724 -2.079110e-03 -0.001042   \n",
       "78988  0.001199 -1.104440e-05 -0.001101  0.000285 -6.928000e-04 -0.000447   \n",
       "78989  0.001123 -1.120120e-04 -0.001738 -0.000820  1.784230e-03 -0.003275   \n",
       "78990 -0.001184 -8.126880e-04  0.000314 -0.004313  6.895810e-04  0.000910   \n",
       "\n",
       "           ...             41        42        43        44        45  \\\n",
       "0          ...      -0.000868  0.001118 -0.002038 -0.001416 -0.001188   \n",
       "1          ...      -0.000008 -0.000016 -0.000029  0.000015 -0.000010   \n",
       "2          ...       0.000023  0.000007 -0.000041 -0.000026  0.000058   \n",
       "3          ...       0.000027 -0.000037  0.000019 -0.000025  0.000066   \n",
       "4          ...      -0.000020 -0.000019  0.000005  0.000014  0.000015   \n",
       "5          ...       0.000007 -0.000003 -0.000060  0.000041  0.000021   \n",
       "6          ...      -0.000046 -0.000039  0.000052 -0.000032 -0.000095   \n",
       "7          ...       0.000003  0.000041 -0.000017 -0.000033  0.000029   \n",
       "8          ...      -0.000104  0.000027 -0.000029  0.000065  0.000015   \n",
       "9          ...       0.000015  0.000055 -0.000024  0.000062  0.000034   \n",
       "10         ...      -0.000022 -0.000116 -0.000045  0.000032 -0.000027   \n",
       "11         ...      -0.000017 -0.000022 -0.000016  0.000015  0.000015   \n",
       "12         ...       0.000013  0.000090 -0.000055  0.000036  0.000025   \n",
       "13         ...       0.000058  0.000046 -0.000017 -0.000021  0.000014   \n",
       "14         ...      -0.000056 -0.000143 -0.000014 -0.000023  0.000016   \n",
       "15         ...       0.000030  0.000024 -0.000043 -0.000072  0.000014   \n",
       "16         ...       0.000007 -0.000018  0.000006 -0.000023 -0.000019   \n",
       "17         ...       0.000009 -0.000079  0.000041  0.000018 -0.000085   \n",
       "18         ...      -0.000042 -0.000091 -0.000074 -0.000040  0.000048   \n",
       "19         ...       0.000127  0.000204  0.000014  0.000213 -0.000087   \n",
       "20         ...      -0.000043  0.000038 -0.000024  0.000019  0.000015   \n",
       "21         ...      -0.000132  0.000042  0.000033  0.000040 -0.000026   \n",
       "22         ...       0.000054  0.000029 -0.000027 -0.000030  0.000046   \n",
       "23         ...      -0.000035  0.000058  0.000005  0.000043  0.000010   \n",
       "24         ...       0.000097 -0.000078  0.000076 -0.000015 -0.000086   \n",
       "25         ...       0.000006  0.000008 -0.000229 -0.000058  0.000141   \n",
       "26         ...      -0.000219 -0.000111 -0.000203 -0.000264  0.000147   \n",
       "27         ...       0.000029 -0.000038 -0.000017  0.000002  0.000008   \n",
       "28         ...      -0.000041 -0.000030  0.000039  0.000075  0.000043   \n",
       "29         ...       0.000047  0.000076 -0.000141 -0.000018  0.000027   \n",
       "...        ...            ...       ...       ...       ...       ...   \n",
       "78961      ...       0.001063  0.001047 -0.002676  0.002291 -0.001325   \n",
       "78962      ...      -0.000432  0.001909 -0.001453 -0.002717 -0.003381   \n",
       "78963      ...       0.000950 -0.001155 -0.000083 -0.000600 -0.000359   \n",
       "78964      ...      -0.001912 -0.000733 -0.000808  0.002837  0.002194   \n",
       "78965      ...       0.000813  0.000703  0.001040  0.000856  0.002484   \n",
       "78966      ...       0.000625 -0.001012  0.001441  0.000958  0.000333   \n",
       "78967      ...       0.000386 -0.000648  0.001867  0.003074  0.002686   \n",
       "78968      ...      -0.001863  0.000017 -0.001914  0.002784 -0.002119   \n",
       "78969      ...       0.000938 -0.003094 -0.002979  0.000290 -0.000513   \n",
       "78970      ...       0.001561  0.000033  0.000586 -0.000801  0.001175   \n",
       "78971      ...       0.000028  0.000361 -0.000452  0.001392  0.000973   \n",
       "78972      ...      -0.001355  0.001303 -0.004386 -0.000741 -0.000873   \n",
       "78973      ...      -0.001054 -0.001224 -0.002171  0.001704 -0.000417   \n",
       "78974      ...      -0.002486 -0.001053  0.001422  0.000872  0.001521   \n",
       "78975      ...       0.000562 -0.000322 -0.003280  0.002624  0.000044   \n",
       "78976      ...       0.001229 -0.000499 -0.000255 -0.000138  0.001192   \n",
       "78977      ...       0.000937 -0.001023 -0.002352 -0.000746 -0.000004   \n",
       "78978      ...       0.000604 -0.000505 -0.001069 -0.000977  0.000939   \n",
       "78979      ...      -0.000774  0.000895  0.000424 -0.001245 -0.001289   \n",
       "78980      ...      -0.002499 -0.001729  0.001013 -0.002637  0.000772   \n",
       "78981      ...       0.000260 -0.000540  0.000656 -0.001577 -0.003603   \n",
       "78982      ...      -0.001401 -0.001132 -0.002322  0.002753  0.002409   \n",
       "78983      ...      -0.000351 -0.001194 -0.002549  0.000951 -0.004459   \n",
       "78984      ...      -0.000538 -0.002259  0.000246  0.001422 -0.002065   \n",
       "78985      ...      -0.000816 -0.002545  0.000971  0.003027 -0.001891   \n",
       "78986      ...       0.004555  0.000049  0.000006  0.002189 -0.002355   \n",
       "78987      ...       0.000048 -0.002144  0.000450 -0.001110 -0.002782   \n",
       "78988      ...      -0.000816 -0.000147  0.000659  0.001360  0.000485   \n",
       "78989      ...      -0.000115 -0.001132 -0.002303 -0.000020 -0.001237   \n",
       "78990      ...       0.001923  0.001714 -0.000897  0.001333 -0.001341   \n",
       "\n",
       "             46            47            48        49            50  \n",
       "0      0.000272 -1.039700e-03  1.249780e-03 -0.000796 -8.301510e-05  \n",
       "1     -0.000019 -4.357470e-05  2.011180e-05  0.000009 -7.639540e-06  \n",
       "2     -0.000013 -1.563940e-05  1.153700e-05 -0.000031 -2.430360e-06  \n",
       "3      0.000021  1.222220e-05 -5.887540e-05  0.000007  3.758550e-05  \n",
       "4     -0.000032 -3.797110e-05 -1.402450e-05  0.000012 -6.772960e-06  \n",
       "5     -0.000062 -8.350000e-05  6.057710e-05  0.000056 -4.780960e-05  \n",
       "6     -0.000008 -6.154720e-06 -5.206500e-06  0.000013 -1.546800e-05  \n",
       "7     -0.000018 -3.421030e-05  4.295350e-05 -0.000036  1.250570e-07  \n",
       "8     -0.000033  2.274020e-05  8.231730e-05  0.000019 -1.743520e-06  \n",
       "9     -0.000017  4.706920e-06 -5.948090e-05 -0.000021 -5.747050e-05  \n",
       "10    -0.000004 -9.676540e-05  8.301950e-06  0.000038  1.810370e-05  \n",
       "11     0.000035  4.682290e-05  5.608910e-05 -0.000106  8.471740e-05  \n",
       "12    -0.000009  1.202550e-05  1.455940e-05 -0.000014 -8.176780e-05  \n",
       "13    -0.000033  5.423480e-05 -3.767350e-05 -0.000082  2.584870e-05  \n",
       "14     0.000142  1.277130e-04  6.132710e-05  0.000027  1.761470e-04  \n",
       "15     0.000031 -1.164980e-07 -6.795670e-05 -0.000039 -5.392040e-05  \n",
       "16     0.000150  4.326830e-05  4.024570e-05 -0.000028 -2.255610e-05  \n",
       "17    -0.000072 -2.725490e-05  6.437440e-05 -0.000059  5.761320e-05  \n",
       "18     0.000016 -6.702450e-05  3.389700e-05  0.000006  6.228510e-05  \n",
       "19    -0.000031  1.007680e-04  4.726460e-05  0.000349 -1.575370e-04  \n",
       "20     0.000035 -3.407370e-05  1.734660e-06 -0.000014 -8.174900e-06  \n",
       "21     0.000033 -4.815830e-05  4.127900e-06  0.000054 -9.324580e-05  \n",
       "22    -0.000024 -2.972300e-06  4.834600e-05  0.000028  5.954240e-05  \n",
       "23    -0.000001  5.082580e-06 -1.365750e-04 -0.000039 -4.572480e-06  \n",
       "24     0.000115 -1.975670e-04  5.710110e-05 -0.000120  5.518170e-05  \n",
       "25    -0.000018  3.797800e-05  9.211330e-08  0.000021 -2.054590e-05  \n",
       "26     0.000103  2.212090e-06  2.685890e-05  0.000101 -6.131520e-05  \n",
       "27     0.000070 -3.293670e-05 -3.160790e-05  0.000035  5.073330e-05  \n",
       "28    -0.000081 -1.465590e-04 -6.357790e-05 -0.000071 -1.378800e-05  \n",
       "29    -0.000045  1.114940e-04 -5.830420e-05 -0.000160 -4.967930e-05  \n",
       "...         ...           ...           ...       ...           ...  \n",
       "78961  0.000567 -7.991940e-05  6.953040e-04  0.000690  1.005080e-04  \n",
       "78962 -0.001546  2.753840e-04 -1.608610e-04  0.001295 -1.380220e-03  \n",
       "78963  0.000705  1.474880e-03  1.524700e-03 -0.000450 -1.085590e-03  \n",
       "78964  0.003074  3.532140e-05 -1.245350e-03 -0.000844 -1.443350e-03  \n",
       "78965  0.004016 -3.046230e-05 -2.057460e-03 -0.000630 -2.503440e-03  \n",
       "78966  0.002915  6.809090e-04 -2.607660e-03  0.000948 -5.024280e-03  \n",
       "78967  0.002670  6.179370e-04 -2.472540e-03  0.002468 -3.443540e-03  \n",
       "78968  0.000304  1.732900e-03 -2.225020e-03 -0.000647 -1.470310e-03  \n",
       "78969  0.000729 -4.302520e-04 -1.313020e-04  0.000474  7.231630e-04  \n",
       "78970 -0.001148 -1.221400e-03 -2.093840e-04 -0.004070 -1.077560e-03  \n",
       "78971 -0.000217  9.564120e-04  1.875080e-03 -0.001768 -2.778280e-03  \n",
       "78972 -0.000412 -1.079340e-03 -1.037770e-03 -0.002255 -1.567260e-03  \n",
       "78973  0.002698 -9.265140e-04 -2.299090e-04 -0.001519 -7.929800e-04  \n",
       "78974  0.000900  2.477130e-03 -5.135250e-05 -0.000675 -1.663800e-03  \n",
       "78975  0.000934 -2.825110e-04  1.912130e-04 -0.001442  1.166860e-03  \n",
       "78976  0.000239 -1.363180e-03 -1.091070e-03  0.001180  2.802170e-05  \n",
       "78977 -0.002133 -1.206440e-03 -2.821130e-04 -0.001127 -1.360350e-04  \n",
       "78978  0.000814 -2.789180e-03 -1.972160e-03 -0.001505 -5.836550e-04  \n",
       "78979 -0.000539 -1.497370e-03 -1.036310e-03 -0.001056 -9.411020e-04  \n",
       "78980 -0.001054  9.044390e-04 -2.354210e-04 -0.001018 -3.219100e-04  \n",
       "78981  0.000579 -1.140140e-03  1.910580e-03  0.000487  5.976540e-04  \n",
       "78982 -0.001146 -3.656990e-04 -4.297690e-04 -0.001808  4.614080e-04  \n",
       "78983 -0.002380  2.801240e-03  2.349990e-05  0.000378 -2.223390e-03  \n",
       "78984  0.002164 -1.401510e-04  2.481260e-03 -0.000318 -1.579690e-03  \n",
       "78985  0.002263 -2.271970e-03  1.656410e-03 -0.001163 -2.956470e-03  \n",
       "78986 -0.000678  2.456270e-03 -1.055290e-03 -0.000333  4.490640e-04  \n",
       "78987  0.000808 -1.376350e-03  5.834340e-04  0.000033  2.126130e-03  \n",
       "78988 -0.001595 -6.368150e-04 -3.036520e-04  0.000391  4.633280e-03  \n",
       "78989 -0.000496  8.010320e-04 -1.125800e-03  0.000569 -2.823520e-03  \n",
       "78990  0.001248 -2.494900e-04  1.547960e-03  0.001972  7.585590e-05  \n",
       "\n",
       "[78991 rows x 51 columns]"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "word_space_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "embedding_matrix = word_space_df.iloc[:,1:].values*100\n",
    "# np.savetxt('embedding_matrix.txt', embedding_matrix)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ True,  True,  True, ...,  True,  True,  True],\n",
       "       [ True,  True,  True, ...,  True,  True,  True],\n",
       "       [ True,  True,  True, ...,  True,  True,  True],\n",
       "       ...,\n",
       "       [ True,  True,  True, ...,  True,  True,  True],\n",
       "       [ True,  True,  True, ...,  True,  True,  True],\n",
       "       [ True,  True,  True, ...,  True,  True,  True]])"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "b = np.loadtxt('embedding_matrix.txt', dtype=float)\n",
    "embedding_matrix == b"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "embedding_matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "78991"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(embedding_matrix)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "50"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(embedding_matrix[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Read Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "df = pd.read_csv('final_ready_all_data_word_to_vec.csv', parse_dates = (['timestamp'])).set_index('timestamp')\n",
    "df.sort_index(inplace = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "word_to_vec_data = df['word_to_vec_id'].values\n",
    "price_label = df['price_change'].values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Timestamp('2016-01-01 00:57:00')"
      ]
     },
     "execution_count": 117,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.index[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "metadata": {},
   "outputs": [],
   "source": [
    "s = [t.value // 10 ** 9 for t in df.index]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "df['unix'] = s"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>category_id</th>\n",
       "      <th>message_author</th>\n",
       "      <th>message_number</th>\n",
       "      <th>message_text</th>\n",
       "      <th>mins_after</th>\n",
       "      <th>mins_before</th>\n",
       "      <th>polarity</th>\n",
       "      <th>price_change</th>\n",
       "      <th>quoteheader</th>\n",
       "      <th>subjectivity</th>\n",
       "      <th>topic_id</th>\n",
       "      <th>topic_title</th>\n",
       "      <th>cleaned_message</th>\n",
       "      <th>word_to_vec_id</th>\n",
       "      <th>unix</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>timestamp</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2016-01-01 00:57:00</th>\n",
       "      <td>57</td>\n",
       "      <td>elux</td>\n",
       "      <td>390</td>\n",
       "      <td>2016!!!!!!       We made it. Bitcoin is dead. ...</td>\n",
       "      <td>430.588333</td>\n",
       "      <td>430.816000</td>\n",
       "      <td>-0.014773</td>\n",
       "      <td>-0.000529</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.427273</td>\n",
       "      <td>1061780</td>\n",
       "      <td>Rally!!!!!</td>\n",
       "      <td>['make', 'dead', 'new', 'year', 'quote']</td>\n",
       "      <td>[11, 803, 58, 8, 1226]</td>\n",
       "      <td>1451609820</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2016-01-01 01:00:00</th>\n",
       "      <td>57</td>\n",
       "      <td>The Pharmacist</td>\n",
       "      <td>391</td>\n",
       "      <td>A'ight bitch, you're quoted. Are you laying m...</td>\n",
       "      <td>430.628333</td>\n",
       "      <td>430.619000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000022</td>\n",
       "      <td>Quote from: elux on January 01, 2016, 12:57:06...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1061780</td>\n",
       "      <td>Rally!!!!!</td>\n",
       "      <td>['ight', 'bitch', 'quote', 'lay', 'money', 'pr...</td>\n",
       "      <td>[28584, 3782, 1226, 2423, 14, 204]</td>\n",
       "      <td>1451610000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2016-01-01 01:21:00</th>\n",
       "      <td>57</td>\n",
       "      <td>keystroke</td>\n",
       "      <td>3</td>\n",
       "      <td>Cool! Looking forward to your comments. :)</td>\n",
       "      <td>430.336250</td>\n",
       "      <td>430.723000</td>\n",
       "      <td>0.468750</td>\n",
       "      <td>-0.000898</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.825000</td>\n",
       "      <td>1310368</td>\n",
       "      <td>Another way of looking at the halving, market ...</td>\n",
       "      <td>['cool', 'look', 'forward', 'comment']</td>\n",
       "      <td>[1252, 66, 651, 783]</td>\n",
       "      <td>1451611260</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2016-01-01 01:31:00</th>\n",
       "      <td>57</td>\n",
       "      <td>Hugroll</td>\n",
       "      <td>260</td>\n",
       "      <td>i dont think its going to go down anytime soon...</td>\n",
       "      <td>430.347917</td>\n",
       "      <td>430.444000</td>\n",
       "      <td>0.114815</td>\n",
       "      <td>-0.000223</td>\n",
       "      <td>Quote from: roldstin on November 27, 2015, 04:...</td>\n",
       "      <td>0.262963</td>\n",
       "      <td>1266304</td>\n",
       "      <td>When will this bitcoin will go down?</td>\n",
       "      <td>['dont', 'go', 'go', 'anytime', 'soon', 'halfi...</td>\n",
       "      <td>[148, 2, 2, 592, 97, 4195, 22, 395, 12, 69, 8,...</td>\n",
       "      <td>1451611860</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2016-01-01 01:52:00</th>\n",
       "      <td>57</td>\n",
       "      <td>prodigy8</td>\n",
       "      <td>71</td>\n",
       "      <td>If we check the last halving period then we ca...</td>\n",
       "      <td>430.753000</td>\n",
       "      <td>430.756250</td>\n",
       "      <td>0.228348</td>\n",
       "      <td>-0.000008</td>\n",
       "      <td>Quote from: avw1982 on December 28, 2015, 12:4...</td>\n",
       "      <td>0.517262</td>\n",
       "      <td>1304141</td>\n",
       "      <td>What will happen if there's no price rise for ...</td>\n",
       "      <td>['check', 'last', 'halve', 'period', 'see', 'p...</td>\n",
       "      <td>[436, 82, 105, 334, 9, 1, 338, 106, 43, 105, 1...</td>\n",
       "      <td>1451613120</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2016-01-01 03:10:00</th>\n",
       "      <td>7</td>\n",
       "      <td>noone000</td>\n",
       "      <td>72</td>\n",
       "      <td>Bitcoin, in my opinion, will probably not repl...</td>\n",
       "      <td>430.936500</td>\n",
       "      <td>430.860000</td>\n",
       "      <td>0.093750</td>\n",
       "      <td>0.000178</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.406250</td>\n",
       "      <td>1237124</td>\n",
       "      <td>POP QUIZ: Do you believe that BTC is the world...</td>\n",
       "      <td>['opinion', 'probably', 'replace', 'mean', 'tr...</td>\n",
       "      <td>[180, 140, 540, 74, 101, 1286, 140, 80, 2191, ...</td>\n",
       "      <td>1451617800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2016-01-01 03:31:00</th>\n",
       "      <td>57</td>\n",
       "      <td>kapguy</td>\n",
       "      <td>261</td>\n",
       "      <td>Why does everyone think the halving will creat...</td>\n",
       "      <td>431.659000</td>\n",
       "      <td>431.885000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>-0.000523</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.533333</td>\n",
       "      <td>1266304</td>\n",
       "      <td>When will this bitcoin will go down?</td>\n",
       "      <td>['everyone', 'halve', 'create', 'instant', 'ju...</td>\n",
       "      <td>[136, 105, 172, 1437, 469, 1, 64, 5384, 129, 1...</td>\n",
       "      <td>1451619060</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2016-01-01 05:11:00</th>\n",
       "      <td>57</td>\n",
       "      <td>r3t4rD4life</td>\n",
       "      <td>1</td>\n",
       "      <td>Buy and sell of a million+ coins at a time. Tu...</td>\n",
       "      <td>436.074167</td>\n",
       "      <td>436.019500</td>\n",
       "      <td>0.100000</td>\n",
       "      <td>0.000125</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1310608</td>\n",
       "      <td>We all know huobi volume is faked, but what is...</td>\n",
       "      <td>['buy', 'sell', 'million', 'coin', 'time', 'tu...</td>\n",
       "      <td>[6, 17, 268, 24, 4, 373, 38, 22, 1180, 65024]</td>\n",
       "      <td>1451625060</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2016-01-01 05:13:00</th>\n",
       "      <td>7</td>\n",
       "      <td>pitham1</td>\n",
       "      <td>8</td>\n",
       "      <td>When you say next year, do you mean 2016 or 20...</td>\n",
       "      <td>436.005833</td>\n",
       "      <td>436.067000</td>\n",
       "      <td>-0.140625</td>\n",
       "      <td>-0.000140</td>\n",
       "      <td>Quote from: Cabdinsard on December 30, 2015, 1...</td>\n",
       "      <td>0.609375</td>\n",
       "      <td>1304240</td>\n",
       "      <td>Bitcoin Price Slides 10% In PostXmas Selloff A...</td>\n",
       "      <td>['say', 'next', 'year', 'mean', 'people', 'dis...</td>\n",
       "      <td>[30, 69, 8, 74, 3, 1214, 1, 1633]</td>\n",
       "      <td>1451625180</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2016-01-01 05:17:00</th>\n",
       "      <td>57</td>\n",
       "      <td>pitham1</td>\n",
       "      <td>2</td>\n",
       "      <td>There is no profit involved in these trades. I...</td>\n",
       "      <td>435.680000</td>\n",
       "      <td>436.061000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>-0.000874</td>\n",
       "      <td>Quote from: r3t4rD4life on January 01, 2016, 0...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1310608</td>\n",
       "      <td>We all know huobi volume is faked, but what is...</td>\n",
       "      <td>['profit', 'involve', 'trade', 'coin', 'move',...</td>\n",
       "      <td>[38, 484, 55, 24, 122, 16, 1356, 112, 75, 101,...</td>\n",
       "      <td>1451625420</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2016-01-01 05:20:00</th>\n",
       "      <td>57</td>\n",
       "      <td>pitham1</td>\n",
       "      <td>72</td>\n",
       "      <td>Miners will just have to look at their variabl...</td>\n",
       "      <td>435.632083</td>\n",
       "      <td>435.887000</td>\n",
       "      <td>0.136364</td>\n",
       "      <td>-0.000585</td>\n",
       "      <td>Quote from: wikenpp on December 31, 2015, 04:4...</td>\n",
       "      <td>0.454545</td>\n",
       "      <td>1304141</td>\n",
       "      <td>What will happen if there's no price rise for ...</td>\n",
       "      <td>['mine', 'look', 'variable', 'cost', 'electric...</td>\n",
       "      <td>[89, 66, 2184, 340, 866, 59, 58, 89, 41, 10, 1...</td>\n",
       "      <td>1451625600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2016-01-01 05:22:00</th>\n",
       "      <td>7</td>\n",
       "      <td>pitham1</td>\n",
       "      <td>103</td>\n",
       "      <td>1 BTC might be enough, but no harm in reaching...</td>\n",
       "      <td>435.681500</td>\n",
       "      <td>435.706000</td>\n",
       "      <td>0.400000</td>\n",
       "      <td>-0.000056</td>\n",
       "      <td>Quote from: helloeverybody on December 30, 201...</td>\n",
       "      <td>0.700000</td>\n",
       "      <td>1253196</td>\n",
       "      <td>Anyone here part of \"1 million club\"?</td>\n",
       "      <td>['bitcoin', 'might', 'enough', 'harm', 'reach'...</td>\n",
       "      <td>[19, 84, 162, 1596, 42, 37, 53, 34, 7, 33]</td>\n",
       "      <td>1451625720</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2016-01-01 05:41:00</th>\n",
       "      <td>57</td>\n",
       "      <td>pattu1</td>\n",
       "      <td>10</td>\n",
       "      <td>Pump and dump can be profitable for people who...</td>\n",
       "      <td>436.039167</td>\n",
       "      <td>435.916875</td>\n",
       "      <td>-0.200000</td>\n",
       "      <td>0.000280</td>\n",
       "      <td>Quote from: NorrisK on December 30, 2015, 06:2...</td>\n",
       "      <td>0.450000</td>\n",
       "      <td>1309163</td>\n",
       "      <td>Pump + Dump</td>\n",
       "      <td>['pump', 'dump', 'profitable', 'people', 'impl...</td>\n",
       "      <td>[114, 94, 380, 3, 635, 243, 1858, 490, 84, 178...</td>\n",
       "      <td>1451626860</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2016-01-01 05:42:00</th>\n",
       "      <td>57</td>\n",
       "      <td>pattu1</td>\n",
       "      <td>35</td>\n",
       "      <td>Nope, I don't believe people are dumb enough t...</td>\n",
       "      <td>436.070000</td>\n",
       "      <td>435.922500</td>\n",
       "      <td>-0.101667</td>\n",
       "      <td>0.000338</td>\n",
       "      <td>Quote from: gkv9 on December 30, 2015, 03:54:0...</td>\n",
       "      <td>0.533333</td>\n",
       "      <td>1306737</td>\n",
       "      <td>Another 10% Cut Incoming</td>\n",
       "      <td>['nope', 'don', 'believe', 'people', 'dumb', '...</td>\n",
       "      <td>[1610, 23, 67, 3, 1359, 162, 67, 135, 10, 172,...</td>\n",
       "      <td>1451626920</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2016-01-01 05:46:00</th>\n",
       "      <td>7</td>\n",
       "      <td>erwin45hacked</td>\n",
       "      <td>41</td>\n",
       "      <td>Those that dont sell when prices moves down 20...</td>\n",
       "      <td>436.256000</td>\n",
       "      <td>436.018000</td>\n",
       "      <td>-0.018519</td>\n",
       "      <td>0.000546</td>\n",
       "      <td>Quote from: newcoins1978 on December 31, 2015,...</td>\n",
       "      <td>0.396296</td>\n",
       "      <td>1304960</td>\n",
       "      <td>#panicselling is so 1995</td>\n",
       "      <td>['dont', 'sell', 'price', 'move', 'day', 'abso...</td>\n",
       "      <td>[148, 17, 1, 122, 40, 752, 1218, 47, 5357, 290...</td>\n",
       "      <td>1451627160</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2016-01-01 05:49:00</th>\n",
       "      <td>57</td>\n",
       "      <td>mtnsaa</td>\n",
       "      <td>11</td>\n",
       "      <td>Bitcoin market it's still vulnerable to p&amp;d sc...</td>\n",
       "      <td>436.355000</td>\n",
       "      <td>436.118000</td>\n",
       "      <td>-0.020833</td>\n",
       "      <td>0.000543</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.582292</td>\n",
       "      <td>1309163</td>\n",
       "      <td>Pump + Dump</td>\n",
       "      <td>['market', 'still', 'vulnerable', 'scheme', 'c...</td>\n",
       "      <td>[10, 21, 2304, 900, 176, 2316, 32, 757, 1356, ...</td>\n",
       "      <td>1451627340</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2016-01-01 06:52:00</th>\n",
       "      <td>57</td>\n",
       "      <td>pattu1</td>\n",
       "      <td>12</td>\n",
       "      <td>Altcoin markets are way too easy given the lac...</td>\n",
       "      <td>434.417500</td>\n",
       "      <td>434.100000</td>\n",
       "      <td>0.113889</td>\n",
       "      <td>0.000731</td>\n",
       "      <td>Quote from: mtnsaa on January 01, 2016, 05:49:...</td>\n",
       "      <td>0.722222</td>\n",
       "      <td>1309163</td>\n",
       "      <td>Pump + Dump</td>\n",
       "      <td>['altcoin', 'market', 'way', 'easy', 'give', '...</td>\n",
       "      <td>[283, 10, 47, 199, 76, 778, 1461, 76, 10, 381,...</td>\n",
       "      <td>1451631120</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2016-01-01 07:04:00</th>\n",
       "      <td>57</td>\n",
       "      <td>suda123</td>\n",
       "      <td>13</td>\n",
       "      <td>LOL</td>\n",
       "      <td>435.912500</td>\n",
       "      <td>434.973750</td>\n",
       "      <td>0.800000</td>\n",
       "      <td>0.002156</td>\n",
       "      <td>Quote from: r0ach on December 30, 2015, 04:20:...</td>\n",
       "      <td>0.700000</td>\n",
       "      <td>1309163</td>\n",
       "      <td>Pump + Dump</td>\n",
       "      <td>['lol']</td>\n",
       "      <td>[459]</td>\n",
       "      <td>1451631840</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2016-01-01 08:56:00</th>\n",
       "      <td>57</td>\n",
       "      <td>--Encrypted--</td>\n",
       "      <td>3</td>\n",
       "      <td>I didn't know we all know that... where's the ...</td>\n",
       "      <td>433.900833</td>\n",
       "      <td>434.880000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>-0.002254</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1310608</td>\n",
       "      <td>We all know huobi volume is faked, but what is...</td>\n",
       "      <td>['didn', 'know', 'know', 'proof']</td>\n",
       "      <td>[338, 15, 15, 959]</td>\n",
       "      <td>1451638560</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2016-01-01 09:10:00</th>\n",
       "      <td>57</td>\n",
       "      <td>tokeweed</td>\n",
       "      <td>73</td>\n",
       "      <td>The. Sauron will get the ring.   http://media-...</td>\n",
       "      <td>433.473333</td>\n",
       "      <td>433.560000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>-0.000200</td>\n",
       "      <td>Quote from: helloeverybody on December 26, 201...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1304141</td>\n",
       "      <td>What will happen if there's no price rise for ...</td>\n",
       "      <td>['sauron', 'ring', 'medium', 'cache', 'ak', 'p...</td>\n",
       "      <td>[28580, 3462, 339, 5329, 6022, 8045, 35295]</td>\n",
       "      <td>1451639400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2016-01-01 09:10:00</th>\n",
       "      <td>7</td>\n",
       "      <td>Gotimour</td>\n",
       "      <td>9</td>\n",
       "      <td>The price below $400 is good to buy. I think t...</td>\n",
       "      <td>433.473333</td>\n",
       "      <td>433.560000</td>\n",
       "      <td>0.350000</td>\n",
       "      <td>-0.000200</td>\n",
       "      <td>Quote from: mobnepal on December 30, 2015, 04:...</td>\n",
       "      <td>0.300000</td>\n",
       "      <td>1304240</td>\n",
       "      <td>Bitcoin Price Slides 10% In PostXmas Selloff A...</td>\n",
       "      <td>['price', 'good', 'buy', 'price', 'go', 'trade...</td>\n",
       "      <td>[1, 7, 6, 1, 2, 160, 41, 52, 935]</td>\n",
       "      <td>1451639400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2016-01-01 09:18:00</th>\n",
       "      <td>57</td>\n",
       "      <td>Alaki</td>\n",
       "      <td>74</td>\n",
       "      <td>IMO , No price rise = Miners will not profit =...</td>\n",
       "      <td>433.105833</td>\n",
       "      <td>433.378750</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>-0.000630</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1304141</td>\n",
       "      <td>What will happen if there's no price rise for ...</td>\n",
       "      <td>['imo', 'price', 'rise', 'mine', 'profit', 'gr...</td>\n",
       "      <td>[777, 1, 5, 89, 38, 198, 3362]</td>\n",
       "      <td>1451639880</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2016-01-01 10:03:00</th>\n",
       "      <td>57</td>\n",
       "      <td>Juhagic</td>\n",
       "      <td>75</td>\n",
       "      <td>If there is no price rise, most S3 miners will...</td>\n",
       "      <td>433.042500</td>\n",
       "      <td>433.010000</td>\n",
       "      <td>0.178333</td>\n",
       "      <td>0.000075</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.471667</td>\n",
       "      <td>1304141</td>\n",
       "      <td>What will happen if there's no price rise for ...</td>\n",
       "      <td>['price', 'rise', 'mine', 'shutdown', 'due', '...</td>\n",
       "      <td>[1, 5, 89, 2743, 170, 380, 866, 1, 18]</td>\n",
       "      <td>1451642580</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2016-01-01 10:11:00</th>\n",
       "      <td>57</td>\n",
       "      <td>enhu</td>\n",
       "      <td>76</td>\n",
       "      <td>Haven't they look at this possibility already ...</td>\n",
       "      <td>433.039000</td>\n",
       "      <td>433.052500</td>\n",
       "      <td>0.042857</td>\n",
       "      <td>-0.000031</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.445714</td>\n",
       "      <td>1304141</td>\n",
       "      <td>What will happen if there's no price rise for ...</td>\n",
       "      <td>['haven', 'look', 'possibility', 'already', 'p...</td>\n",
       "      <td>[620, 66, 313, 64, 280, 1292, 13, 17, 637, 89,...</td>\n",
       "      <td>1451643060</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2016-01-01 10:13:00</th>\n",
       "      <td>57</td>\n",
       "      <td>buddu</td>\n",
       "      <td>38</td>\n",
       "      <td>I don't think price will drop under 400 $ mark...</td>\n",
       "      <td>432.997083</td>\n",
       "      <td>433.057500</td>\n",
       "      <td>-0.163889</td>\n",
       "      <td>-0.000140</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.213889</td>\n",
       "      <td>1309538</td>\n",
       "      <td>$400 will not survive the weekend</td>\n",
       "      <td>['don', 'price', 'drop', 'mark', 'look', 'perf...</td>\n",
       "      <td>[23, 1, 70, 376, 66, 1236, 1, 120, 52, 1, 338,...</td>\n",
       "      <td>1451643180</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2016-01-01 10:19:00</th>\n",
       "      <td>57</td>\n",
       "      <td>fantoos</td>\n",
       "      <td>39</td>\n",
       "      <td>Although can not say whether it is still bulli...</td>\n",
       "      <td>432.620000</td>\n",
       "      <td>432.994500</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>-0.000865</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1309538</td>\n",
       "      <td>$400 will not survive the weekend</td>\n",
       "      <td>['although', 'say', 'whether', 'still', 'bulli...</td>\n",
       "      <td>[331, 30, 354, 21, 496, 50, 838, 1, 566, 22, 3...</td>\n",
       "      <td>1451643540</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2016-01-01 10:25:00</th>\n",
       "      <td>57</td>\n",
       "      <td>Ekanenf</td>\n",
       "      <td>36</td>\n",
       "      <td>Have you made any money from your prediction? ...</td>\n",
       "      <td>432.700000</td>\n",
       "      <td>432.556667</td>\n",
       "      <td>-0.500000</td>\n",
       "      <td>0.000331</td>\n",
       "      <td>Quote from: talks_cheep on December 28, 2015, ...</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1306737</td>\n",
       "      <td>Another 10% Cut Incoming</td>\n",
       "      <td>['make', 'money', 'prediction', 'price', 'vola...</td>\n",
       "      <td>[11, 14, 204, 1, 332, 358, 11, 14]</td>\n",
       "      <td>1451643900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2016-01-01 10:57:00</th>\n",
       "      <td>57</td>\n",
       "      <td>1Referee</td>\n",
       "      <td>40</td>\n",
       "      <td>Seeing the price go up from below $250 to righ...</td>\n",
       "      <td>432.478500</td>\n",
       "      <td>432.222500</td>\n",
       "      <td>0.001720</td>\n",
       "      <td>0.000592</td>\n",
       "      <td>Quote from: fantoos on January 01, 2016, 10:19...</td>\n",
       "      <td>0.358201</td>\n",
       "      <td>1309538</td>\n",
       "      <td>$400 will not survive the weekend</td>\n",
       "      <td>['see', 'price', 'go', 'right', 'exactly', 'co...</td>\n",
       "      <td>[9, 1, 2, 39, 369, 197, 838, 110, 1, 1020, 438...</td>\n",
       "      <td>1451645820</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2016-01-01 11:03:00</th>\n",
       "      <td>57</td>\n",
       "      <td>1Referee</td>\n",
       "      <td>77</td>\n",
       "      <td>The price will rise anyway. If it's not done b...</td>\n",
       "      <td>432.310000</td>\n",
       "      <td>432.424375</td>\n",
       "      <td>0.107273</td>\n",
       "      <td>-0.000265</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.470909</td>\n",
       "      <td>1304141</td>\n",
       "      <td>What will happen if there's no price rise for ...</td>\n",
       "      <td>['price', 'rise', 'anyway', 'legit', 'growth',...</td>\n",
       "      <td>[1, 5, 443, 1269, 198, 272, 75, 466, 1, 13, 26...</td>\n",
       "      <td>1451646180</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2016-01-01 11:12:00</th>\n",
       "      <td>57</td>\n",
       "      <td>lexuz</td>\n",
       "      <td>41</td>\n",
       "      <td>after seeing price on the charts today, i gues...</td>\n",
       "      <td>432.403750</td>\n",
       "      <td>432.310000</td>\n",
       "      <td>-0.093182</td>\n",
       "      <td>0.000217</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.483239</td>\n",
       "      <td>1309538</td>\n",
       "      <td>$400 will not survive the weekend</td>\n",
       "      <td>['see', 'price', 'chart', 'today', 'guess', 'p...</td>\n",
       "      <td>[9, 1, 286, 132, 194, 1, 266, 270, 47, 74, 1, ...</td>\n",
       "      <td>1451646720</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2018-05-03 22:45:00</th>\n",
       "      <td>7</td>\n",
       "      <td>Elrozaq</td>\n",
       "      <td>195</td>\n",
       "      <td>The bitcoin is the best crypto, it is so popul...</td>\n",
       "      <td>9628.070000</td>\n",
       "      <td>9629.955000</td>\n",
       "      <td>0.533333</td>\n",
       "      <td>-0.000196</td>\n",
       "      <td>Quote from: naphto on April 19, 2013, 08:04:15...</td>\n",
       "      <td>0.422222</td>\n",
       "      <td>180882</td>\n",
       "      <td>Why people are still buying BTC?</td>\n",
       "      <td>['best', 'crypto', 'popular', 'see', 'last', '...</td>\n",
       "      <td>[103, 48, 401, 9, 82, 8, 3, 21, 24278, 21362, ...</td>\n",
       "      <td>1525387500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2018-05-03 22:46:00</th>\n",
       "      <td>7</td>\n",
       "      <td>weblouartisan</td>\n",
       "      <td>419</td>\n",
       "      <td>Actually you are just doing it well, trading o...</td>\n",
       "      <td>9627.499583</td>\n",
       "      <td>9629.995000</td>\n",
       "      <td>0.220238</td>\n",
       "      <td>-0.000259</td>\n",
       "      <td>Quote from: zarados on August 22, 2017, 01:20:...</td>\n",
       "      <td>0.461905</td>\n",
       "      <td>2109367</td>\n",
       "      <td>A wise strategy for your bitcoin</td>\n",
       "      <td>['actually', 'well', 'trade', 'right', 'time',...</td>\n",
       "      <td>[138, 53, 55, 39, 4, 11, 77, 80, 230, 72, 160,...</td>\n",
       "      <td>1525387560</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2018-05-03 22:48:00</th>\n",
       "      <td>7</td>\n",
       "      <td>Yamifoud</td>\n",
       "      <td>196</td>\n",
       "      <td>Of course they know that bitcoin investment gr...</td>\n",
       "      <td>9629.531667</td>\n",
       "      <td>9629.995000</td>\n",
       "      <td>0.061667</td>\n",
       "      <td>-0.000048</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.328333</td>\n",
       "      <td>180882</td>\n",
       "      <td>Why people are still buying BTC?</td>\n",
       "      <td>['course', 'know', 'investment', 'grow', 'real...</td>\n",
       "      <td>[176, 15, 60, 118, 29, 191, 38, 3, 30, 60, 529...</td>\n",
       "      <td>1525387680</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2018-05-03 22:49:00</th>\n",
       "      <td>7</td>\n",
       "      <td>weblouartisan</td>\n",
       "      <td>282</td>\n",
       "      <td>It depends on the government, if the governmen...</td>\n",
       "      <td>9633.339583</td>\n",
       "      <td>9629.224500</td>\n",
       "      <td>0.271429</td>\n",
       "      <td>0.000427</td>\n",
       "      <td>Quote from: yselacreyo3 on December 24, 2017, ...</td>\n",
       "      <td>0.297959</td>\n",
       "      <td>2639457</td>\n",
       "      <td>Can cryptocurrencies make physical money disap...</td>\n",
       "      <td>['depend', 'government', 'government', 'allow'...</td>\n",
       "      <td>[173, 73, 73, 394, 107, 766, 159, 84, 29, 2, 7...</td>\n",
       "      <td>1525387740</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2018-05-03 22:52:00</th>\n",
       "      <td>7</td>\n",
       "      <td>weblouartisan</td>\n",
       "      <td>131</td>\n",
       "      <td>Bitcoin should be advertised on the television...</td>\n",
       "      <td>9653.365417</td>\n",
       "      <td>9627.000500</td>\n",
       "      <td>0.100000</td>\n",
       "      <td>0.002735</td>\n",
       "      <td>Quote from: cutikanzilong on April 27, 2018, 0...</td>\n",
       "      <td>0.400000</td>\n",
       "      <td>3410399</td>\n",
       "      <td>bitcoin in developing countries</td>\n",
       "      <td>['advertise', 'television', 'company', 'accept...</td>\n",
       "      <td>[1073, 3234, 255, 147, 107, 144, 179, 3, 207, ...</td>\n",
       "      <td>1525387920</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2018-05-03 22:54:00</th>\n",
       "      <td>57</td>\n",
       "      <td>laluna24</td>\n",
       "      <td>78</td>\n",
       "      <td>This will surely increase again the price now ...</td>\n",
       "      <td>9666.236250</td>\n",
       "      <td>9630.209000</td>\n",
       "      <td>0.171818</td>\n",
       "      <td>0.003734</td>\n",
       "      <td>Quote from: EARL MATEUS on May 03, 2018, 06:26...</td>\n",
       "      <td>0.518586</td>\n",
       "      <td>3423482</td>\n",
       "      <td>Bitcoin increase again?</td>\n",
       "      <td>['surely', 'rise', 'price', 'go', 'high', 'pos...</td>\n",
       "      <td>[285, 5, 1, 2, 18, 270, 873, 59, 731, 592, 317...</td>\n",
       "      <td>1525388040</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2018-05-03 22:55:00</th>\n",
       "      <td>57</td>\n",
       "      <td>Dingdong7</td>\n",
       "      <td>79</td>\n",
       "      <td>Bitcoin price will really go higher than we ar...</td>\n",
       "      <td>9670.569583</td>\n",
       "      <td>9634.778500</td>\n",
       "      <td>0.350000</td>\n",
       "      <td>0.003708</td>\n",
       "      <td>Quote from: Hui Ling on April 28, 2018, 03:08:...</td>\n",
       "      <td>0.715556</td>\n",
       "      <td>3423482</td>\n",
       "      <td>Bitcoin increase again?</td>\n",
       "      <td>['price', 'really', 'go', 'high', 'expect', 'p...</td>\n",
       "      <td>[1, 29, 2, 18, 78, 1, 84, 70, 106, 249, 33, 57...</td>\n",
       "      <td>1525388100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2018-05-03 22:58:00</th>\n",
       "      <td>57</td>\n",
       "      <td>Yamifoud</td>\n",
       "      <td>265</td>\n",
       "      <td>Definitely we could see a lot of surprise happ...</td>\n",
       "      <td>9677.481667</td>\n",
       "      <td>9657.859500</td>\n",
       "      <td>0.250000</td>\n",
       "      <td>0.002030</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>3146568</td>\n",
       "      <td>What will happen to bitcoin in 2018?</td>\n",
       "      <td>['definitely', 'see', 'lot', 'surprise', 'happ...</td>\n",
       "      <td>[243, 9, 43, 353, 12, 1, 615, 140, 11, 238, 44...</td>\n",
       "      <td>1525388280</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2018-05-03 22:58:00</th>\n",
       "      <td>57</td>\n",
       "      <td>Duzter</td>\n",
       "      <td>47</td>\n",
       "      <td>Agreed, the investors who were the backbone ha...</td>\n",
       "      <td>9677.481667</td>\n",
       "      <td>9657.859500</td>\n",
       "      <td>-0.026948</td>\n",
       "      <td>0.002030</td>\n",
       "      <td>Quote from: Capt00 on May 03, 2018, 10:42:43 P...</td>\n",
       "      <td>0.436364</td>\n",
       "      <td>3464694</td>\n",
       "      <td>Bitcoin is taking a breath</td>\n",
       "      <td>['agree', 'investor', 'backbone', 'felt', 'muc...</td>\n",
       "      <td>[155, 77, 4140, 1433, 34, 121, 1, 2, 61, 1, 26...</td>\n",
       "      <td>1525388280</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2018-05-03 22:59:00</th>\n",
       "      <td>57</td>\n",
       "      <td>Gabb</td>\n",
       "      <td>48</td>\n",
       "      <td>Today I was surprised by the remarkably bullis...</td>\n",
       "      <td>9681.836667</td>\n",
       "      <td>9664.485000</td>\n",
       "      <td>0.102143</td>\n",
       "      <td>0.001794</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.535476</td>\n",
       "      <td>3464694</td>\n",
       "      <td>Bitcoin is taking a breath</td>\n",
       "      <td>['today', 'surprise', 'remarkably', 'bullish',...</td>\n",
       "      <td>[132, 353, 6370, 496, 1381, 120, 78, 276, 332,...</td>\n",
       "      <td>1525388340</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2018-05-03 22:59:00</th>\n",
       "      <td>57</td>\n",
       "      <td>Bagaji</td>\n",
       "      <td>23</td>\n",
       "      <td>As the trend of an upward movement of bitcoin ...</td>\n",
       "      <td>9681.836667</td>\n",
       "      <td>9664.485000</td>\n",
       "      <td>0.025000</td>\n",
       "      <td>0.001794</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.450000</td>\n",
       "      <td>3454537</td>\n",
       "      <td>Analysis of the mid-term for Bitcoin price</td>\n",
       "      <td>['trend', 'upward', 'movement', 'value', 'begi...</td>\n",
       "      <td>[221, 932, 282, 25, 267, 1521, 1001, 100, 379,...</td>\n",
       "      <td>1525388340</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2018-05-03 23:00:00</th>\n",
       "      <td>57</td>\n",
       "      <td>Pasnik</td>\n",
       "      <td>154</td>\n",
       "      <td>This is good we have more users who believes i...</td>\n",
       "      <td>9687.913333</td>\n",
       "      <td>9669.685000</td>\n",
       "      <td>0.433333</td>\n",
       "      <td>0.001883</td>\n",
       "      <td>Quote from: myhometalk on April 22, 2018, 07:2...</td>\n",
       "      <td>0.494444</td>\n",
       "      <td>3141148</td>\n",
       "      <td>Will bitcoin survive?</td>\n",
       "      <td>['good', 'user', 'belief', 'day', 'moment', 's...</td>\n",
       "      <td>[7, 119, 974, 40, 187, 566, 511, 480, 1640, 25...</td>\n",
       "      <td>1525388400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2018-05-03 23:02:00</th>\n",
       "      <td>57</td>\n",
       "      <td>Capt00</td>\n",
       "      <td>249</td>\n",
       "      <td>If you have invested it earlier when prices ar...</td>\n",
       "      <td>9701.035833</td>\n",
       "      <td>9674.646000</td>\n",
       "      <td>-0.070000</td>\n",
       "      <td>0.002724</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.280000</td>\n",
       "      <td>3195183</td>\n",
       "      <td>is this right time to invest in BITCOIN..?</td>\n",
       "      <td>['invest', 'early', 'price', 'least', 'bug', '...</td>\n",
       "      <td>[31, 235, 1, 202, 2021, 93, 132, 1, 122, 615, ...</td>\n",
       "      <td>1525388520</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2018-05-03 23:06:00</th>\n",
       "      <td>57</td>\n",
       "      <td>Anait</td>\n",
       "      <td>11</td>\n",
       "      <td>We can just expect good things to happen in th...</td>\n",
       "      <td>9744.966667</td>\n",
       "      <td>9690.497500</td>\n",
       "      <td>0.162500</td>\n",
       "      <td>0.005605</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.300000</td>\n",
       "      <td>3514500</td>\n",
       "      <td>we're pumpin right now</td>\n",
       "      <td>['expect', 'good', 'thing', 'happen', 'upcomin...</td>\n",
       "      <td>[78, 7, 33, 12, 695, 5803, 4, 216, 1, 114, 12,...</td>\n",
       "      <td>1525388760</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2018-05-03 23:11:00</th>\n",
       "      <td>57</td>\n",
       "      <td>n0ne</td>\n",
       "      <td>266</td>\n",
       "      <td>Agreed, various predictions from experts have ...</td>\n",
       "      <td>9768.468333</td>\n",
       "      <td>9742.663000</td>\n",
       "      <td>0.170909</td>\n",
       "      <td>0.002645</td>\n",
       "      <td>Quote from: BUK2016 on May 03, 2018, 10:22:24 ...</td>\n",
       "      <td>0.484935</td>\n",
       "      <td>3146568</td>\n",
       "      <td>What will happen to bitcoin in 2018?</td>\n",
       "      <td>['agree', 'various', 'prediction', 'expert', '...</td>\n",
       "      <td>[155, 837, 204, 613, 294, 42, 58, 8, 676, 366,...</td>\n",
       "      <td>1525389060</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2018-05-03 23:15:00</th>\n",
       "      <td>57</td>\n",
       "      <td>muf18</td>\n",
       "      <td>486</td>\n",
       "      <td>Well I guess stop is now taken away.  Trends a...</td>\n",
       "      <td>9767.387500</td>\n",
       "      <td>9763.042000</td>\n",
       "      <td>-0.004444</td>\n",
       "      <td>0.000445</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.411111</td>\n",
       "      <td>2711461</td>\n",
       "      <td>2018 Cryptocurrency Crash (Elliott Wave)</td>\n",
       "      <td>['well', 'guess', 'stop', 'take', 'away', 'tre...</td>\n",
       "      <td>[53, 194, 192, 45, 346, 221, 2, 353, 137, 29, ...</td>\n",
       "      <td>1525389300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2018-05-03 23:17:00</th>\n",
       "      <td>57</td>\n",
       "      <td>Bagaji</td>\n",
       "      <td>250</td>\n",
       "      <td>From all indications bitcoin has not yet reach...</td>\n",
       "      <td>9759.733333</td>\n",
       "      <td>9770.865000</td>\n",
       "      <td>0.107143</td>\n",
       "      <td>-0.001140</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.372143</td>\n",
       "      <td>3195183</td>\n",
       "      <td>is this right time to invest in BITCOIN..?</td>\n",
       "      <td>['indication', 'yet', 'reach', 'real', 'value'...</td>\n",
       "      <td>[1663, 190, 42, 131, 25, 74, 39, 16, 31, 591, ...</td>\n",
       "      <td>1525389420</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2018-05-03 23:22:00</th>\n",
       "      <td>57</td>\n",
       "      <td>Happiest</td>\n",
       "      <td>23</td>\n",
       "      <td>Recently, it's hard to get good ICOs.</td>\n",
       "      <td>9754.919583</td>\n",
       "      <td>9760.686500</td>\n",
       "      <td>0.204167</td>\n",
       "      <td>-0.000591</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.570833</td>\n",
       "      <td>2985611</td>\n",
       "      <td>So, what's an ICO and why is it revolutionary?</td>\n",
       "      <td>['recently', 'hard', 'good', 'icos']</td>\n",
       "      <td>[549, 91, 7, 608]</td>\n",
       "      <td>1525389720</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2018-05-03 23:23:00</th>\n",
       "      <td>57</td>\n",
       "      <td>Biscutard</td>\n",
       "      <td>49</td>\n",
       "      <td>Investors play a lot of role in crypto currenc...</td>\n",
       "      <td>9754.909583</td>\n",
       "      <td>9757.345000</td>\n",
       "      <td>0.032584</td>\n",
       "      <td>-0.000250</td>\n",
       "      <td>Quote from: Duzter on May 03, 2018, 10:58:04 P...</td>\n",
       "      <td>0.468739</td>\n",
       "      <td>3464694</td>\n",
       "      <td>Bitcoin is taking a breath</td>\n",
       "      <td>['investor', 'play', 'lot', 'role', 'crypto', ...</td>\n",
       "      <td>[77, 359, 43, 970, 48, 26, 840, 608, 347, 524,...</td>\n",
       "      <td>1525389780</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2018-05-03 23:28:00</th>\n",
       "      <td>57</td>\n",
       "      <td>bhadz</td>\n",
       "      <td>50</td>\n",
       "      <td>Let ETH push itself as it is just following bi...</td>\n",
       "      <td>9745.970833</td>\n",
       "      <td>9754.910000</td>\n",
       "      <td>0.095833</td>\n",
       "      <td>-0.000917</td>\n",
       "      <td>Quote from: firasbc on May 01, 2018, 10:54:36 ...</td>\n",
       "      <td>0.491667</td>\n",
       "      <td>3464694</td>\n",
       "      <td>Bitcoin is taking a breath</td>\n",
       "      <td>['let', 'eth', 'push', 'follow', 'path', 'posi...</td>\n",
       "      <td>[126, 375, 409, 245, 1351, 3423, 99, 325, 248,...</td>\n",
       "      <td>1525390080</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2018-05-03 23:30:00</th>\n",
       "      <td>57</td>\n",
       "      <td>figmentofmyass</td>\n",
       "      <td>487</td>\n",
       "      <td>that is not proper negative divergence. you're...</td>\n",
       "      <td>9742.360417</td>\n",
       "      <td>9754.904500</td>\n",
       "      <td>-0.100000</td>\n",
       "      <td>-0.001287</td>\n",
       "      <td>Quote from: xxxx123abcxxxx on May 02, 2018, 02...</td>\n",
       "      <td>0.166667</td>\n",
       "      <td>2711461</td>\n",
       "      <td>2018 Cryptocurrency Crash (Elliott Wave)</td>\n",
       "      <td>['proper', 'negative', 'divergence', 'ignore',...</td>\n",
       "      <td>[1069, 343, 3959, 1002, 867, 452, 109, 2668, 4...</td>\n",
       "      <td>1525390200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2018-05-03 23:41:00</th>\n",
       "      <td>57</td>\n",
       "      <td>xxxx123abcxxxx</td>\n",
       "      <td>488</td>\n",
       "      <td>Price/RSI divergences on the daily too, so qui...</td>\n",
       "      <td>9763.082917</td>\n",
       "      <td>9771.746000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>-0.000887</td>\n",
       "      <td>Quote from: figmentofmyass on May 03, 2018, 11...</td>\n",
       "      <td>0.125000</td>\n",
       "      <td>2711461</td>\n",
       "      <td>2018 Cryptocurrency Crash (Elliott Wave)</td>\n",
       "      <td>['price', 'rsi', 'divergence', 'daily', 'quite...</td>\n",
       "      <td>[1, 2956, 3959, 426, 239, 5917, 516, 187, 126,...</td>\n",
       "      <td>1525390860</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2018-05-03 23:42:00</th>\n",
       "      <td>57</td>\n",
       "      <td>Altas</td>\n",
       "      <td>251</td>\n",
       "      <td>That's true and unlike the market it is good t...</td>\n",
       "      <td>9760.919167</td>\n",
       "      <td>9775.504500</td>\n",
       "      <td>0.233333</td>\n",
       "      <td>-0.001493</td>\n",
       "      <td>Quote from: Bagaji on May 03, 2018, 11:17:22 P...</td>\n",
       "      <td>0.379167</td>\n",
       "      <td>3195183</td>\n",
       "      <td>is this right time to invest in BITCOIN..?</td>\n",
       "      <td>['true', 'unlike', 'market', 'good', 'make', '...</td>\n",
       "      <td>[185, 894, 10, 7, 11, 60, 712, 38, 60, 164, 16...</td>\n",
       "      <td>1525390920</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2018-05-03 23:45:00</th>\n",
       "      <td>57</td>\n",
       "      <td>Capt00</td>\n",
       "      <td>347</td>\n",
       "      <td>It might be a risk for us buying such price, I...</td>\n",
       "      <td>9753.210000</td>\n",
       "      <td>9767.653500</td>\n",
       "      <td>0.076190</td>\n",
       "      <td>-0.001480</td>\n",
       "      <td>Quote from: PalindromemordnilaP on May 01, 201...</td>\n",
       "      <td>0.611376</td>\n",
       "      <td>2962470</td>\n",
       "      <td>Will you buy Bitcoin at $20,000</td>\n",
       "      <td>['might', 'risk', 'buy', 'price', 'may', 'afra...</td>\n",
       "      <td>[84, 164, 6, 1, 59, 565, 111, 22, 13, 12, 82, ...</td>\n",
       "      <td>1525391100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2018-05-03 23:52:00</th>\n",
       "      <td>57</td>\n",
       "      <td>Gabb</td>\n",
       "      <td>12</td>\n",
       "      <td>I think that most of us who are involved in th...</td>\n",
       "      <td>9740.947917</td>\n",
       "      <td>9748.713500</td>\n",
       "      <td>0.218182</td>\n",
       "      <td>-0.000797</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.379196</td>\n",
       "      <td>3514500</td>\n",
       "      <td>we're pumpin right now</td>\n",
       "      <td>['involve', 'cryptocurrency', 'market', 'truly...</td>\n",
       "      <td>[484, 107, 10, 961, 1863, 1, 238, 925, 301, 46...</td>\n",
       "      <td>1525391520</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2018-05-03 23:58:00</th>\n",
       "      <td>57</td>\n",
       "      <td>Fedor07</td>\n",
       "      <td>80</td>\n",
       "      <td>Well , i also think that bitcoin will go up th...</td>\n",
       "      <td>9679.669167</td>\n",
       "      <td>9741.201500</td>\n",
       "      <td>0.107143</td>\n",
       "      <td>-0.006337</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.220476</td>\n",
       "      <td>3423482</td>\n",
       "      <td>Bitcoin increase again?</td>\n",
       "      <td>['well', 'also', 'go', 'year', 'exactly', 'las...</td>\n",
       "      <td>[53, 22, 2, 8, 369, 82, 8, 1170, 48, 43, 156, ...</td>\n",
       "      <td>1525391880</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2018-05-04 00:52:00</th>\n",
       "      <td>57</td>\n",
       "      <td>The_Dark_Knight</td>\n",
       "      <td>27</td>\n",
       "      <td>Except for those that do insider trading no on...</td>\n",
       "      <td>9620.774167</td>\n",
       "      <td>9626.655000</td>\n",
       "      <td>-0.120000</td>\n",
       "      <td>-0.000611</td>\n",
       "      <td>Quote from: onnz423 on May 03, 2018, 10:37:45 ...</td>\n",
       "      <td>0.620000</td>\n",
       "      <td>3243181</td>\n",
       "      <td>Will bitcoin come a low price..!?</td>\n",
       "      <td>['except', 'insider', 'trade', 'one', 'know', ...</td>\n",
       "      <td>[882, 2359, 55, 16, 15, 2, 12, 313, 9, 182, 78...</td>\n",
       "      <td>1525395120</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2018-05-04 01:11:00</th>\n",
       "      <td>57</td>\n",
       "      <td>icecube45</td>\n",
       "      <td>340</td>\n",
       "      <td>within the scope of bitcoin, increase (bullish...</td>\n",
       "      <td>9621.171250</td>\n",
       "      <td>9616.268000</td>\n",
       "      <td>0.129762</td>\n",
       "      <td>0.000510</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.644048</td>\n",
       "      <td>3167446</td>\n",
       "      <td>Will The Price Of Bitcoin Increase Forever?</td>\n",
       "      <td>['within', 'scope', 'rise', 'bullish', 'declin...</td>\n",
       "      <td>[315, 3087, 5, 496, 421, 838, 520, 1418, 1, 82...</td>\n",
       "      <td>1525396260</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2018-05-04 01:11:00</th>\n",
       "      <td>57</td>\n",
       "      <td>Barbarian</td>\n",
       "      <td>277</td>\n",
       "      <td>You are not wrong, but what happens is that th...</td>\n",
       "      <td>9621.171250</td>\n",
       "      <td>9616.268000</td>\n",
       "      <td>-0.011111</td>\n",
       "      <td>0.000510</td>\n",
       "      <td>Quote from: unknown_36 on October 16, 2017, 04...</td>\n",
       "      <td>0.524868</td>\n",
       "      <td>2277102</td>\n",
       "      <td>Selling Bitcoin</td>\n",
       "      <td>['wrong', 'happen', 'many', 'people', 'simply'...</td>\n",
       "      <td>[292, 12, 27, 3, 403, 493, 36, 2, 35, 38, 124,...</td>\n",
       "      <td>1525396260</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2018-05-04 01:17:00</th>\n",
       "      <td>57</td>\n",
       "      <td>Barbarian</td>\n",
       "      <td>303</td>\n",
       "      <td>We cannot simply look at the price at the begi...</td>\n",
       "      <td>9612.947083</td>\n",
       "      <td>9621.168500</td>\n",
       "      <td>0.083896</td>\n",
       "      <td>-0.000855</td>\n",
       "      <td>Quote from: gabmen on April 29, 2018, 03:05:51...</td>\n",
       "      <td>0.648942</td>\n",
       "      <td>2851491</td>\n",
       "      <td>Will 2018 be better than 2017 for bitcoin</td>\n",
       "      <td>['simply', 'look', 'price', 'begin', 'year', '...</td>\n",
       "      <td>[403, 66, 1, 267, 8, 109, 194, 1, 51, 8, 43, 3...</td>\n",
       "      <td>1525396620</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>351666 rows  15 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                     category_id   message_author  message_number  \\\n",
       "timestamp                                                           \n",
       "2016-01-01 00:57:00           57             elux             390   \n",
       "2016-01-01 01:00:00           57   The Pharmacist             391   \n",
       "2016-01-01 01:21:00           57        keystroke               3   \n",
       "2016-01-01 01:31:00           57          Hugroll             260   \n",
       "2016-01-01 01:52:00           57         prodigy8              71   \n",
       "2016-01-01 03:10:00            7         noone000              72   \n",
       "2016-01-01 03:31:00           57           kapguy             261   \n",
       "2016-01-01 05:11:00           57      r3t4rD4life               1   \n",
       "2016-01-01 05:13:00            7          pitham1               8   \n",
       "2016-01-01 05:17:00           57          pitham1               2   \n",
       "2016-01-01 05:20:00           57          pitham1              72   \n",
       "2016-01-01 05:22:00            7          pitham1             103   \n",
       "2016-01-01 05:41:00           57           pattu1              10   \n",
       "2016-01-01 05:42:00           57           pattu1              35   \n",
       "2016-01-01 05:46:00            7    erwin45hacked              41   \n",
       "2016-01-01 05:49:00           57           mtnsaa              11   \n",
       "2016-01-01 06:52:00           57           pattu1              12   \n",
       "2016-01-01 07:04:00           57          suda123              13   \n",
       "2016-01-01 08:56:00           57    --Encrypted--               3   \n",
       "2016-01-01 09:10:00           57         tokeweed              73   \n",
       "2016-01-01 09:10:00            7         Gotimour               9   \n",
       "2016-01-01 09:18:00           57            Alaki              74   \n",
       "2016-01-01 10:03:00           57          Juhagic              75   \n",
       "2016-01-01 10:11:00           57             enhu              76   \n",
       "2016-01-01 10:13:00           57            buddu              38   \n",
       "2016-01-01 10:19:00           57          fantoos              39   \n",
       "2016-01-01 10:25:00           57          Ekanenf              36   \n",
       "2016-01-01 10:57:00           57         1Referee              40   \n",
       "2016-01-01 11:03:00           57         1Referee              77   \n",
       "2016-01-01 11:12:00           57            lexuz              41   \n",
       "...                          ...              ...             ...   \n",
       "2018-05-03 22:45:00            7          Elrozaq             195   \n",
       "2018-05-03 22:46:00            7    weblouartisan             419   \n",
       "2018-05-03 22:48:00            7         Yamifoud             196   \n",
       "2018-05-03 22:49:00            7    weblouartisan             282   \n",
       "2018-05-03 22:52:00            7    weblouartisan             131   \n",
       "2018-05-03 22:54:00           57         laluna24              78   \n",
       "2018-05-03 22:55:00           57        Dingdong7              79   \n",
       "2018-05-03 22:58:00           57         Yamifoud             265   \n",
       "2018-05-03 22:58:00           57           Duzter              47   \n",
       "2018-05-03 22:59:00           57             Gabb              48   \n",
       "2018-05-03 22:59:00           57           Bagaji              23   \n",
       "2018-05-03 23:00:00           57           Pasnik             154   \n",
       "2018-05-03 23:02:00           57           Capt00             249   \n",
       "2018-05-03 23:06:00           57            Anait              11   \n",
       "2018-05-03 23:11:00           57             n0ne             266   \n",
       "2018-05-03 23:15:00           57            muf18             486   \n",
       "2018-05-03 23:17:00           57           Bagaji             250   \n",
       "2018-05-03 23:22:00           57         Happiest              23   \n",
       "2018-05-03 23:23:00           57        Biscutard              49   \n",
       "2018-05-03 23:28:00           57            bhadz              50   \n",
       "2018-05-03 23:30:00           57   figmentofmyass             487   \n",
       "2018-05-03 23:41:00           57   xxxx123abcxxxx             488   \n",
       "2018-05-03 23:42:00           57            Altas             251   \n",
       "2018-05-03 23:45:00           57           Capt00             347   \n",
       "2018-05-03 23:52:00           57             Gabb              12   \n",
       "2018-05-03 23:58:00           57          Fedor07              80   \n",
       "2018-05-04 00:52:00           57  The_Dark_Knight              27   \n",
       "2018-05-04 01:11:00           57        icecube45             340   \n",
       "2018-05-04 01:11:00           57        Barbarian             277   \n",
       "2018-05-04 01:17:00           57        Barbarian             303   \n",
       "\n",
       "                                                          message_text  \\\n",
       "timestamp                                                                \n",
       "2016-01-01 00:57:00  2016!!!!!!       We made it. Bitcoin is dead. ...   \n",
       "2016-01-01 01:00:00  A'ight bitch, you're quoted. Are you laying m...   \n",
       "2016-01-01 01:21:00        Cool! Looking forward to your comments. :)   \n",
       "2016-01-01 01:31:00  i dont think its going to go down anytime soon...   \n",
       "2016-01-01 01:52:00  If we check the last halving period then we ca...   \n",
       "2016-01-01 03:10:00  Bitcoin, in my opinion, will probably not repl...   \n",
       "2016-01-01 03:31:00  Why does everyone think the halving will creat...   \n",
       "2016-01-01 05:11:00  Buy and sell of a million+ coins at a time. Tu...   \n",
       "2016-01-01 05:13:00  When you say next year, do you mean 2016 or 20...   \n",
       "2016-01-01 05:17:00  There is no profit involved in these trades. I...   \n",
       "2016-01-01 05:20:00  Miners will just have to look at their variabl...   \n",
       "2016-01-01 05:22:00  1 BTC might be enough, but no harm in reaching...   \n",
       "2016-01-01 05:41:00  Pump and dump can be profitable for people who...   \n",
       "2016-01-01 05:42:00  Nope, I don't believe people are dumb enough t...   \n",
       "2016-01-01 05:46:00  Those that dont sell when prices moves down 20...   \n",
       "2016-01-01 05:49:00  Bitcoin market it's still vulnerable to p&d sc...   \n",
       "2016-01-01 06:52:00  Altcoin markets are way too easy given the lac...   \n",
       "2016-01-01 07:04:00                                                LOL   \n",
       "2016-01-01 08:56:00  I didn't know we all know that... where's the ...   \n",
       "2016-01-01 09:10:00  The. Sauron will get the ring.   http://media-...   \n",
       "2016-01-01 09:10:00  The price below $400 is good to buy. I think t...   \n",
       "2016-01-01 09:18:00  IMO , No price rise = Miners will not profit =...   \n",
       "2016-01-01 10:03:00  If there is no price rise, most S3 miners will...   \n",
       "2016-01-01 10:11:00  Haven't they look at this possibility already ...   \n",
       "2016-01-01 10:13:00  I don't think price will drop under 400 $ mark...   \n",
       "2016-01-01 10:19:00  Although can not say whether it is still bulli...   \n",
       "2016-01-01 10:25:00  Have you made any money from your prediction? ...   \n",
       "2016-01-01 10:57:00  Seeing the price go up from below $250 to righ...   \n",
       "2016-01-01 11:03:00  The price will rise anyway. If it's not done b...   \n",
       "2016-01-01 11:12:00  after seeing price on the charts today, i gues...   \n",
       "...                                                                ...   \n",
       "2018-05-03 22:45:00  The bitcoin is the best crypto, it is so popul...   \n",
       "2018-05-03 22:46:00  Actually you are just doing it well, trading o...   \n",
       "2018-05-03 22:48:00  Of course they know that bitcoin investment gr...   \n",
       "2018-05-03 22:49:00  It depends on the government, if the governmen...   \n",
       "2018-05-03 22:52:00  Bitcoin should be advertised on the television...   \n",
       "2018-05-03 22:54:00  This will surely increase again the price now ...   \n",
       "2018-05-03 22:55:00  Bitcoin price will really go higher than we ar...   \n",
       "2018-05-03 22:58:00  Definitely we could see a lot of surprise happ...   \n",
       "2018-05-03 22:58:00  Agreed, the investors who were the backbone ha...   \n",
       "2018-05-03 22:59:00  Today I was surprised by the remarkably bullis...   \n",
       "2018-05-03 22:59:00  As the trend of an upward movement of bitcoin ...   \n",
       "2018-05-03 23:00:00  This is good we have more users who believes i...   \n",
       "2018-05-03 23:02:00  If you have invested it earlier when prices ar...   \n",
       "2018-05-03 23:06:00  We can just expect good things to happen in th...   \n",
       "2018-05-03 23:11:00  Agreed, various predictions from experts have ...   \n",
       "2018-05-03 23:15:00  Well I guess stop is now taken away.  Trends a...   \n",
       "2018-05-03 23:17:00  From all indications bitcoin has not yet reach...   \n",
       "2018-05-03 23:22:00              Recently, it's hard to get good ICOs.   \n",
       "2018-05-03 23:23:00  Investors play a lot of role in crypto currenc...   \n",
       "2018-05-03 23:28:00  Let ETH push itself as it is just following bi...   \n",
       "2018-05-03 23:30:00  that is not proper negative divergence. you're...   \n",
       "2018-05-03 23:41:00  Price/RSI divergences on the daily too, so qui...   \n",
       "2018-05-03 23:42:00  That's true and unlike the market it is good t...   \n",
       "2018-05-03 23:45:00  It might be a risk for us buying such price, I...   \n",
       "2018-05-03 23:52:00  I think that most of us who are involved in th...   \n",
       "2018-05-03 23:58:00  Well , i also think that bitcoin will go up th...   \n",
       "2018-05-04 00:52:00  Except for those that do insider trading no on...   \n",
       "2018-05-04 01:11:00  within the scope of bitcoin, increase (bullish...   \n",
       "2018-05-04 01:11:00  You are not wrong, but what happens is that th...   \n",
       "2018-05-04 01:17:00  We cannot simply look at the price at the begi...   \n",
       "\n",
       "                      mins_after  mins_before  polarity  price_change  \\\n",
       "timestamp                                                               \n",
       "2016-01-01 00:57:00   430.588333   430.816000 -0.014773     -0.000529   \n",
       "2016-01-01 01:00:00   430.628333   430.619000  0.000000      0.000022   \n",
       "2016-01-01 01:21:00   430.336250   430.723000  0.468750     -0.000898   \n",
       "2016-01-01 01:31:00   430.347917   430.444000  0.114815     -0.000223   \n",
       "2016-01-01 01:52:00   430.753000   430.756250  0.228348     -0.000008   \n",
       "2016-01-01 03:10:00   430.936500   430.860000  0.093750      0.000178   \n",
       "2016-01-01 03:31:00   431.659000   431.885000  0.000000     -0.000523   \n",
       "2016-01-01 05:11:00   436.074167   436.019500  0.100000      0.000125   \n",
       "2016-01-01 05:13:00   436.005833   436.067000 -0.140625     -0.000140   \n",
       "2016-01-01 05:17:00   435.680000   436.061000  0.000000     -0.000874   \n",
       "2016-01-01 05:20:00   435.632083   435.887000  0.136364     -0.000585   \n",
       "2016-01-01 05:22:00   435.681500   435.706000  0.400000     -0.000056   \n",
       "2016-01-01 05:41:00   436.039167   435.916875 -0.200000      0.000280   \n",
       "2016-01-01 05:42:00   436.070000   435.922500 -0.101667      0.000338   \n",
       "2016-01-01 05:46:00   436.256000   436.018000 -0.018519      0.000546   \n",
       "2016-01-01 05:49:00   436.355000   436.118000 -0.020833      0.000543   \n",
       "2016-01-01 06:52:00   434.417500   434.100000  0.113889      0.000731   \n",
       "2016-01-01 07:04:00   435.912500   434.973750  0.800000      0.002156   \n",
       "2016-01-01 08:56:00   433.900833   434.880000  0.000000     -0.002254   \n",
       "2016-01-01 09:10:00   433.473333   433.560000  0.000000     -0.000200   \n",
       "2016-01-01 09:10:00   433.473333   433.560000  0.350000     -0.000200   \n",
       "2016-01-01 09:18:00   433.105833   433.378750  0.000000     -0.000630   \n",
       "2016-01-01 10:03:00   433.042500   433.010000  0.178333      0.000075   \n",
       "2016-01-01 10:11:00   433.039000   433.052500  0.042857     -0.000031   \n",
       "2016-01-01 10:13:00   432.997083   433.057500 -0.163889     -0.000140   \n",
       "2016-01-01 10:19:00   432.620000   432.994500  0.000000     -0.000865   \n",
       "2016-01-01 10:25:00   432.700000   432.556667 -0.500000      0.000331   \n",
       "2016-01-01 10:57:00   432.478500   432.222500  0.001720      0.000592   \n",
       "2016-01-01 11:03:00   432.310000   432.424375  0.107273     -0.000265   \n",
       "2016-01-01 11:12:00   432.403750   432.310000 -0.093182      0.000217   \n",
       "...                          ...          ...       ...           ...   \n",
       "2018-05-03 22:45:00  9628.070000  9629.955000  0.533333     -0.000196   \n",
       "2018-05-03 22:46:00  9627.499583  9629.995000  0.220238     -0.000259   \n",
       "2018-05-03 22:48:00  9629.531667  9629.995000  0.061667     -0.000048   \n",
       "2018-05-03 22:49:00  9633.339583  9629.224500  0.271429      0.000427   \n",
       "2018-05-03 22:52:00  9653.365417  9627.000500  0.100000      0.002735   \n",
       "2018-05-03 22:54:00  9666.236250  9630.209000  0.171818      0.003734   \n",
       "2018-05-03 22:55:00  9670.569583  9634.778500  0.350000      0.003708   \n",
       "2018-05-03 22:58:00  9677.481667  9657.859500  0.250000      0.002030   \n",
       "2018-05-03 22:58:00  9677.481667  9657.859500 -0.026948      0.002030   \n",
       "2018-05-03 22:59:00  9681.836667  9664.485000  0.102143      0.001794   \n",
       "2018-05-03 22:59:00  9681.836667  9664.485000  0.025000      0.001794   \n",
       "2018-05-03 23:00:00  9687.913333  9669.685000  0.433333      0.001883   \n",
       "2018-05-03 23:02:00  9701.035833  9674.646000 -0.070000      0.002724   \n",
       "2018-05-03 23:06:00  9744.966667  9690.497500  0.162500      0.005605   \n",
       "2018-05-03 23:11:00  9768.468333  9742.663000  0.170909      0.002645   \n",
       "2018-05-03 23:15:00  9767.387500  9763.042000 -0.004444      0.000445   \n",
       "2018-05-03 23:17:00  9759.733333  9770.865000  0.107143     -0.001140   \n",
       "2018-05-03 23:22:00  9754.919583  9760.686500  0.204167     -0.000591   \n",
       "2018-05-03 23:23:00  9754.909583  9757.345000  0.032584     -0.000250   \n",
       "2018-05-03 23:28:00  9745.970833  9754.910000  0.095833     -0.000917   \n",
       "2018-05-03 23:30:00  9742.360417  9754.904500 -0.100000     -0.001287   \n",
       "2018-05-03 23:41:00  9763.082917  9771.746000  0.000000     -0.000887   \n",
       "2018-05-03 23:42:00  9760.919167  9775.504500  0.233333     -0.001493   \n",
       "2018-05-03 23:45:00  9753.210000  9767.653500  0.076190     -0.001480   \n",
       "2018-05-03 23:52:00  9740.947917  9748.713500  0.218182     -0.000797   \n",
       "2018-05-03 23:58:00  9679.669167  9741.201500  0.107143     -0.006337   \n",
       "2018-05-04 00:52:00  9620.774167  9626.655000 -0.120000     -0.000611   \n",
       "2018-05-04 01:11:00  9621.171250  9616.268000  0.129762      0.000510   \n",
       "2018-05-04 01:11:00  9621.171250  9616.268000 -0.011111      0.000510   \n",
       "2018-05-04 01:17:00  9612.947083  9621.168500  0.083896     -0.000855   \n",
       "\n",
       "                                                           quoteheader  \\\n",
       "timestamp                                                                \n",
       "2016-01-01 00:57:00                                                NaN   \n",
       "2016-01-01 01:00:00  Quote from: elux on January 01, 2016, 12:57:06...   \n",
       "2016-01-01 01:21:00                                                NaN   \n",
       "2016-01-01 01:31:00  Quote from: roldstin on November 27, 2015, 04:...   \n",
       "2016-01-01 01:52:00  Quote from: avw1982 on December 28, 2015, 12:4...   \n",
       "2016-01-01 03:10:00                                                NaN   \n",
       "2016-01-01 03:31:00                                                NaN   \n",
       "2016-01-01 05:11:00                                                NaN   \n",
       "2016-01-01 05:13:00  Quote from: Cabdinsard on December 30, 2015, 1...   \n",
       "2016-01-01 05:17:00  Quote from: r3t4rD4life on January 01, 2016, 0...   \n",
       "2016-01-01 05:20:00  Quote from: wikenpp on December 31, 2015, 04:4...   \n",
       "2016-01-01 05:22:00  Quote from: helloeverybody on December 30, 201...   \n",
       "2016-01-01 05:41:00  Quote from: NorrisK on December 30, 2015, 06:2...   \n",
       "2016-01-01 05:42:00  Quote from: gkv9 on December 30, 2015, 03:54:0...   \n",
       "2016-01-01 05:46:00  Quote from: newcoins1978 on December 31, 2015,...   \n",
       "2016-01-01 05:49:00                                                NaN   \n",
       "2016-01-01 06:52:00  Quote from: mtnsaa on January 01, 2016, 05:49:...   \n",
       "2016-01-01 07:04:00  Quote from: r0ach on December 30, 2015, 04:20:...   \n",
       "2016-01-01 08:56:00                                                NaN   \n",
       "2016-01-01 09:10:00  Quote from: helloeverybody on December 26, 201...   \n",
       "2016-01-01 09:10:00  Quote from: mobnepal on December 30, 2015, 04:...   \n",
       "2016-01-01 09:18:00                                                NaN   \n",
       "2016-01-01 10:03:00                                                NaN   \n",
       "2016-01-01 10:11:00                                                NaN   \n",
       "2016-01-01 10:13:00                                                NaN   \n",
       "2016-01-01 10:19:00                                                NaN   \n",
       "2016-01-01 10:25:00  Quote from: talks_cheep on December 28, 2015, ...   \n",
       "2016-01-01 10:57:00  Quote from: fantoos on January 01, 2016, 10:19...   \n",
       "2016-01-01 11:03:00                                                NaN   \n",
       "2016-01-01 11:12:00                                                NaN   \n",
       "...                                                                ...   \n",
       "2018-05-03 22:45:00  Quote from: naphto on April 19, 2013, 08:04:15...   \n",
       "2018-05-03 22:46:00  Quote from: zarados on August 22, 2017, 01:20:...   \n",
       "2018-05-03 22:48:00                                                NaN   \n",
       "2018-05-03 22:49:00  Quote from: yselacreyo3 on December 24, 2017, ...   \n",
       "2018-05-03 22:52:00  Quote from: cutikanzilong on April 27, 2018, 0...   \n",
       "2018-05-03 22:54:00  Quote from: EARL MATEUS on May 03, 2018, 06:26...   \n",
       "2018-05-03 22:55:00  Quote from: Hui Ling on April 28, 2018, 03:08:...   \n",
       "2018-05-03 22:58:00                                                NaN   \n",
       "2018-05-03 22:58:00  Quote from: Capt00 on May 03, 2018, 10:42:43 P...   \n",
       "2018-05-03 22:59:00                                                NaN   \n",
       "2018-05-03 22:59:00                                                NaN   \n",
       "2018-05-03 23:00:00  Quote from: myhometalk on April 22, 2018, 07:2...   \n",
       "2018-05-03 23:02:00                                                NaN   \n",
       "2018-05-03 23:06:00                                                NaN   \n",
       "2018-05-03 23:11:00  Quote from: BUK2016 on May 03, 2018, 10:22:24 ...   \n",
       "2018-05-03 23:15:00                                                NaN   \n",
       "2018-05-03 23:17:00                                                NaN   \n",
       "2018-05-03 23:22:00                                                NaN   \n",
       "2018-05-03 23:23:00  Quote from: Duzter on May 03, 2018, 10:58:04 P...   \n",
       "2018-05-03 23:28:00  Quote from: firasbc on May 01, 2018, 10:54:36 ...   \n",
       "2018-05-03 23:30:00  Quote from: xxxx123abcxxxx on May 02, 2018, 02...   \n",
       "2018-05-03 23:41:00  Quote from: figmentofmyass on May 03, 2018, 11...   \n",
       "2018-05-03 23:42:00  Quote from: Bagaji on May 03, 2018, 11:17:22 P...   \n",
       "2018-05-03 23:45:00  Quote from: PalindromemordnilaP on May 01, 201...   \n",
       "2018-05-03 23:52:00                                                NaN   \n",
       "2018-05-03 23:58:00                                                NaN   \n",
       "2018-05-04 00:52:00  Quote from: onnz423 on May 03, 2018, 10:37:45 ...   \n",
       "2018-05-04 01:11:00                                                NaN   \n",
       "2018-05-04 01:11:00  Quote from: unknown_36 on October 16, 2017, 04...   \n",
       "2018-05-04 01:17:00  Quote from: gabmen on April 29, 2018, 03:05:51...   \n",
       "\n",
       "                     subjectivity  topic_id  \\\n",
       "timestamp                                     \n",
       "2016-01-01 00:57:00      0.427273   1061780   \n",
       "2016-01-01 01:00:00      0.000000   1061780   \n",
       "2016-01-01 01:21:00      0.825000   1310368   \n",
       "2016-01-01 01:31:00      0.262963   1266304   \n",
       "2016-01-01 01:52:00      0.517262   1304141   \n",
       "2016-01-01 03:10:00      0.406250   1237124   \n",
       "2016-01-01 03:31:00      0.533333   1266304   \n",
       "2016-01-01 05:11:00      1.000000   1310608   \n",
       "2016-01-01 05:13:00      0.609375   1304240   \n",
       "2016-01-01 05:17:00      0.000000   1310608   \n",
       "2016-01-01 05:20:00      0.454545   1304141   \n",
       "2016-01-01 05:22:00      0.700000   1253196   \n",
       "2016-01-01 05:41:00      0.450000   1309163   \n",
       "2016-01-01 05:42:00      0.533333   1306737   \n",
       "2016-01-01 05:46:00      0.396296   1304960   \n",
       "2016-01-01 05:49:00      0.582292   1309163   \n",
       "2016-01-01 06:52:00      0.722222   1309163   \n",
       "2016-01-01 07:04:00      0.700000   1309163   \n",
       "2016-01-01 08:56:00      0.000000   1310608   \n",
       "2016-01-01 09:10:00      0.000000   1304141   \n",
       "2016-01-01 09:10:00      0.300000   1304240   \n",
       "2016-01-01 09:18:00      0.000000   1304141   \n",
       "2016-01-01 10:03:00      0.471667   1304141   \n",
       "2016-01-01 10:11:00      0.445714   1304141   \n",
       "2016-01-01 10:13:00      0.213889   1309538   \n",
       "2016-01-01 10:19:00      1.000000   1309538   \n",
       "2016-01-01 10:25:00      1.000000   1306737   \n",
       "2016-01-01 10:57:00      0.358201   1309538   \n",
       "2016-01-01 11:03:00      0.470909   1304141   \n",
       "2016-01-01 11:12:00      0.483239   1309538   \n",
       "...                           ...       ...   \n",
       "2018-05-03 22:45:00      0.422222    180882   \n",
       "2018-05-03 22:46:00      0.461905   2109367   \n",
       "2018-05-03 22:48:00      0.328333    180882   \n",
       "2018-05-03 22:49:00      0.297959   2639457   \n",
       "2018-05-03 22:52:00      0.400000   3410399   \n",
       "2018-05-03 22:54:00      0.518586   3423482   \n",
       "2018-05-03 22:55:00      0.715556   3423482   \n",
       "2018-05-03 22:58:00      0.500000   3146568   \n",
       "2018-05-03 22:58:00      0.436364   3464694   \n",
       "2018-05-03 22:59:00      0.535476   3464694   \n",
       "2018-05-03 22:59:00      0.450000   3454537   \n",
       "2018-05-03 23:00:00      0.494444   3141148   \n",
       "2018-05-03 23:02:00      0.280000   3195183   \n",
       "2018-05-03 23:06:00      0.300000   3514500   \n",
       "2018-05-03 23:11:00      0.484935   3146568   \n",
       "2018-05-03 23:15:00      0.411111   2711461   \n",
       "2018-05-03 23:17:00      0.372143   3195183   \n",
       "2018-05-03 23:22:00      0.570833   2985611   \n",
       "2018-05-03 23:23:00      0.468739   3464694   \n",
       "2018-05-03 23:28:00      0.491667   3464694   \n",
       "2018-05-03 23:30:00      0.166667   2711461   \n",
       "2018-05-03 23:41:00      0.125000   2711461   \n",
       "2018-05-03 23:42:00      0.379167   3195183   \n",
       "2018-05-03 23:45:00      0.611376   2962470   \n",
       "2018-05-03 23:52:00      0.379196   3514500   \n",
       "2018-05-03 23:58:00      0.220476   3423482   \n",
       "2018-05-04 00:52:00      0.620000   3243181   \n",
       "2018-05-04 01:11:00      0.644048   3167446   \n",
       "2018-05-04 01:11:00      0.524868   2277102   \n",
       "2018-05-04 01:17:00      0.648942   2851491   \n",
       "\n",
       "                                                           topic_title  \\\n",
       "timestamp                                                                \n",
       "2016-01-01 00:57:00                                         Rally!!!!!   \n",
       "2016-01-01 01:00:00                                         Rally!!!!!   \n",
       "2016-01-01 01:21:00  Another way of looking at the halving, market ...   \n",
       "2016-01-01 01:31:00               When will this bitcoin will go down?   \n",
       "2016-01-01 01:52:00  What will happen if there's no price rise for ...   \n",
       "2016-01-01 03:10:00  POP QUIZ: Do you believe that BTC is the world...   \n",
       "2016-01-01 03:31:00               When will this bitcoin will go down?   \n",
       "2016-01-01 05:11:00  We all know huobi volume is faked, but what is...   \n",
       "2016-01-01 05:13:00  Bitcoin Price Slides 10% In PostXmas Selloff A...   \n",
       "2016-01-01 05:17:00  We all know huobi volume is faked, but what is...   \n",
       "2016-01-01 05:20:00  What will happen if there's no price rise for ...   \n",
       "2016-01-01 05:22:00              Anyone here part of \"1 million club\"?   \n",
       "2016-01-01 05:41:00                                        Pump + Dump   \n",
       "2016-01-01 05:42:00                           Another 10% Cut Incoming   \n",
       "2016-01-01 05:46:00                           #panicselling is so 1995   \n",
       "2016-01-01 05:49:00                                        Pump + Dump   \n",
       "2016-01-01 06:52:00                                        Pump + Dump   \n",
       "2016-01-01 07:04:00                                        Pump + Dump   \n",
       "2016-01-01 08:56:00  We all know huobi volume is faked, but what is...   \n",
       "2016-01-01 09:10:00  What will happen if there's no price rise for ...   \n",
       "2016-01-01 09:10:00  Bitcoin Price Slides 10% In PostXmas Selloff A...   \n",
       "2016-01-01 09:18:00  What will happen if there's no price rise for ...   \n",
       "2016-01-01 10:03:00  What will happen if there's no price rise for ...   \n",
       "2016-01-01 10:11:00  What will happen if there's no price rise for ...   \n",
       "2016-01-01 10:13:00                  $400 will not survive the weekend   \n",
       "2016-01-01 10:19:00                  $400 will not survive the weekend   \n",
       "2016-01-01 10:25:00                           Another 10% Cut Incoming   \n",
       "2016-01-01 10:57:00                  $400 will not survive the weekend   \n",
       "2016-01-01 11:03:00  What will happen if there's no price rise for ...   \n",
       "2016-01-01 11:12:00                  $400 will not survive the weekend   \n",
       "...                                                                ...   \n",
       "2018-05-03 22:45:00                   Why people are still buying BTC?   \n",
       "2018-05-03 22:46:00                   A wise strategy for your bitcoin   \n",
       "2018-05-03 22:48:00                   Why people are still buying BTC?   \n",
       "2018-05-03 22:49:00  Can cryptocurrencies make physical money disap...   \n",
       "2018-05-03 22:52:00                    bitcoin in developing countries   \n",
       "2018-05-03 22:54:00                            Bitcoin increase again?   \n",
       "2018-05-03 22:55:00                            Bitcoin increase again?   \n",
       "2018-05-03 22:58:00               What will happen to bitcoin in 2018?   \n",
       "2018-05-03 22:58:00                         Bitcoin is taking a breath   \n",
       "2018-05-03 22:59:00                         Bitcoin is taking a breath   \n",
       "2018-05-03 22:59:00         Analysis of the mid-term for Bitcoin price   \n",
       "2018-05-03 23:00:00                              Will bitcoin survive?   \n",
       "2018-05-03 23:02:00         is this right time to invest in BITCOIN..?   \n",
       "2018-05-03 23:06:00                             we're pumpin right now   \n",
       "2018-05-03 23:11:00               What will happen to bitcoin in 2018?   \n",
       "2018-05-03 23:15:00           2018 Cryptocurrency Crash (Elliott Wave)   \n",
       "2018-05-03 23:17:00         is this right time to invest in BITCOIN..?   \n",
       "2018-05-03 23:22:00     So, what's an ICO and why is it revolutionary?   \n",
       "2018-05-03 23:23:00                         Bitcoin is taking a breath   \n",
       "2018-05-03 23:28:00                         Bitcoin is taking a breath   \n",
       "2018-05-03 23:30:00           2018 Cryptocurrency Crash (Elliott Wave)   \n",
       "2018-05-03 23:41:00           2018 Cryptocurrency Crash (Elliott Wave)   \n",
       "2018-05-03 23:42:00         is this right time to invest in BITCOIN..?   \n",
       "2018-05-03 23:45:00                    Will you buy Bitcoin at $20,000   \n",
       "2018-05-03 23:52:00                             we're pumpin right now   \n",
       "2018-05-03 23:58:00                            Bitcoin increase again?   \n",
       "2018-05-04 00:52:00                  Will bitcoin come a low price..!?   \n",
       "2018-05-04 01:11:00        Will The Price Of Bitcoin Increase Forever?   \n",
       "2018-05-04 01:11:00                                    Selling Bitcoin   \n",
       "2018-05-04 01:17:00          Will 2018 be better than 2017 for bitcoin   \n",
       "\n",
       "                                                       cleaned_message  \\\n",
       "timestamp                                                                \n",
       "2016-01-01 00:57:00           ['make', 'dead', 'new', 'year', 'quote']   \n",
       "2016-01-01 01:00:00  ['ight', 'bitch', 'quote', 'lay', 'money', 'pr...   \n",
       "2016-01-01 01:21:00             ['cool', 'look', 'forward', 'comment']   \n",
       "2016-01-01 01:31:00  ['dont', 'go', 'go', 'anytime', 'soon', 'halfi...   \n",
       "2016-01-01 01:52:00  ['check', 'last', 'halve', 'period', 'see', 'p...   \n",
       "2016-01-01 03:10:00  ['opinion', 'probably', 'replace', 'mean', 'tr...   \n",
       "2016-01-01 03:31:00  ['everyone', 'halve', 'create', 'instant', 'ju...   \n",
       "2016-01-01 05:11:00  ['buy', 'sell', 'million', 'coin', 'time', 'tu...   \n",
       "2016-01-01 05:13:00  ['say', 'next', 'year', 'mean', 'people', 'dis...   \n",
       "2016-01-01 05:17:00  ['profit', 'involve', 'trade', 'coin', 'move',...   \n",
       "2016-01-01 05:20:00  ['mine', 'look', 'variable', 'cost', 'electric...   \n",
       "2016-01-01 05:22:00  ['bitcoin', 'might', 'enough', 'harm', 'reach'...   \n",
       "2016-01-01 05:41:00  ['pump', 'dump', 'profitable', 'people', 'impl...   \n",
       "2016-01-01 05:42:00  ['nope', 'don', 'believe', 'people', 'dumb', '...   \n",
       "2016-01-01 05:46:00  ['dont', 'sell', 'price', 'move', 'day', 'abso...   \n",
       "2016-01-01 05:49:00  ['market', 'still', 'vulnerable', 'scheme', 'c...   \n",
       "2016-01-01 06:52:00  ['altcoin', 'market', 'way', 'easy', 'give', '...   \n",
       "2016-01-01 07:04:00                                            ['lol']   \n",
       "2016-01-01 08:56:00                  ['didn', 'know', 'know', 'proof']   \n",
       "2016-01-01 09:10:00  ['sauron', 'ring', 'medium', 'cache', 'ak', 'p...   \n",
       "2016-01-01 09:10:00  ['price', 'good', 'buy', 'price', 'go', 'trade...   \n",
       "2016-01-01 09:18:00  ['imo', 'price', 'rise', 'mine', 'profit', 'gr...   \n",
       "2016-01-01 10:03:00  ['price', 'rise', 'mine', 'shutdown', 'due', '...   \n",
       "2016-01-01 10:11:00  ['haven', 'look', 'possibility', 'already', 'p...   \n",
       "2016-01-01 10:13:00  ['don', 'price', 'drop', 'mark', 'look', 'perf...   \n",
       "2016-01-01 10:19:00  ['although', 'say', 'whether', 'still', 'bulli...   \n",
       "2016-01-01 10:25:00  ['make', 'money', 'prediction', 'price', 'vola...   \n",
       "2016-01-01 10:57:00  ['see', 'price', 'go', 'right', 'exactly', 'co...   \n",
       "2016-01-01 11:03:00  ['price', 'rise', 'anyway', 'legit', 'growth',...   \n",
       "2016-01-01 11:12:00  ['see', 'price', 'chart', 'today', 'guess', 'p...   \n",
       "...                                                                ...   \n",
       "2018-05-03 22:45:00  ['best', 'crypto', 'popular', 'see', 'last', '...   \n",
       "2018-05-03 22:46:00  ['actually', 'well', 'trade', 'right', 'time',...   \n",
       "2018-05-03 22:48:00  ['course', 'know', 'investment', 'grow', 'real...   \n",
       "2018-05-03 22:49:00  ['depend', 'government', 'government', 'allow'...   \n",
       "2018-05-03 22:52:00  ['advertise', 'television', 'company', 'accept...   \n",
       "2018-05-03 22:54:00  ['surely', 'rise', 'price', 'go', 'high', 'pos...   \n",
       "2018-05-03 22:55:00  ['price', 'really', 'go', 'high', 'expect', 'p...   \n",
       "2018-05-03 22:58:00  ['definitely', 'see', 'lot', 'surprise', 'happ...   \n",
       "2018-05-03 22:58:00  ['agree', 'investor', 'backbone', 'felt', 'muc...   \n",
       "2018-05-03 22:59:00  ['today', 'surprise', 'remarkably', 'bullish',...   \n",
       "2018-05-03 22:59:00  ['trend', 'upward', 'movement', 'value', 'begi...   \n",
       "2018-05-03 23:00:00  ['good', 'user', 'belief', 'day', 'moment', 's...   \n",
       "2018-05-03 23:02:00  ['invest', 'early', 'price', 'least', 'bug', '...   \n",
       "2018-05-03 23:06:00  ['expect', 'good', 'thing', 'happen', 'upcomin...   \n",
       "2018-05-03 23:11:00  ['agree', 'various', 'prediction', 'expert', '...   \n",
       "2018-05-03 23:15:00  ['well', 'guess', 'stop', 'take', 'away', 'tre...   \n",
       "2018-05-03 23:17:00  ['indication', 'yet', 'reach', 'real', 'value'...   \n",
       "2018-05-03 23:22:00               ['recently', 'hard', 'good', 'icos']   \n",
       "2018-05-03 23:23:00  ['investor', 'play', 'lot', 'role', 'crypto', ...   \n",
       "2018-05-03 23:28:00  ['let', 'eth', 'push', 'follow', 'path', 'posi...   \n",
       "2018-05-03 23:30:00  ['proper', 'negative', 'divergence', 'ignore',...   \n",
       "2018-05-03 23:41:00  ['price', 'rsi', 'divergence', 'daily', 'quite...   \n",
       "2018-05-03 23:42:00  ['true', 'unlike', 'market', 'good', 'make', '...   \n",
       "2018-05-03 23:45:00  ['might', 'risk', 'buy', 'price', 'may', 'afra...   \n",
       "2018-05-03 23:52:00  ['involve', 'cryptocurrency', 'market', 'truly...   \n",
       "2018-05-03 23:58:00  ['well', 'also', 'go', 'year', 'exactly', 'las...   \n",
       "2018-05-04 00:52:00  ['except', 'insider', 'trade', 'one', 'know', ...   \n",
       "2018-05-04 01:11:00  ['within', 'scope', 'rise', 'bullish', 'declin...   \n",
       "2018-05-04 01:11:00  ['wrong', 'happen', 'many', 'people', 'simply'...   \n",
       "2018-05-04 01:17:00  ['simply', 'look', 'price', 'begin', 'year', '...   \n",
       "\n",
       "                                                        word_to_vec_id  \\\n",
       "timestamp                                                                \n",
       "2016-01-01 00:57:00                             [11, 803, 58, 8, 1226]   \n",
       "2016-01-01 01:00:00                 [28584, 3782, 1226, 2423, 14, 204]   \n",
       "2016-01-01 01:21:00                               [1252, 66, 651, 783]   \n",
       "2016-01-01 01:31:00  [148, 2, 2, 592, 97, 4195, 22, 395, 12, 69, 8,...   \n",
       "2016-01-01 01:52:00  [436, 82, 105, 334, 9, 1, 338, 106, 43, 105, 1...   \n",
       "2016-01-01 03:10:00  [180, 140, 540, 74, 101, 1286, 140, 80, 2191, ...   \n",
       "2016-01-01 03:31:00  [136, 105, 172, 1437, 469, 1, 64, 5384, 129, 1...   \n",
       "2016-01-01 05:11:00      [6, 17, 268, 24, 4, 373, 38, 22, 1180, 65024]   \n",
       "2016-01-01 05:13:00                  [30, 69, 8, 74, 3, 1214, 1, 1633]   \n",
       "2016-01-01 05:17:00  [38, 484, 55, 24, 122, 16, 1356, 112, 75, 101,...   \n",
       "2016-01-01 05:20:00  [89, 66, 2184, 340, 866, 59, 58, 89, 41, 10, 1...   \n",
       "2016-01-01 05:22:00         [19, 84, 162, 1596, 42, 37, 53, 34, 7, 33]   \n",
       "2016-01-01 05:41:00  [114, 94, 380, 3, 635, 243, 1858, 490, 84, 178...   \n",
       "2016-01-01 05:42:00  [1610, 23, 67, 3, 1359, 162, 67, 135, 10, 172,...   \n",
       "2016-01-01 05:46:00  [148, 17, 1, 122, 40, 752, 1218, 47, 5357, 290...   \n",
       "2016-01-01 05:49:00  [10, 21, 2304, 900, 176, 2316, 32, 757, 1356, ...   \n",
       "2016-01-01 06:52:00  [283, 10, 47, 199, 76, 778, 1461, 76, 10, 381,...   \n",
       "2016-01-01 07:04:00                                              [459]   \n",
       "2016-01-01 08:56:00                                 [338, 15, 15, 959]   \n",
       "2016-01-01 09:10:00        [28580, 3462, 339, 5329, 6022, 8045, 35295]   \n",
       "2016-01-01 09:10:00                  [1, 7, 6, 1, 2, 160, 41, 52, 935]   \n",
       "2016-01-01 09:18:00                     [777, 1, 5, 89, 38, 198, 3362]   \n",
       "2016-01-01 10:03:00             [1, 5, 89, 2743, 170, 380, 866, 1, 18]   \n",
       "2016-01-01 10:11:00  [620, 66, 313, 64, 280, 1292, 13, 17, 637, 89,...   \n",
       "2016-01-01 10:13:00  [23, 1, 70, 376, 66, 1236, 1, 120, 52, 1, 338,...   \n",
       "2016-01-01 10:19:00  [331, 30, 354, 21, 496, 50, 838, 1, 566, 22, 3...   \n",
       "2016-01-01 10:25:00                 [11, 14, 204, 1, 332, 358, 11, 14]   \n",
       "2016-01-01 10:57:00  [9, 1, 2, 39, 369, 197, 838, 110, 1, 1020, 438...   \n",
       "2016-01-01 11:03:00  [1, 5, 443, 1269, 198, 272, 75, 466, 1, 13, 26...   \n",
       "2016-01-01 11:12:00  [9, 1, 286, 132, 194, 1, 266, 270, 47, 74, 1, ...   \n",
       "...                                                                ...   \n",
       "2018-05-03 22:45:00  [103, 48, 401, 9, 82, 8, 3, 21, 24278, 21362, ...   \n",
       "2018-05-03 22:46:00  [138, 53, 55, 39, 4, 11, 77, 80, 230, 72, 160,...   \n",
       "2018-05-03 22:48:00  [176, 15, 60, 118, 29, 191, 38, 3, 30, 60, 529...   \n",
       "2018-05-03 22:49:00  [173, 73, 73, 394, 107, 766, 159, 84, 29, 2, 7...   \n",
       "2018-05-03 22:52:00  [1073, 3234, 255, 147, 107, 144, 179, 3, 207, ...   \n",
       "2018-05-03 22:54:00  [285, 5, 1, 2, 18, 270, 873, 59, 731, 592, 317...   \n",
       "2018-05-03 22:55:00  [1, 29, 2, 18, 78, 1, 84, 70, 106, 249, 33, 57...   \n",
       "2018-05-03 22:58:00  [243, 9, 43, 353, 12, 1, 615, 140, 11, 238, 44...   \n",
       "2018-05-03 22:58:00  [155, 77, 4140, 1433, 34, 121, 1, 2, 61, 1, 26...   \n",
       "2018-05-03 22:59:00  [132, 353, 6370, 496, 1381, 120, 78, 276, 332,...   \n",
       "2018-05-03 22:59:00  [221, 932, 282, 25, 267, 1521, 1001, 100, 379,...   \n",
       "2018-05-03 23:00:00  [7, 119, 974, 40, 187, 566, 511, 480, 1640, 25...   \n",
       "2018-05-03 23:02:00  [31, 235, 1, 202, 2021, 93, 132, 1, 122, 615, ...   \n",
       "2018-05-03 23:06:00  [78, 7, 33, 12, 695, 5803, 4, 216, 1, 114, 12,...   \n",
       "2018-05-03 23:11:00  [155, 837, 204, 613, 294, 42, 58, 8, 676, 366,...   \n",
       "2018-05-03 23:15:00  [53, 194, 192, 45, 346, 221, 2, 353, 137, 29, ...   \n",
       "2018-05-03 23:17:00  [1663, 190, 42, 131, 25, 74, 39, 16, 31, 591, ...   \n",
       "2018-05-03 23:22:00                                  [549, 91, 7, 608]   \n",
       "2018-05-03 23:23:00  [77, 359, 43, 970, 48, 26, 840, 608, 347, 524,...   \n",
       "2018-05-03 23:28:00  [126, 375, 409, 245, 1351, 3423, 99, 325, 248,...   \n",
       "2018-05-03 23:30:00  [1069, 343, 3959, 1002, 867, 452, 109, 2668, 4...   \n",
       "2018-05-03 23:41:00  [1, 2956, 3959, 426, 239, 5917, 516, 187, 126,...   \n",
       "2018-05-03 23:42:00  [185, 894, 10, 7, 11, 60, 712, 38, 60, 164, 16...   \n",
       "2018-05-03 23:45:00  [84, 164, 6, 1, 59, 565, 111, 22, 13, 12, 82, ...   \n",
       "2018-05-03 23:52:00  [484, 107, 10, 961, 1863, 1, 238, 925, 301, 46...   \n",
       "2018-05-03 23:58:00  [53, 22, 2, 8, 369, 82, 8, 1170, 48, 43, 156, ...   \n",
       "2018-05-04 00:52:00  [882, 2359, 55, 16, 15, 2, 12, 313, 9, 182, 78...   \n",
       "2018-05-04 01:11:00  [315, 3087, 5, 496, 421, 838, 520, 1418, 1, 82...   \n",
       "2018-05-04 01:11:00  [292, 12, 27, 3, 403, 493, 36, 2, 35, 38, 124,...   \n",
       "2018-05-04 01:17:00  [403, 66, 1, 267, 8, 109, 194, 1, 51, 8, 43, 3...   \n",
       "\n",
       "                           unix  \n",
       "timestamp                        \n",
       "2016-01-01 00:57:00  1451609820  \n",
       "2016-01-01 01:00:00  1451610000  \n",
       "2016-01-01 01:21:00  1451611260  \n",
       "2016-01-01 01:31:00  1451611860  \n",
       "2016-01-01 01:52:00  1451613120  \n",
       "2016-01-01 03:10:00  1451617800  \n",
       "2016-01-01 03:31:00  1451619060  \n",
       "2016-01-01 05:11:00  1451625060  \n",
       "2016-01-01 05:13:00  1451625180  \n",
       "2016-01-01 05:17:00  1451625420  \n",
       "2016-01-01 05:20:00  1451625600  \n",
       "2016-01-01 05:22:00  1451625720  \n",
       "2016-01-01 05:41:00  1451626860  \n",
       "2016-01-01 05:42:00  1451626920  \n",
       "2016-01-01 05:46:00  1451627160  \n",
       "2016-01-01 05:49:00  1451627340  \n",
       "2016-01-01 06:52:00  1451631120  \n",
       "2016-01-01 07:04:00  1451631840  \n",
       "2016-01-01 08:56:00  1451638560  \n",
       "2016-01-01 09:10:00  1451639400  \n",
       "2016-01-01 09:10:00  1451639400  \n",
       "2016-01-01 09:18:00  1451639880  \n",
       "2016-01-01 10:03:00  1451642580  \n",
       "2016-01-01 10:11:00  1451643060  \n",
       "2016-01-01 10:13:00  1451643180  \n",
       "2016-01-01 10:19:00  1451643540  \n",
       "2016-01-01 10:25:00  1451643900  \n",
       "2016-01-01 10:57:00  1451645820  \n",
       "2016-01-01 11:03:00  1451646180  \n",
       "2016-01-01 11:12:00  1451646720  \n",
       "...                         ...  \n",
       "2018-05-03 22:45:00  1525387500  \n",
       "2018-05-03 22:46:00  1525387560  \n",
       "2018-05-03 22:48:00  1525387680  \n",
       "2018-05-03 22:49:00  1525387740  \n",
       "2018-05-03 22:52:00  1525387920  \n",
       "2018-05-03 22:54:00  1525388040  \n",
       "2018-05-03 22:55:00  1525388100  \n",
       "2018-05-03 22:58:00  1525388280  \n",
       "2018-05-03 22:58:00  1525388280  \n",
       "2018-05-03 22:59:00  1525388340  \n",
       "2018-05-03 22:59:00  1525388340  \n",
       "2018-05-03 23:00:00  1525388400  \n",
       "2018-05-03 23:02:00  1525388520  \n",
       "2018-05-03 23:06:00  1525388760  \n",
       "2018-05-03 23:11:00  1525389060  \n",
       "2018-05-03 23:15:00  1525389300  \n",
       "2018-05-03 23:17:00  1525389420  \n",
       "2018-05-03 23:22:00  1525389720  \n",
       "2018-05-03 23:23:00  1525389780  \n",
       "2018-05-03 23:28:00  1525390080  \n",
       "2018-05-03 23:30:00  1525390200  \n",
       "2018-05-03 23:41:00  1525390860  \n",
       "2018-05-03 23:42:00  1525390920  \n",
       "2018-05-03 23:45:00  1525391100  \n",
       "2018-05-03 23:52:00  1525391520  \n",
       "2018-05-03 23:58:00  1525391880  \n",
       "2018-05-04 00:52:00  1525395120  \n",
       "2018-05-04 01:11:00  1525396260  \n",
       "2018-05-04 01:11:00  1525396260  \n",
       "2018-05-04 01:17:00  1525396620  \n",
       "\n",
       "[351666 rows x 15 columns]"
      ]
     },
     "execution_count": 123,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import json\n",
    "word_to_vec_data = [json.loads(elem) for elem in word_to_vec_data]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "price_label = price_label*1000"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "price_label = [-1 if elem <= -1 else elem for elem in price_label ]\n",
    "price_label = [1 if elem >= 1 else elem for elem in price_label ]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array([89868., 11345., 14080., 18875., 32849., 37072., 22085., 16630.,\n",
       "        13124., 95738.]),\n",
       " array([-1. , -0.8, -0.6, -0.4, -0.2,  0. ,  0.2,  0.4,  0.6,  0.8,  1. ]),\n",
       " <a list of 10 Patch objects>)"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "plt.hist(price_label)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Train/Test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[   11   803    58 ... 78991 78991 78991]\n",
      " [28584  3782  1226 ... 78991 78991 78991]\n",
      " [ 1252    66   651 ... 78991 78991 78991]\n",
      " ...\n",
      " [  315  3087     5 ... 78991 78991 78991]\n",
      " [  292    12    27 ... 78991 78991 78991]\n",
      " [  403    66     1 ... 78991 78991 78991]]\n"
     ]
    }
   ],
   "source": [
    "emb_len = len( np.loadtxt('embedding_matrix.txt', dtype=float))\n",
    "padded_docs = pad_sequences(word_to_vec_data, maxlen=150, padding='post', value=emb_len)\n",
    "print(padded_docs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# divide to train test validation sets (80% 10% 10%)\n",
    "additional_data = df[['polarity', 'subjectivity', 'unix', 'topic_id']].values\n",
    "\n",
    "X_train, X_test, y_train, y_test, additional_train, additional_test = train_test_split(padded_docs, price_label, additional_data, test_size=0.3, random_state=1)\n",
    "\n",
    "X_train, X_val, y_train, y_val, additional_train, additional_val = train_test_split(X_train, y_train, additional_train, test_size=0.1, random_state=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "ll = [len(elem) for elem in padded_docs]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array([     0.,      0.,      0.,      0.,      0.,      0.,      0.,\n",
       "             0.,      0.,      0.,      0.,      0.,      0.,      0.,\n",
       "             0.,      0.,      0.,      0.,      0.,      0.,      0.,\n",
       "             0.,      0.,      0.,      0.,      0.,      0.,      0.,\n",
       "             0.,      0.,      0.,      0.,      0.,      0.,      0.,\n",
       "             0.,      0.,      0.,      0.,      0.,      0.,      0.,\n",
       "             0.,      0.,      0.,      0.,      0.,      0.,      0.,\n",
       "             0., 351666.,      0.,      0.,      0.,      0.,      0.,\n",
       "             0.,      0.,      0.,      0.,      0.,      0.,      0.,\n",
       "             0.,      0.,      0.,      0.,      0.,      0.,      0.,\n",
       "             0.,      0.,      0.,      0.,      0.,      0.,      0.,\n",
       "             0.,      0.,      0.,      0.,      0.,      0.,      0.,\n",
       "             0.,      0.,      0.,      0.,      0.,      0.,      0.,\n",
       "             0.,      0.,      0.,      0.,      0.,      0.,      0.,\n",
       "             0.,      0.]),\n",
       " array([149.5 , 149.51, 149.52, 149.53, 149.54, 149.55, 149.56, 149.57,\n",
       "        149.58, 149.59, 149.6 , 149.61, 149.62, 149.63, 149.64, 149.65,\n",
       "        149.66, 149.67, 149.68, 149.69, 149.7 , 149.71, 149.72, 149.73,\n",
       "        149.74, 149.75, 149.76, 149.77, 149.78, 149.79, 149.8 , 149.81,\n",
       "        149.82, 149.83, 149.84, 149.85, 149.86, 149.87, 149.88, 149.89,\n",
       "        149.9 , 149.91, 149.92, 149.93, 149.94, 149.95, 149.96, 149.97,\n",
       "        149.98, 149.99, 150.  , 150.01, 150.02, 150.03, 150.04, 150.05,\n",
       "        150.06, 150.07, 150.08, 150.09, 150.1 , 150.11, 150.12, 150.13,\n",
       "        150.14, 150.15, 150.16, 150.17, 150.18, 150.19, 150.2 , 150.21,\n",
       "        150.22, 150.23, 150.24, 150.25, 150.26, 150.27, 150.28, 150.29,\n",
       "        150.3 , 150.31, 150.32, 150.33, 150.34, 150.35, 150.36, 150.37,\n",
       "        150.38, 150.39, 150.4 , 150.41, 150.42, 150.43, 150.44, 150.45,\n",
       "        150.46, 150.47, 150.48, 150.49, 150.5 ]),\n",
       " <a list of 100 Patch objects>)"
      ]
     },
     "execution_count": 126,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "plt.hist(ll, bins = 100)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Dictionary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "word_space_df[0] = [ww[8:] if type(ww) != float else str(ww) for ww in word_space_df[0] ]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 128,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "words_dict = word_space_df[0].to_dict()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 129,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "words_dict = dict(zip(words_dict.values(), words_dict.keys()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 151,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# import json \n",
    "# with open('word_dict.json', 'w') as outfile:\n",
    "#     json.dump(words_dict, outfile)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 130,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "with open('word_dict.json') as json_data:\n",
    "    words_dict_test = json.load(json_data)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "----------"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# LSTM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 131,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from keras.layers import Dense, Activation, Embedding, Flatten, Dropout, TimeDistributed, Reshape, Lambda\n",
    "from keras.layers import LSTM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 132,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "embedding_matrix = np.loadtxt('embedding_matrix.txt', dtype=float)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 133,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "zero_padding_embedding = (np.zeros(len(embedding_matrix[0]), dtype=float))\n",
    "embedding_matrix = np.row_stack([embedding_matrix, zero_padding_embedding])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 134,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "hidden_size = 8 #25\n",
    "use_dropout=True"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "-----------"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 135,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from keras.layers import Input, Embedding, LSTM, Dense, concatenate\n",
    "from keras.models import Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 157,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "main_input = Input(shape=(100,), dtype='int32', name='main_input')\n",
    "\n",
    "# This embedding layer will encode the input sequence\n",
    "# into a sequence of dense 512-dimensional vectors.\n",
    "# x = Embedding(output_dim=512, input_dim=10000, input_length=100)(main_input)\n",
    "\n",
    "main_input = Input(shape=(150,), dtype='int32', name='main_input')\n",
    "x = Embedding(output_dim = len(embedding_matrix[0]), input_dim = len(embedding_matrix),\n",
    "                    weights=[embedding_matrix], input_length = 150, trainable=False)(main_input)\n",
    "# A LSTM will transform the vector sequence into a single vector,\n",
    "# containing information about the entire sequence\n",
    "lstm_out = LSTM(units = 50)(x)\n",
    "\n",
    "# model.add(Dense(1, activation='sigmoid'))\n",
    "auxiliary_output = Dense(1, activation='sigmoid', name='aux_output')(lstm_out)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 158,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 159,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "auxiliary_input = Input(shape=(4,), name='aux_input')\n",
    "x = concatenate([lstm_out, auxiliary_input])\n",
    "\n",
    "# We stack a deep densely-connected network on top\n",
    "x = Dense(1024, activation='tanh')(x)\n",
    "x = Dense(1024, activation='tanh')(x)\n",
    "x = Dense(1024, activation='tanh')(x)\n",
    "x = Dense(1024, activation='tanh')(x)\n",
    "x = Dense(1024, activation='tanh')(x)\n",
    "x = Dense(1024, activation='tanh')(x)\n",
    "\n",
    "# And finally we add the main logistic regression layer\n",
    "main_output = Dense(1, activation='tanh', name='main_output')(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 160,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "model = Model(inputs=[main_input, auxiliary_input], outputs=[main_output])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 161,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "model.compile(optimizer='rmsprop', loss='mean_squared_error', metrics=['accuracy'])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 162,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "221549/221549 [==============================] - 618s 3ms/step - loss: 1.5286 - acc: 0.2416\n",
      "Epoch 2/10\n",
      "221549/221549 [==============================] - 720s 3ms/step - loss: 1.5289 - acc: 0.2416\n",
      "Epoch 3/10\n",
      "221549/221549 [==============================] - 872s 4ms/step - loss: 1.5289 - acc: 0.2416\n",
      "Epoch 4/10\n",
      "221549/221549 [==============================] - 824s 4ms/step - loss: 1.5289 - acc: 0.2416\n",
      "Epoch 5/10\n",
      "221549/221549 [==============================] - 839s 4ms/step - loss: 1.5289 - acc: 0.2416\n",
      "Epoch 6/10\n",
      "221549/221549 [==============================] - 621s 3ms/step - loss: 1.5289 - acc: 0.2416\n",
      "Epoch 7/10\n",
      "221549/221549 [==============================] - 1471s 7ms/step - loss: 1.5289 - acc: 0.2416\n",
      "Epoch 8/10\n",
      "221549/221549 [==============================] - 633s 3ms/step - loss: 1.5289 - acc: 0.2416\n",
      "Epoch 9/10\n",
      "221549/221549 [==============================] - 633s 3ms/step - loss: 1.5289 - acc: 0.2416\n",
      "Epoch 10/10\n",
      "221549/221549 [==============================] - 634s 3ms/step - loss: 1.5289 - acc: 0.2416\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x1a56276f28>"
      ]
     },
     "execution_count": 162,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit([np.array(X_train), additional_train], [np.array(y_train)],\n",
    "          epochs=10, batch_size=64)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 167,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "main_input (InputLayer)         (None, 150)          0                                            \n",
      "__________________________________________________________________________________________________\n",
      "embedding_15 (Embedding)        (None, 150, 50)      3949600     main_input[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "lstm_15 (LSTM)                  (None, 50)           20200       embedding_15[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "aux_input (InputLayer)          (None, 4)            0                                            \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_17 (Concatenate)    (None, 54)           0           lstm_15[0][0]                    \n",
      "                                                                 aux_input[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "dense_66 (Dense)                (None, 1024)         56320       concatenate_17[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "dense_67 (Dense)                (None, 1024)         1049600     dense_66[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "dense_68 (Dense)                (None, 1024)         1049600     dense_67[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "dense_69 (Dense)                (None, 1024)         1049600     dense_68[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "dense_70 (Dense)                (None, 1024)         1049600     dense_69[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "dense_71 (Dense)                (None, 1024)         1049600     dense_70[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "main_output (Dense)             (None, 1)            1025        dense_71[0][0]                   \n",
      "==================================================================================================\n",
      "Total params: 9,275,145\n",
      "Trainable params: 5,325,545\n",
      "Non-trainable params: 3,949,600\n",
      "__________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "with open(\"model_result.json\", \"w\") as json_file:\n",
    "    json_file.write(model_json)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 163,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from keras.models import model_from_json"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 165,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "sss = model.to_json()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 169,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(\"model_result.json\", \"w\") as json_file:\n",
    "    json_file.write(sss)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# additional_data = df[['polarity', 'subjectivity']].values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "221549"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "221549"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(np.array(X_train))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len([np.array(X_train), additional_data])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "150"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(X_train[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "351666"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(additional_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "0.58^2  0.2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# model = Sequential()\n",
    "# model.add(Embedding(len(embedding_matrix), len(embedding_matrix[0]), \n",
    "#                     weights=[embedding_matrix], input_length= 1, trainable=False))\n",
    "\n",
    "# model.add(LSTM(hidden_size, return_sequences=True))\n",
    "# model.add(LSTM(hidden_size, return_sequences=True))\n",
    "# if use_dropout:\n",
    "#     model.add(Dropout(0.2))\n",
    "\n",
    "# model.add(Dense(8))\n",
    "# model.add(Dense(4))\n",
    "# model.add(Dense(1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# optimizer = Adam()\n",
    "# model.compile(loss='categorical_crossentropy', optimizer='adam', metrics=['categorical_accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# embedding_matrix = np.loadtxt('embedding_matrix.txt', dtype=float)\n",
    "# # hidden_size = 500\n",
    "# hidden_size = 8 #25\n",
    "# use_dropout=True\n",
    "\n",
    "# #model.add(Embedding(vocabulary, hidden_size, input_length=num_steps))\n",
    "\n",
    "# model = Sequential()\n",
    "# model.add(Embedding(len(embedding_matrix), len(embedding_matrix[0]), weights=[embedding_matrix], input_length= 1, trainable=False))\n",
    "\n",
    "# model.add(LSTM(hidden_size, return_sequences=True))\n",
    "# model.add(LSTM(hidden_size, return_sequences=True))\n",
    "# if use_dropout:\n",
    "#     model.add(Dropout(0.2))\n",
    "\n",
    "# model.add(Dense(8, activation='relu'))\n",
    "# model.add(Dense(4, activation='relu'))\n",
    "# model.add(Dense(1, activation='relu'))\n",
    "# model.compile(optimizer='rmsprop', loss='mse', metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# model.fit(x_train, y_train, batch_size=16, epochs=10)\n",
    "# score = model.evaluate(x_test, y_test, batch_size=16)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "one epoch = one forward pass and one backward pass of all the training examples\n",
    "batch size = the number of training examples in one forward/backward pass. The higher the batch size, the more memory space you'll need.\n",
    "number of iterations = number of passes, each pass using [batch size] number of examples. To be clear, one pass = one forward pass + one backward pass (we do not count the forward pass and backward pass as two different passes).\n",
    "Example: if you have 1000 training examples, and your batch size is 500, then it will take 2 iterations to complete 1 epoch."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "embedding_10 (Embedding)     (None, 150, 50)           3949550   \n",
      "_________________________________________________________________\n",
      "lstm_9 (LSTM)                (None, 50)                20200     \n",
      "=================================================================\n",
      "Total params: 3,969,750\n",
      "Trainable params: 20,200\n",
      "Non-trainable params: 3,949,550\n",
      "_________________________________________________________________\n",
      "None\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "embedding_10 (Embedding)     (None, 150, 50)           3949550   \n",
      "_________________________________________________________________\n",
      "lstm_9 (LSTM)                (None, 50)                20200     \n",
      "_________________________________________________________________\n",
      "dropout_9 (Dropout)          (None, 50)                0         \n",
      "_________________________________________________________________\n",
      "dense_6 (Dense)              (None, 1)                 51        \n",
      "=================================================================\n",
      "Total params: 3,969,801\n",
      "Trainable params: 20,251\n",
      "Non-trainable params: 3,949,550\n",
      "_________________________________________________________________\n",
      "None\n"
     ]
    }
   ],
   "source": [
    "embedding_matrix = np.loadtxt('embedding_matrix.txt', dtype=float)\n",
    "# hidden_size = 500\n",
    "hidden_size =  len(embedding_matrix[0]) #25\n",
    "use_dropout=True\n",
    "\n",
    "#model.add(Embedding(vocabulary, hidden_size, input_length=num_steps))\n",
    "\n",
    "model = Sequential()\n",
    "model.add(Embedding(len(embedding_matrix), len(embedding_matrix[0]),\n",
    "                    weights=[embedding_matrix], input_length = 150, trainable=False))\n",
    "# model.add(Flatten())\n",
    "\n",
    "#model.add(LSTM(50, return_sequences=True, input_shape=(150, 50)))\n",
    "model.add(LSTM(hidden_size, return_sequences=False))\n",
    "\n",
    "print(model.summary())\n",
    "if use_dropout:\n",
    "    model.add(Dropout(0.2))\n",
    "\n",
    "#model.add(Flatten())\n",
    "model.add(Dense(1, activation='sigmoid'))\n",
    "\n",
    "# model.add(Dense(8, activation='relu'))\n",
    "# model.add(Dense(1, activation='relu'))\n",
    "# model.add(Dense(1, activation='softmax'))\n",
    "\n",
    "model.compile(optimizer='rmsprop', loss='mse', metrics=['accuracy'])\n",
    "print(model.summary())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "main_input (InputLayer)         (None, 150)          0                                            \n",
      "__________________________________________________________________________________________________\n",
      "embedding_1 (Embedding)         (None, 150, 50)      3949600     main_input[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "lstm_1 (LSTM)                   (None, 16)           4288        embedding_1[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "aux_input (InputLayer)          (None, 2)            0                                            \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_1 (Concatenate)     (None, 18)           0           lstm_1[0][0]                     \n",
      "                                                                 aux_input[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "dense_1 (Dense)                 (None, 18)           342         concatenate_1[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "dense_2 (Dense)                 (None, 18)           342         dense_1[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "dense_3 (Dense)                 (None, 18)           342         dense_2[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "main_output (Dense)             (None, 1)            19          dense_3[0][0]                    \n",
      "==================================================================================================\n",
      "Total params: 3,954,933\n",
      "Trainable params: 5,333\n",
      "Non-trainable params: 3,949,600\n",
      "__________________________________________________________________________________________________\n",
      "None\n"
     ]
    }
   ],
   "source": [
    "print(model.summary())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "embedding_matrix = np.loadtxt('embedding_matrix.txt', dtype=float)\n",
    "# hidden_size = 500\n",
    "hidden_size =  len(embedding_matrix[0]) #25\n",
    "use_dropout=True\n",
    "\n",
    "#model.add(Embedding(vocabulary, hidden_size, input_length=num_steps))\n",
    "\n",
    "def part(x):\n",
    "    x0 = x[:3]\n",
    "    x1 = x[3:]\n",
    "    model_2 = Sequential()\n",
    "    model_2.add(Embedding(len(embedding_matrix), len(embedding_matrix[0]),\n",
    "                    weights=[embedding_matrix], input_length = 150, trainable=False))\n",
    "    \n",
    "\n",
    "    #model.add(LSTM(50, return_sequences=True, input_shape=(150, 50)))\n",
    "    model_2.add(LSTM(hidden_size, return_sequences=False))\n",
    "    \n",
    "model = Sequential()\n",
    "model.add(Embedding(len(embedding_matrix), len(embedding_matrix[0]),\n",
    "                    weights=[embedding_matrix], input_length = 150, trainable=False))\n",
    "# model.add(Flatten())\n",
    "\n",
    "#model.add(LSTM(50, return_sequences=True, input_shape=(150, 50)))\n",
    "model.add(LSTM(hidden_size, return_sequences=False))\n",
    "\n",
    "print(model.summary())\n",
    "if use_dropout:\n",
    "    model.add(Dropout(0.2))\n",
    "\n",
    "#model.add(Flatten())\n",
    "model.add(Dense(1, activation='sigmoid'))\n",
    "\n",
    "# model.add(Dense(8, activation='relu'))\n",
    "# model.add(Dense(1, activation='relu'))\n",
    "# model.add(Dense(1, activation='softmax'))\n",
    "\n",
    "model.compile(optimizer='rmsprop', loss='mse', metrics=['accuracy'])\n",
    "print(model.summary())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[ 116 1119  603 ...    0    0    0]\n",
      " [   1  157 1608 ...    0    0    0]\n",
      " [ 274  185   30 ...    0    0    0]\n",
      " ...\n",
      " [  35 1318  513 ...    0    0    0]\n",
      " [ 124  407   81 ...    0    0    0]\n",
      " [  97   40   41 ...    0    0    0]]\n"
     ]
    }
   ],
   "source": [
    "padded_docs = pad_sequences(train_data, maxlen=150, padding='post')\n",
    "print(padded_docs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-44-96f42dcab441>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0marray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpadded_docs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0marray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my_train\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mepochs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m100\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mverbose\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m~/anaconda3/lib/python3.6/site-packages/keras/models.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, **kwargs)\u001b[0m\n\u001b[1;32m   1000\u001b[0m                               \u001b[0minitial_epoch\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0minitial_epoch\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1001\u001b[0m                               \u001b[0msteps_per_epoch\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0msteps_per_epoch\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1002\u001b[0;31m                               validation_steps=validation_steps)\n\u001b[0m\u001b[1;32m   1003\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1004\u001b[0m     def evaluate(self, x=None, y=None,\n",
      "\u001b[0;32m~/anaconda3/lib/python3.6/site-packages/keras/engine/training.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, **kwargs)\u001b[0m\n\u001b[1;32m   1703\u001b[0m                               \u001b[0minitial_epoch\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0minitial_epoch\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1704\u001b[0m                               \u001b[0msteps_per_epoch\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0msteps_per_epoch\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1705\u001b[0;31m                               validation_steps=validation_steps)\n\u001b[0m\u001b[1;32m   1706\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1707\u001b[0m     def evaluate(self, x=None, y=None,\n",
      "\u001b[0;32m~/anaconda3/lib/python3.6/site-packages/keras/engine/training.py\u001b[0m in \u001b[0;36m_fit_loop\u001b[0;34m(self, f, ins, out_labels, batch_size, epochs, verbose, callbacks, val_f, val_ins, shuffle, callback_metrics, initial_epoch, steps_per_epoch, validation_steps)\u001b[0m\n\u001b[1;32m   1234\u001b[0m                         \u001b[0mins_batch\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mins_batch\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtoarray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1235\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1236\u001b[0;31m                     \u001b[0mouts\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mins_batch\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1237\u001b[0m                     \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mouts\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlist\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1238\u001b[0m                         \u001b[0mouts\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mouts\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.6/site-packages/keras/backend/tensorflow_backend.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, inputs)\u001b[0m\n\u001b[1;32m   2480\u001b[0m         \u001b[0msession\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mget_session\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2481\u001b[0m         updated = session.run(fetches=fetches, feed_dict=feed_dict,\n\u001b[0;32m-> 2482\u001b[0;31m                               **self.session_kwargs)\n\u001b[0m\u001b[1;32m   2483\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mupdated\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moutputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2484\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.6/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36mrun\u001b[0;34m(self, fetches, feed_dict, options, run_metadata)\u001b[0m\n\u001b[1;32m    898\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    899\u001b[0m       result = self._run(None, fetches, feed_dict, options_ptr,\n\u001b[0;32m--> 900\u001b[0;31m                          run_metadata_ptr)\n\u001b[0m\u001b[1;32m    901\u001b[0m       \u001b[0;32mif\u001b[0m \u001b[0mrun_metadata\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    902\u001b[0m         \u001b[0mproto_data\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtf_session\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTF_GetBuffer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrun_metadata_ptr\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.6/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m_run\u001b[0;34m(self, handle, fetches, feed_dict, options, run_metadata)\u001b[0m\n\u001b[1;32m   1133\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mfinal_fetches\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0mfinal_targets\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mhandle\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mfeed_dict_tensor\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1134\u001b[0m       results = self._do_run(handle, final_targets, final_fetches,\n\u001b[0;32m-> 1135\u001b[0;31m                              feed_dict_tensor, options, run_metadata)\n\u001b[0m\u001b[1;32m   1136\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1137\u001b[0m       \u001b[0mresults\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.6/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m_do_run\u001b[0;34m(self, handle, target_list, fetch_list, feed_dict, options, run_metadata)\u001b[0m\n\u001b[1;32m   1314\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mhandle\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1315\u001b[0m       return self._do_call(_run_fn, feeds, fetches, targets, options,\n\u001b[0;32m-> 1316\u001b[0;31m                            run_metadata)\n\u001b[0m\u001b[1;32m   1317\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1318\u001b[0m       \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_do_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0m_prun_fn\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhandle\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfeeds\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfetches\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.6/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m_do_call\u001b[0;34m(self, fn, *args)\u001b[0m\n\u001b[1;32m   1320\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0m_do_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1321\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1322\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1323\u001b[0m     \u001b[0;32mexcept\u001b[0m \u001b[0merrors\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mOpError\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1324\u001b[0m       \u001b[0mmessage\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcompat\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mas_text\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmessage\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.6/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m_run_fn\u001b[0;34m(feed_dict, fetch_list, target_list, options, run_metadata)\u001b[0m\n\u001b[1;32m   1305\u001b[0m       \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_extend_graph\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1306\u001b[0m       return self._call_tf_sessionrun(\n\u001b[0;32m-> 1307\u001b[0;31m           options, feed_dict, fetch_list, target_list, run_metadata)\n\u001b[0m\u001b[1;32m   1308\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1309\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_prun_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mhandle\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfeed_dict\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfetch_list\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.6/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m_call_tf_sessionrun\u001b[0;34m(self, options, feed_dict, fetch_list, target_list, run_metadata)\u001b[0m\n\u001b[1;32m   1407\u001b[0m       return tf_session.TF_SessionRun_wrapper(\n\u001b[1;32m   1408\u001b[0m           \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_session\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moptions\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfeed_dict\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfetch_list\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtarget_list\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1409\u001b[0;31m           run_metadata)\n\u001b[0m\u001b[1;32m   1410\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1411\u001b[0m       \u001b[0;32mwith\u001b[0m \u001b[0merrors\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mraise_exception_on_not_ok_status\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mstatus\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "model.fit(np.array(padded_docs), np.array(y_train), epochs=100, verbose=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 247,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.000000\n"
     ]
    }
   ],
   "source": [
    "loss, accuracy = model.evaluate(padded_docs, np.array(y_train), verbose=0)\n",
    "print('Accuracy: %f' % (accuracy*100))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "-----------"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Keras"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from keras.preprocessing.text import Tokenizer\n",
    "from keras.preprocessing.sequence import pad_sequences\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, Embedding, LSTM\n",
    "from sklearn.model_selection import train_test_split\n",
    "from keras.utils.np_utils import to_categorical\n",
    "import re"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def file_to_word_ids(data, word_to_id):\n",
    "    return [word_to_id[word] for word in data if word in word_to_id]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "vocabulary = len(words_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def generate(self):\n",
    "    x = np.zeros((self.batch_size, self.num_steps))\n",
    "    y = np.zeros((self.batch_size, self.num_steps, self.vocabulary))\n",
    "    while True:\n",
    "        for i in range(self.batch_size):\n",
    "            if self.current_idx + self.num_steps >= len(self.data):\n",
    "                # reset the index back to the start of the data set\n",
    "                self.current_idx = 0\n",
    "            x[i, :] = self.data[self.current_idx:self.current_idx + self.num_steps]\n",
    "            temp_y = self.data[self.current_idx + 1:self.current_idx + self.num_steps + 1]\n",
    "            # convert all of temp_y into a one hot representation\n",
    "            y[i, :, :] = to_categorical(temp_y, num_classes=self.vocabulary)\n",
    "            self.current_idx += self.skip_step\n",
    "        yield x, y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "num_steps = 1\n",
    "batch_size = len(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "KerasBatchGenerator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "hidden_size = 500\n",
    "num_steps = 50\n",
    "use_dropout=True\n",
    "\n",
    "model = Sequential()\n",
    "model.add(Embedding(vocabulary, hidden_size, input_length=num_steps))\n",
    "model.add(LSTM(hidden_size, return_sequences=True))\n",
    "model.add(LSTM(hidden_size, return_sequences=True))\n",
    "model.add(Dropout(0.5))\n",
    "model.add(TimeDistributed(Dense(vocabulary)))\n",
    "model.add(Activation('softmax'))\n",
    "\n",
    "optimizer = Adam()\n",
    "model.compile(loss='categorical_crossentropy', optimizer='adam', metrics=['categorical_accuracy'])\n",
    "\n",
    "print(model.summary())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "model = Sequential()\n",
    "#output sze 32\n",
    "model.add(Dense(32, activation='relu', input_dim=50))\n",
    "model.add(Dense(1, activation='sigmoid'))\n",
    "model.compile(optimizer='rmsprop',\n",
    "              loss='binary_crossentropy',\n",
    "              metrics=['accuracy'])\n",
    "\n",
    "model.fit(train_vecs_w2v, y_train, epochs=9, batch_size=32, verbose=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/gasia/anaconda3/lib/python3.6/site-packages/ipykernel_launcher.py:6: UserWarning: The `dropout` argument is no longer support in `Embedding`. You can apply a `keras.layers.SpatialDropout1D` layer right after the `Embedding` layer to get the same behavior.\n",
      "  \n",
      "/home/gasia/anaconda3/lib/python3.6/site-packages/ipykernel_launcher.py:7: UserWarning: Update your `LSTM` call to the Keras 2 API: `LSTM(200, dropout=0.2, recurrent_dropout=0.2)`\n",
      "  import sys\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "embedding_1 (Embedding)      (None, 452820, 50)        3949550   \n",
      "_________________________________________________________________\n",
      "lstm_1 (LSTM)                (None, 200)               200800    \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 2)                 402       \n",
      "=================================================================\n",
      "Total params: 4,150,752\n",
      "Trainable params: 4,150,752\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "None\n"
     ]
    }
   ],
   "source": [
    "embed_dim = 50\n",
    "lstm_out = 200\n",
    "batch_size = 32\n",
    "\n",
    "model = Sequential()\n",
    "model.add(Embedding(len(word_space_df), embed_dim,input_length = len(X_train), dropout = 0.2))\n",
    "model.add(LSTM(lstm_out, dropout_U = 0.2, dropout_W = 0.2))\n",
    "model.add(Dense(2,activation='softmax'))\n",
    "model.compile(loss = 'categorical_crossentropy', optimizer='adam',metrics = ['accuracy'])\n",
    "print(model.summary())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "78991"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(word_space_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "'list' object has no attribute 'shape'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-47-30db9dd1bddd>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mX_train\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m: 'list' object has no attribute 'shape'"
     ]
    }
   ],
   "source": [
    "X_train.shape[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def load_data():\n",
    "    # get the data paths\n",
    "    train_path = os.path.join(data_path, \"ptb.train.txt\")\n",
    "    valid_path = os.path.join(data_path, \"ptb.valid.txt\")\n",
    "    test_path = os.path.join(data_path, \"ptb.test.txt\")\n",
    "\n",
    "    # build the complete vocabulary, then convert text data to list of integers\n",
    "    word_to_id = build_vocab(train_path)\n",
    "    train_data = file_to_word_ids(train_path, word_to_id)\n",
    "    valid_data = file_to_word_ids(valid_path, word_to_id)\n",
    "    test_data = file_to_word_ids(test_path, word_to_id)\n",
    "    vocabulary = len(word_to_id)\n",
    "    reversed_dictionary = dict(zip(word_to_id.values(), word_to_id.keys()))\n",
    "\n",
    "    print(train_data[:5])\n",
    "    print(word_to_id)\n",
    "    print(vocabulary)\n",
    "    print(\" \".join([reversed_dictionary[x] for x in train_data[:10]]))\n",
    "    return train_data, valid_data, test_data, vocabulary, reversed_dictionary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "class KerasBatchGenerator(object):\n",
    "\n",
    "    def __init__(self, data, num_steps, batch_size, vocabulary, skip_step=5):\n",
    "        self.data = data\n",
    "        self.num_steps = num_steps\n",
    "        self.batch_size = batch_size\n",
    "        self.vocabulary = vocabulary\n",
    "        # this will track the progress of the batches sequentially through the\n",
    "        # data set - once the data reaches the end of the data set it will reset\n",
    "        # back to zero\n",
    "        self.current_idx = 0\n",
    "        # skip_step is the number of words which will be skipped before the next\n",
    "        # batch is skimmed from the data set\n",
    "        self.skip_step = skip_step"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "simple arithmetic\n"
     ]
    }
   ],
   "source": [
    "def file_to_word_ids(data, word_to_id):\n",
    "    return [word_to_id[word] for word in data if word in word_to_id]\n",
    "\n",
    "\n",
    "def load_data():\n",
    "\n",
    "    # build the complete vocabulary, then convert text data to list of integers\n",
    "    #word_to_id = build_vocab(train_path)\n",
    "    with open('word_dict.json') as json_data:\n",
    "        word_to_id = json.load(json_data)\n",
    "\n",
    "    #train_data = file_to_word_ids(train_path, word_to_id)\n",
    "    with open('texts_clean.json') as json_data:\n",
    "        all_forum_data = json.load(json_data)\n",
    "    \n",
    "#     all_forum_data =all_forum_data[:20]\n",
    "    ###WARNINGS change to price\n",
    "    random_y = [random.uniform(-1, 1) for i in range(len(all_forum_data))]\n",
    "    price_data = random_y\n",
    "\n",
    "    # divide to train test validation sets (80% 10% 10%)\n",
    "    X_train, X_test, y_train, y_test = train_test_split(all_forum_data, price_data, test_size=0.1, random_state=1)\n",
    "\n",
    "    X_train, X_val, y_train, y_val = train_test_split(X_train, y_train, test_size=0.1, random_state=1)\n",
    "\n",
    "    train_data = [file_to_word_ids(elem, word_to_id) for elem in X_train]\n",
    "    valid_data = [file_to_word_ids(elem, word_to_id) for elem in X_val  ]\n",
    "    test_data  = [file_to_word_ids(elem, word_to_id) for elem in X_test ]\n",
    "\n",
    "    #valid_data = file_to_word_ids(valid_path, word_to_id)\n",
    "    #test_data = file_to_word_ids(test_path, word_to_id)\n",
    "\n",
    "    vocabulary = len(word_to_id)\n",
    "    reversed_dictionary = dict(zip(word_to_id.values(), word_to_id.keys()))\n",
    "\n",
    "    # back to word representation\n",
    "    print(\" \".join([reversed_dictionary[x] for x in train_data[5]]))\n",
    "    return train_data, valid_data, test_data, vocabulary, reversed_dictionary, y_train, y_test, y_val\n",
    "\n",
    "train_data, valid_data, test_data, vocabulary, reversed_dictionary, y_train, y_test, y_val = load_data()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
